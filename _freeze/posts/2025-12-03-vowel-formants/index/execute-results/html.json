{
  "hash": "db6aed58f1d1efea7050bbb0e449a03c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Normalising formant values for plotting and modelling\nauthor: Stefano Coretta\ndate: 2025-12-03\ncategories:\n  - Phonetics\n  - R\nexecute: \n  echo: true\nbibliography: references.bib\n---\n\nIn this R tutorial, you will learn how to normalise formant values for plotting and for modelling.\n\nFirst, let's attach the necessary packages.\nWe will use data from @coretta2025b, contained in the [coretta2018itaegg](https://github.com/stefanocoretta/coretta2018itaegg) package.\nYou will have to install the package from GitHub (code below).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ntheme_set(theme_light())\nlibrary(brms)\nlibrary(posterior)\nlibrary(tidybayes)\n# remotes::install_github(\"stefanocoretta/coretta2018itaegg)\nlibrary(coretta2018itaegg)\nlibrary(kableExtra)\n```\n:::\n\n\nNow we can load the `ita_egg` data, which has formant values from 19 speakers of Northwestern Italian (Verbano-Cusio-Ossola province).\nFormant values were extracted from 5 points within the first (stressed) vowel of CVCV words.\nIn this post, we will use values from the 3rd (central) point.\nBelow you can see a preview of the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"ita_egg\")\nita_egg <- ita_egg |> \n  drop_na(f13, f23)\n```\n:::\n\n\nThe columns of interests are:\n\n-   `f13`: first formant value in Hz (taken from the mid-point of the vowel).\n\n-   `f23`: second formant value in Hz (taken from the mid-point of the vowel).\n\n-   `vowel`: one of /a, e, i, o, u/.\n    The data comes from disyllabic CVCV words.\n\n-   `speaker`: the speaker's ID.\n\n## Raw Hz\n\nThe following is a vowel space plot, with the raw formant values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nita_egg |> \n  ggplot(aes(f23, f13, colour = vowel)) +\n  geom_point(alpha = 0.5) +\n  scale_x_reverse() + scale_y_reverse() +\n  labs(x = \"F2 (Hz)\", y = \"F1 (Hz)\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/f1-f2-1.png){width=672}\n:::\n:::\n\n\nWe know that different baseline vocal tract lengths result in different placements of the speaker's vowel space within the vowel plot.\nSimplifying, longer vocal tracts correspond to lower formants on average.\nCompare for example speaker IT02 and IT03.\nBased on their vowel spaces, we can derive that IT02 has a shorter vocal tract than IT03.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nita_egg |> \n  filter(speaker %in% c(\"it02\", \"it03\")) |> \n  ggplot(aes(f23, f13, colour = vowel)) +\n  geom_point(alpha = 0.5) +\n  scale_x_reverse() + scale_y_reverse() +\n  labs(x = \"F2 (Hz)\", y = \"F1 (Hz)\") +\n  facet_wrap(vars(speaker))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/f1-f2-speakers-1.png){width=672}\n:::\n:::\n\n\n## Within-speaker normalisation\n\nBecause of the different baseline vocal tract length, plotting raw formant values can result in misleading higher variance of formant values for each vowel.\nOne common way to \"normalise\" for different baseline vocal tract lengths is to calculate z-scores *within* speaker.\nThis is known as the Lobanov normalisation procedure due to @lobanov1971 having proposed the method.\n\nThe following code calculates z-scores for each formant, within speaker (remember to ungroup the tibble at the end).\nZ-scores are simply the value minus the mean divided by the standard deviation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nita_egg <- ita_egg |> \n  group_by(speaker) |> \n  mutate(\n    f1_z_sp = (f13 - mean(f13)) / sd(f13),\n    f2_z_sp = (f23 - mean(f23)) / sd(f23)\n  ) |> \n  ungroup()\n```\n:::\n\n\nIf we plot the within-speaker normalised data, now the clouds of values for each vowel look \"tighter\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nita_egg |> \n  ggplot(aes(f2_z_sp, f1_z_sp, colour = vowel)) +\n  geom_point(alpha = 0.5) +\n  scale_x_reverse() + scale_y_reverse() +\n  labs(x = \"F2 (z-scores)\", y = \"F1 (z-scores)\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/f1zsp-f2zsp-1.png){width=672}\n:::\n:::\n\n\nHowever, z-scores are very difficult to interpret in this context.\nTechnically, a z-score is a standardised measure of distance from the mean.\nThe unit of z-scores is the standard deviation of the variable.\nSo a z-score of +1 means that the value is one standard deviation above the mean (+1 SD).\nA z-score of -2 indicates that the value is two standard deviations below the mean (-2 SD).\nSince we have normalised within speaker, the mean and SD refer to the specific mean and SD of each speaker.\n\n## Within-speaker normalised Hz\n\nWe can transform the z-scores back to Hz by using the *overall* mean and SD: this will results in \"normalised\" Hz, or in other words Hz values for an \"average\" speaker (averaged across all speakers).\nThe following code does that.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nita_egg <- ita_egg |> \n  mutate(\n    f1_z_sp_hz = (f1_z_sp * sd(f13)) + mean(f13),\n    f2_z_sp_hz = (f2_z_sp * sd(f23)) + mean(f23)\n  )\n```\n:::\n\n\nNow we can plot with the normalised Hz values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nita_egg |> \n  ggplot(aes(f2_z_sp_hz, f1_z_sp_hz, colour = vowel)) +\n  geom_point(alpha = 0.5) +\n  scale_x_reverse() + scale_y_reverse() +\n  labs(x = \"F2 (norm Hz)\", y = \"F1 (norm Hz)\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/f1zsphz-f2zsphz-1.png){width=672}\n:::\n:::\n\n\n## Across-speaker normalisation\n\nIt seems to have become common to z-scores within speaker and then model this normalised data with multilevel regression models with by-speaker varying terms.\nSince the data is normalised within speaker, the by-speaker varying intercept is basically useless: there is no individual variability in intercept to account for, because of the normalisation.\n\nIn reality, a multilevel model can efficiently deal with individual variation (and even pool that information for estimation), so there is no real need to use within-speaker normalise data.\nHowever, z-scoring across speakers can help with convergence.\nIn the following code, we calculate z-scores *across* speakers (note that there is no `group_by()` in the code).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nita_egg <- ita_egg |> \n  mutate(\n    f1_z = (f13 - mean(f13)) / sd(f13),\n    f2_z = (f23 - mean(f23)) / sd(f23)\n  )\n```\n:::\n\n\nWe can now fit a multivariate multilevel regression model with F1 and F2 as outcome variables.\nTo keep things simple we just add vowel as a predictor and we include speaker-specific varying terms for intercept and vowel.\nWe use `set_rescor()` to estimate correlation between the residuals of F1 and F2.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor_bm <- brm(\n  bf(mvbind(f1_z, f2_z) ~ vowel + (vowel | speaker)) + set_rescor(),\n  family = gaussian,\n  data = ita_egg,\n  seed = 1923,\n  cores = 4,\n  file = \"posts/2025-12-03-vowel-formants/for_bm\"\n)\n```\n:::\n\n\nWe now proceed to obtain the draws of the expected predictions of F1 and F2.\nThe `epred_draws()` function from the tidybayes package facilitates that (see my blog post on methods for [obtaining expected values](../2025-11-08-expected-predictions/index.qmd)).\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_grid <- tibble(\n  vowel = unique(formants$vowel)\n)\n\nfor_draws <- epred_draws(for_bm, newdata = pred_grid, re_formula = NA)\n```\n:::\n\n\nBy default, `epred_draws()` returns a \"long\" tibble, where the two outcome variables are listed in the `.category` column.\nFor transformation and plotting it is easier to work with a wide format.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor_draws_wide <- for_draws |> \n  pivot_wider(names_from = .category, values_from = .epred)\n```\n:::\n\n\nWe can now plot the expected values draws.\nThese are z-scores.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor_draws_wide |> \n  ggplot(aes(f2z, f1z, colour = vowel)) +\n  geom_point(alpha = 0.05) +\n  scale_x_reverse() + scale_y_reverse()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/f1z-f2z-1.png){width=672}\n:::\n:::\n\n\nWe can transform these values to Hz by using the overall mean and SD of F1 and F2, like we did above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nf1m <- mean(formants$f13)\nf1sd <- sd(formants$f13)\nf2m <- mean(formants$f23)\nf2sd <- sd(formants$f23)\n\nfor_draws_wide <- for_draws_wide |> \n  mutate(\n    f1z_hz = (f1z * f1sd) + f1m,\n    f2z_hz = (f2z * f2sd) + f2m\n  )\n```\n:::\n\n\nAnd finally, we plot 95% ellipses for each vowel based on the draws.\nNote that, since these are *expected* values, they do not include uncertainty from the residuals nor from the varying terms of the model.\nIn other words, there is a 95% probability that the mean F1/F2 for each vowel is within the ellipse.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor_draws_wide |> \n  ggplot(aes(f2z_hz, f1z_hz, colour = vowel)) +\n  stat_ellipse(type = \"norm\") +\n  scale_x_reverse() + scale_y_reverse()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/f1zhz-f2zhz-1.png){width=672}\n:::\n:::\n\n\nWe can also obtain Credible Intervals (CrI) for each vowel F1 and F2.\nHere, we get 90% CrIs (the default in `quantile2()` from the posterior package).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor_draws_wide |> \n  group_by(vowel) |> \n  summarise(\n    f1_mean = round(mean(f1z_hz)), f1_sd = round(sd(f1z_hz)),\n    f1_90 = str_glue(\"[{round(quantile2(f1z_hz)[1])}, {round(quantile2(f1z_hz)[2])}]\"),\n    f2_mean = round(mean(f2z_hz)), f2_sd = round(sd(f2z_hz)),\n    f2_90 = str_glue(\"[{round(quantile2(f2z_hz)[1])}, {round(quantile2(f2z_hz)[2])}]\")\n  ) |> \n  knitr::kable(col.names = rep(\"\", 7), align = \"c\") |> \n  add_header_above(c(\" \" = 1, rep(c(\"mean\" = 1, \"SD\" = 1, \"90% CrI\" = 1), 2))) |> \n  add_header_above(c(\" \" = 1, \"F1\" = 3, \"F2\" = 3))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"3\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">F1</div></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"3\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">F2</div></th>\n</tr>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"1\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">mean</div></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"1\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">SD</div></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"1\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">90% CrI</div></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"1\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">mean</div></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"1\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">SD</div></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"1\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">90% CrI</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:center;\">  </th>\n   <th style=\"text-align:center;\">  </th>\n   <th style=\"text-align:center;\">  </th>\n   <th style=\"text-align:center;\">  </th>\n   <th style=\"text-align:center;\">  </th>\n   <th style=\"text-align:center;\">  </th>\n   <th style=\"text-align:center;\">  </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> a </td>\n   <td style=\"text-align:center;\"> 864 </td>\n   <td style=\"text-align:center;\"> 16 </td>\n   <td style=\"text-align:center;\"> [837, 890] </td>\n   <td style=\"text-align:center;\"> 1438 </td>\n   <td style=\"text-align:center;\"> 25 </td>\n   <td style=\"text-align:center;\"> [1397, 1479] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> e </td>\n   <td style=\"text-align:center;\"> 484 </td>\n   <td style=\"text-align:center;\"> 14 </td>\n   <td style=\"text-align:center;\"> [462, 508] </td>\n   <td style=\"text-align:center;\"> 2218 </td>\n   <td style=\"text-align:center;\"> 41 </td>\n   <td style=\"text-align:center;\"> [2152, 2285] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> i </td>\n   <td style=\"text-align:center;\"> 422 </td>\n   <td style=\"text-align:center;\"> 17 </td>\n   <td style=\"text-align:center;\"> [394, 449] </td>\n   <td style=\"text-align:center;\"> 2474 </td>\n   <td style=\"text-align:center;\"> 48 </td>\n   <td style=\"text-align:center;\"> [2394, 2550] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> o </td>\n   <td style=\"text-align:center;\"> 639 </td>\n   <td style=\"text-align:center;\"> 14 </td>\n   <td style=\"text-align:center;\"> [617, 661] </td>\n   <td style=\"text-align:center;\"> 1065 </td>\n   <td style=\"text-align:center;\"> 24 </td>\n   <td style=\"text-align:center;\"> [1025, 1104] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> u </td>\n   <td style=\"text-align:center;\"> 406 </td>\n   <td style=\"text-align:center;\"> 14 </td>\n   <td style=\"text-align:center;\"> [384, 428] </td>\n   <td style=\"text-align:center;\"> 829 </td>\n   <td style=\"text-align:center;\"> 28 </td>\n   <td style=\"text-align:center;\"> [782, 873] </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## Summary\n\n::: {.callout-note appearance=\"simple\"}\nIn sum, there are two main options for normalising formant values.\n\n-   *Within*-speaker normalisation (z-scores) and back-transformation in Hz with the overall mean and SD.\n    Ideal for plotting.\n\n-   *Across*-speaker normalisation (z-scores) and back-transformation in Hz with the overall mean and SD.\n    Ideal for modelling.\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}