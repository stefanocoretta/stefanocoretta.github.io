<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Methods | Stefano Coretta</title>
    <link>https://stefanocoretta.github.io/categories/methods/</link>
      <atom:link href="https://stefanocoretta.github.io/categories/methods/index.xml" rel="self" type="application/rss+xml" />
    <description>Methods</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-uk</language><copyright>© 2017-2020 Stefano Coretta</copyright><lastBuildDate>Mon, 17 Jun 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Methods</title>
      <link>https://stefanocoretta.github.io/categories/methods/</link>
    </image>
    
    <item>
      <title>Plotting prior distributions with ggplot2</title>
      <link>https://stefanocoretta.github.io/post/plot-prior-distributions-with-ggplot2/</link>
      <pubDate>Mon, 17 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://stefanocoretta.github.io/post/plot-prior-distributions-with-ggplot2/</guid>
      <description>


&lt;p&gt;The choice of priors is a fundamental step of the Bayesian inference process. &lt;span class=&#34;citation&#34;&gt;Vasishth et al. (2018)&lt;/span&gt; recommend plotting the chosen priors to see if they are reasonable.&lt;/p&gt;
&lt;p&gt;In this post I will show how to easily plot prior distributions in &lt;a href=&#34;https://ggplot2.tidyverse.org&#34;&gt;ggplot2&lt;/a&gt; (which is part of the &lt;a href=&#34;https://www.tidyverse.org&#34;&gt;tidyverse&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Let’s load the tidyverse first.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ────────────── tidyverse 1.3.0 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓ ggplot2 3.2.1     ✓ purrr   0.3.3
## ✓ tibble  2.1.3     ✓ dplyr   0.8.4
## ✓ tidyr   1.0.2     ✓ stringr 1.4.0
## ✓ readr   1.3.1     ✓ forcats 0.4.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ───────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;theme_set(theme_minimal()) # I just like this theme :)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;plotting-your-priors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plotting your priors&lt;/h2&gt;
&lt;p&gt;Let’s start with a simple normal prior with &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; = 0 and &lt;em&gt;sd&lt;/em&gt; = 1.&lt;/p&gt;
&lt;p&gt;The plot is initialised with an empty call to &lt;code&gt;ggplot()&lt;/code&gt;.
As aesthetics, you only need to specify the range of &lt;em&gt;x&lt;/em&gt; values in &lt;code&gt;aes()&lt;/code&gt;.
Here, we use &lt;code&gt;c(-4, 4)&lt;/code&gt;, meaning that the &lt;em&gt;x&lt;/em&gt;-axis of this plot will have these limits.
For a normal distribution, it is useful to set the limits as the mean ± 4 times the standard deviation (this ensures all the distribution is shown).&lt;/p&gt;
&lt;p&gt;The function &lt;code&gt;ggplot2::stat_function()&lt;/code&gt; allows us to specify a distribution family with the &lt;code&gt;fun&lt;/code&gt; argument.
This arguments takes the density function (the R functions of the form &lt;em&gt;dxxx&lt;/em&gt;) of the chosen distribution family, so for the normal (Gaussian) distribution we use &lt;code&gt;dnorm()&lt;/code&gt;.
The argument &lt;code&gt;n&lt;/code&gt; specifies the number of points along which to calculate the distribution (here &lt;code&gt;101&lt;/code&gt;), while &lt;code&gt;args&lt;/code&gt; takes a list with the parameters of the distribution (here the mean &lt;code&gt;0&lt;/code&gt; and standard deviation &lt;code&gt;1&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  aes(x = c(-4, 4)) +
  stat_function(fun = dnorm, n = 101, args = list(0, 1)) +
  labs(title = &amp;quot;Normal (Gaussian) distribution&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://stefanocoretta.github.io/post/2019-06-17-plot-prior-distributions-with-ggplot2_files/figure-html/normal-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you are using a half-normal prior, you can plot it by setting one of the limits to the mean.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  # the mean is 0, only positive number are shown
  aes(x = c(0, 4)) +
  stat_function(fun = dnorm, n = 101, args = list(0, 1)) +
  labs(title = &amp;quot;Half-normal distribution&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://stefanocoretta.github.io/post/2019-06-17-plot-prior-distributions-with-ggplot2_files/figure-html/half-normal-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A beta prior will be bounded between 0 and 1, so we can specify that in &lt;code&gt;aes()&lt;/code&gt;.
The beta distribution has two arguments, &lt;code&gt;shape1&lt;/code&gt; and &lt;code&gt;shape2&lt;/code&gt; (here &lt;code&gt;2&lt;/code&gt; and &lt;code&gt;5&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  aes(x = c(0, 1)) +
  stat_function(fun = dbeta, n = 101, args = list(2, 5)) +
  labs(title = &amp;quot;Beta distribution&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://stefanocoretta.github.io/post/2019-06-17-plot-prior-distributions-with-ggplot2_files/figure-html/beta-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Another common distribution is the Cauchy.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  aes(x = c(-10, 10)) +
  stat_function(fun = dcauchy, n = 201, args = list(-2, 1)) +
  labs(title = &amp;quot;Cauchy distribution&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://stefanocoretta.github.io/post/2019-06-17-plot-prior-distributions-with-ggplot2_files/figure-html/cauchy-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The Poisson distribution can be plotted by changing the type of &lt;code&gt;geom&lt;/code&gt; and using an &lt;code&gt;n&lt;/code&gt; that creates only integers.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the range 0:20 includes 21 integers, so n = 21
ggplot() +
  aes(x = c(0, 20)) +
  stat_function(fun = dpois, n = 21, args = list(4), geom = &amp;quot;point&amp;quot;) +
  labs(title = &amp;quot;Poisson distribution&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://stefanocoretta.github.io/post/2019-06-17-plot-prior-distributions-with-ggplot2_files/figure-html/poisson-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Of course any family with a corresponding &lt;em&gt;dxxx&lt;/em&gt; function can be plotted (see &lt;code&gt;?Distributions&lt;/code&gt; and package-provided families).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-vasishth2018&#34;&gt;
&lt;p&gt;Vasishth, Shravan, M. Beckman, B. Nicenboim, Fangfang Li, and Eun Jong Kong. 2018. “Bayesian Data Analysis in the Phonetic Sciences: A Tutorial Introduction.” &lt;em&gt;Journal of Phonetics&lt;/em&gt; 71: 147–61. &lt;a href=&#34;https://doi.org/10.1016/j.wocn.2018.07.008&#34;&gt;https://doi.org/10.1016/j.wocn.2018.07.008&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>An estimate of number of speakers per study in phonetics</title>
      <link>https://stefanocoretta.github.io/post/an-estimate-of-number-of-speakers-per-study-in-phonetics/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      <guid>https://stefanocoretta.github.io/post/an-estimate-of-number-of-speakers-per-study-in-phonetics/</guid>
      <description>


&lt;p&gt;A few weeks ago, I’ve asked on Twitter what people thought was the average number of participants used in phonetic studies.
Here’s the tweet.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
Does anyone have an estimate of the average number of participants/tokens per context of recently published phonetic studies (let&#39;s say from the last 10 years)? &lt;a href=&#34;https://twitter.com/hashtag/OpenScience?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#OpenScience&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/phonetics?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#phonetics&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/replication?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#replication&lt;/a&gt;
&lt;/p&gt;
— Stefano Coretta (&lt;span class=&#34;citation&#34;&gt;@StefanoCoretta&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/StefanoCoretta/status/1116692106700103680?ref_src=twsrc%5Etfw&#34;&gt;April 12, 2019&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;Thankfully, &lt;a href=&#34;https://timo-roettger.weebly.com&#34;&gt;Timo Roettger&lt;/a&gt; has pointed me to a dataset he and &lt;a href=&#34;http://gordon.faculty.linguistics.ucsb.edu&#34;&gt;Matthew Gordon&lt;/a&gt; created for a study on the &lt;a href=&#34;https://osf.io/9r2cd/&#34;&gt;acoustic correlates of word stress&lt;/a&gt;, and he suggested to look at how the median number of speakers changed (or not) through the years.
The &lt;a href=&#34;https://osf.io/765q4/&#34;&gt;dataset&lt;/a&gt; reports, among other things, the number of participants in the surveyed studies.
&lt;a href=&#34;http://www.acsu.buffalo.edu/~cdicanio/&#34;&gt;Christian DiCanio&lt;/a&gt; has also thoughtfully noted that language endangerment should be taken into consideration in any enquiry about number of speakers.&lt;/p&gt;
&lt;div id=&#34;general-trends&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;General trends&lt;/h2&gt;
&lt;p&gt;The dataset contains data from 113 studies, published between 1955 and 2017 (the bulk of studies is within the range 1990-2017 though).
The median number of speakers per study is 5.
The histogram below illustrates that most studies have around 10 speakers or less, and that there are a few outliers with 30-40 speakers.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://stefanocoretta.github.io/post/2019-05-03-an-estimate-of-number-of-speakers-per-study-in-phonetics_files/figure-html/hist-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;number-of-speakers-through-the-years&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Number of speakers through the years&lt;/h2&gt;
&lt;p&gt;We now turn to the number of speakers through the years.
I can’t really say that there is a clear trend, if not for the fact that the studies with more than 30 speakers are (unsurprisingly) more recent.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://stefanocoretta.github.io/post/2019-05-03-an-estimate-of-number-of-speakers-per-study-in-phonetics_files/figure-html/year-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;number-of-speakers-by-linguistic-affiliation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Number of speakers by linguistic affiliation&lt;/h2&gt;
&lt;p&gt;The following bar chart shows the median number of speakers in studies by genetic affiliation.
The colour of the bars indicates the number of studies.
Indo-European languages stand out in terms of number of studies (&amp;gt; 30), although the number of speakers does not fare better than other less-reachable language families.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://stefanocoretta.github.io/post/2019-05-03-an-estimate-of-number-of-speakers-per-study-in-phonetics_files/figure-html/participants-affiliation-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This plot is the same as the one above, but families have been categorised by number of studies in two categories: up to 5 studies vs. 5 or more.
It is not surprising that Uralic, Indo-European, Turkic, Afro-Asiatic and Austronesian stand out.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://stefanocoretta.github.io/post/2019-05-03-an-estimate-of-number-of-speakers-per-study-in-phonetics_files/figure-html/participants-affiliation-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;number-of-speakers-by-endangerment-status&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Number of speakers by endangerment status&lt;/h2&gt;
&lt;p&gt;Information on the endangerment status of the languages in the dataset was obtained from &lt;a href=&#34;https://glottolog.org/meta/downloads&#34;&gt;GlottoLog&lt;/a&gt;.
The following strip chart show the number of speakers for each of the studies (each point) categorised by the endangerment of the language.
Of course there are way more studies on safe languages, and if we focus on the first three categories of endangerment (safe, vulnerable, definitely endangered) there is a tendency to have a decreasing number of speakers.
Considering though that we are talking of very low numbers of speakers (5-10) I am not sure it is actually relevant that definitely endangered languages have a lower median than safe languages.
Difficult to say anything about higher endangerment levels given the low number of studies.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://stefanocoretta.github.io/post/2019-05-03-an-estimate-of-number-of-speakers-per-study-in-phonetics_files/figure-html/status-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;While of course making generalisations based on this cursory analysis would not be wise, there seems to be a tendency for studies to have a very low number of speakers (median 5 speakers over study).
The majority of studies have obtained data from 10 speakers or less, independent of publication year and endangerment status of the language enquired.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Literate programming with Praat</title>
      <link>https://stefanocoretta.github.io/post/literate-programming-with-praat/</link>
      <pubDate>Thu, 21 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://stefanocoretta.github.io/post/literate-programming-with-praat/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://stefanocoretta.github.io/img/praat-literate.png&#34; alt=&#34;Literate Praat example&#34;&gt;&lt;/p&gt;
&lt;p&gt;This post quickly illustrates how to apply a literate programming workflow to Praat scripting.
To be able to reproduce the steps described here you need the latest version of &lt;a href=&#34;https://pandoc.org&#34;&gt;pandoc&lt;/a&gt; and the &lt;a href=&#34;https://github.com/driusan/lmt&#34;&gt;Literate Markdown Tangler&lt;/a&gt; (&lt;code&gt;lmt&lt;/code&gt;, you will need to install &lt;a href=&#34;https://golang.org&#34;&gt;Go&lt;/a&gt; first to install &lt;code&gt;lmt&lt;/code&gt;).&lt;/p&gt;
&lt;h2 id=&#34;what-is-literate-programming&#34;&gt;What is literate programming?&lt;/h2&gt;
&lt;p&gt;In &lt;a href=&#34;https://en.wikipedia.org/wiki/Literate_programming&#34;&gt;literate programming&lt;/a&gt;, one writes both code and plain text which explains what the code does in a single document.
Natural language and programming language are interleaved in the document in a way that is reader-oriented, rather than software oriented.
So, for example, the code can be included in an order that is different from the order it should have had the document been a script.&lt;/p&gt;
&lt;p&gt;This programming paradigm allows developers to focus on documenting their code in a more natural way.
This has the double advantage of aiding a new user in understanding what the code does and helping the author of the code to develop the code following a logic that can be different from the logic of the code&amp;rsquo;s programming language.&lt;/p&gt;
&lt;p&gt;In general, from a literate source file (a file containing both natural language and programming code) it is possible to obtain a documentation file (by the process called &lt;em&gt;weaving&lt;/em&gt;) and a script file (by the process called &lt;em&gt;tangling&lt;/em&gt;) which is interpretable by the target programming language.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.markdownguide.org&#34;&gt;Markdown&lt;/a&gt;, a simple but effective mark-up language, allows mixing natural language (with rich formatting) and code in a single document.
&lt;a href=&#34;https://pandoc.org&#34;&gt;Pandoc&lt;/a&gt; is a software utility which can convert documents from and to a variety of formats.
The conversion relevant to us is from Markdown to PDF.
Converting Markdown to PDF corresponds to the weaving process mentioned above, i.e. creating a richly formatted documentation of the code.
Pandoc has syntax highlighting capabilities, and Praat syntax is supported, so that your documentation will also be easier to interpret.
The &lt;code&gt;Literate Markdown Tangler&lt;/code&gt;, by Dave MacFarlane, is a software written in &lt;a href=&#34;https://golang.org&#34;&gt;Go&lt;/a&gt; that instead can be used to tangle (extract) the code from the source file into a scripting file.&lt;/p&gt;
&lt;p&gt;Pandoc and &lt;code&gt;lmt&lt;/code&gt; can be used together to develop a literate programming workflow with Praat scripting.
This means that you can develop a Praat script by laying out the pieces of the script in the source file and explain what the various parts of the script do in using natural language.
&lt;code&gt;lmt&lt;/code&gt; further allows the user to create &amp;ldquo;blocks&amp;rdquo; of code that can be referenced in other blocks and reused.
If you wanna generate a PDF version of the documentation, you can convert the source file to a PDF with Pandoc.&lt;/p&gt;
&lt;p&gt;The figure at the top of this post shows an example of a literate Praat source file.&lt;/p&gt;
&lt;p&gt;The following sections will point you to the software and files that need to be installed/copied and will show how to use literate programming with Praat scripting.&lt;/p&gt;
&lt;h2 id=&#34;necessary-software&#34;&gt;Necessary software&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;You need to install the latest version of Pandoc, which can be found &lt;a href=&#34;https://pandoc.org/installing.html&#34;&gt;here&lt;/a&gt;. After installing, be sure you can run this command from your command line GUI: &lt;code&gt;pandoc --version&lt;/code&gt;. If a version is returned, Pandoc is working on your system.&lt;/li&gt;
&lt;li&gt;Install Go from &lt;a href=&#34;https://golang.org&#34;&gt;here&lt;/a&gt; and set it up, then download and install &lt;code&gt;lmt&lt;/code&gt; from &lt;a href=&#34;https://github.com/driusan/lmt&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Download and unzip the content of &lt;a href=&#34;https://stefanocoretta.github.io/files/pandoc-praat.zip&#34;&gt;this zip&lt;/a&gt; to a convenient directory (usually, in &lt;code&gt;.pandoc/&lt;/code&gt; in your user folder). This folder contains the files which allow Pandoc to highlight Praat syntax.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;literate-praat&#34;&gt;Literate Praat&lt;/h2&gt;
&lt;p&gt;To generate the Praat script and its documentation, you have to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Write your script in a Markdown source file with Praat code enclosed in code chunks that follow the format required by &lt;code&gt;lmt&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;lmt&lt;/code&gt; to tangle the code from the source file into a standalone Praat script.&lt;/li&gt;
&lt;li&gt;Use pandoc with a custom syntax highlighter to generate the documentation of the script.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;the-source-file&#34;&gt;The source file&lt;/h3&gt;
&lt;p&gt;The source file will contain text, Markdown markup, and code enclosed between back-ticks.
The following is an example of how such file would look like.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://stefanocoretta.github.io/img/basic.png&#34; alt=&#34;Literate Praat basic example&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;tangle-the-code&#34;&gt;Tangle the code&lt;/h3&gt;
&lt;p&gt;To tangle the code into a standalone Praat script, run the following line from your command line GUI, where &lt;code&gt;my-script.praat.md&lt;/code&gt; is your Praat source file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lmt my-script.praat.md
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The scripts defined in the source file will be output in the same directory as the source file (to learn more on how this works, check the &lt;code&gt;lmt&lt;/code&gt; README on GitHub).&lt;/p&gt;
&lt;h3 id=&#34;weave-the-documentation&#34;&gt;Weave the documentation&lt;/h3&gt;
&lt;p&gt;To weave the documentation, run the following by replacing the syntax definition path with the path to the &lt;code&gt;pandoc-praat/&lt;/code&gt; folder on your computer:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pandoc -f gfm -o doc.pdf script.praat.md -N --syntax-definition=&amp;lt;your-path-here&amp;gt;/pandoc-praat/praat.xml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This line of code tells Pandoc to convert from Markdown to PDF and where to find the files for highlighting Praat code.&lt;/p&gt;
&lt;p&gt;A &lt;code&gt;.pdf&lt;/code&gt; file named &lt;code&gt;doc.pdf&lt;/code&gt; containing the documentation of the script will be created when the line is run.&lt;/p&gt;
&lt;h2 id=&#34;syntax-highlighting-in-your-editor&#34;&gt;Syntax highlighting in your editor&lt;/h2&gt;
&lt;p&gt;If you are after an editor that has syntax highlighting for Praat, I suggest you to try out (Atom)[https://atom.io] and the package &lt;a href=&#34;https://atom.io/packages/language-praat&#34;&gt;language-praat&lt;/a&gt; (disclaimer, I am the author of the package 😉).&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
