---
title: 'Regression models: a cheat-sheet'
author: Stefano Coretta
date: '2021-08-21'
slug: [regression-models]
categories: []
tags: []
---

# One model to rule them all

TBA

# Step 1: Choose a distribution for your outcome variable

The first step towards building a regression model is to choose the **family of distributions** you believe the outcome variable belongs to.

You can start by answering this question: is your outcome variable continuous or discrete?

## Continuous outcome variable

* The variable can take on *any positive and negative real number, including 0*: **Gaussian** (aka normal) distribution.

    * There are very few truly Gaussian variables, although in some cases one can speak of "approximate" or "assumed" normality.

    * This family is fitted by default in `lm()` and `brms::brm()`.

* The variable can take on *any positive number only*: **Log-normal** distribution.

    * Duration of segments, words, pauses, etc, are known to be log-normally distributed.

    * Measurements taken in Hz (like f0, formants, centre of gravity, ...) could be considered to be log-normal.

    * There other families that could potentially be used depending on the nature of the variable: exponential-Gaussian (reaction times), gamma, ...

* The variable can take on *any number between 0 and 1, but not 0 nor 1*: **Beta** distribution.

    * Proportions fall into this category (for example proportion of voicing within closure), although 0 and 1 are not allowed in the beta distribution.

* The variable can take on *any number between 0 and 1, including 0 or 0 and 1*: **Zero-inflated** or **Zero/one-inflated beta** (ZOIB) distribution.

    * If the proportion data includes many 0s and 1s, then this is the ideal distribution to use. ZOIB distributions are somewhat more difficult to fit than a simple beta distribution, so a common practice is to transform the data so that it doesn't include 0s nor 1s (this can be achieved using different techniques, some better than others).

## Discrete outcome variable

* The variable is *dichotomous*, i.e. it can take one of two levels: **Bernoulli** distribution.

    * Categorical outcome variables like yes/no, correct/incorrect, voiced/voiceless, follow this distribution.

    * This family is fitted by default when you run `glm(family = binomial)`, aka "logistic regression".

* The variable is *counts*: **Poisson** distribution.

    * Counts of words, segments, gestures, f0 peaks, ...

# Step 2: Are there hierarchical groupings and/or repeated measures?

The second step is to ensure that, if the data is structured hierarchically or repeated measures were taken, this is taken into account in the model.
Here is where so-called "random effects" or "group-level terms" come in.

As an example, let's assume you asked a number of participants to read a list of words and each word was repeated 5 times by each participant.
You then took f0 measurements from the stressed vowel of each word, of each repetition.

Now, the data has a structure to it:

- First, observations are grouped by participant (some observations belong to one participant and others to another and so on).
- Second, observations are grouped by word (some observations belong to one word and others to another and so on).
- Third, within the observations of each word, some belong to the same participant (or, from a different perspective, within the observations of each participant, some belong to the same word).

The presence of "groupings" within the data (whether they come from natural groupings like participant or word, or from repeated measures) breaks one of the assumptions of regression models: that each observation must be independent.

If you don't include any random effect/group-level terms, your model will expect that each observation is independent and hence it will underestimate variance and return unreliable results.

In the toy-example of f0 measurements, you will want to include group-level terms for *participant* and *word*.
These will take care to let the model know of the structure of the data mentioned above.

If you have other predictors in the model, you should also add them as (random) slopes in the random effects/group-level terms.
For example: `(question | participant) + (question | word)` (where `question` = statement vs question).

A quick terminological note: models that include random effects/group-level terms are called:

- Random-effects models.
- Mixed-effects models.
- Hierarchical models.
- Nested models.
- Multilevel models.

These terms are for all intents and purposes equivalent (it just happens that different traditions uses different terms).

# Step 3: Are there non-linear effects?

# Step 0: Number of outcome variables

If you want to model just one outcome variable, you are already covered if you went through Steps 1-3.

If instead your data has two or more outcome variables, then you want to fit a **multivariate model** (i.e. a model with *multiple outcome *variables*).
