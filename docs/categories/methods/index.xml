<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Methods on Stefano Coretta</title>
    <link>https://stefanocoretta.github.io/categories/methods/</link>
    <description>Recent content in Methods on Stefano Coretta</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <lastBuildDate>Fri, 22 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://stefanocoretta.github.io/categories/methods/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>One Thousand and One names</title>
      <link>https://stefanocoretta.github.io/post/2022-07-22-one-thousand-and-one-names/</link>
      <pubDate>Fri, 22 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/2022-07-22-one-thousand-and-one-names/</guid>
      <description>The following table lists common “portmanteau” names for linear models. Note that different traditions/disciplines might use one particular name more often than the others.
My usual recommendation is to move away from using specific names like “logistic regression” or “mixed-effects models” and instead just specify what kind of components your linear model has (see the Description column in the table).
Formula Description Names lm(y ~ x) Linear model with one predictor x using a Gaussian distribution for the outcome variable y simple linear regression, simple linear model lm(y ~ x + z + .</description>
    </item>
    
    <item>
      <title>Linear models: a cheat-sheet</title>
      <link>https://stefanocoretta.github.io/post/2021-08-21-regression-models-a-cheat-sheet/</link>
      <pubDate>Sat, 21 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/2021-08-21-regression-models-a-cheat-sheet/</guid>
      <description>One model to rule them all Linear models, aka linear regression models or regression models, are a group of statistical models based on the simple idea that we can predict an outcome variable \(Y\) based on a function \(f(X)\).
The “simplest” linear model is the formula of a line:1
\[ y = \alpha + \beta x \]
where \(\alpha\) is the intercept of the line and \(\beta\) the slope.</description>
    </item>
    
    <item>
      <title>Factors, coding and contrasts</title>
      <link>https://stefanocoretta.github.io/post/contrasts/</link>
      <pubDate>Tue, 20 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/contrasts/</guid>
      <description>This post is an overview of how factors (i.e. categorical variables) are coded under the hood and which types of coding can be set in R.1
Introduction There’s seems to be a bit of terminological mix-up in the wild, so we first present a terminological set that will be used throughout the vignette.
Categorical variables in R are generally stored using factors. A factor is a vector of values from a categorical variable.</description>
    </item>
    
    <item>
      <title>R gist — Plotting the area under the curve with ggplot</title>
      <link>https://stefanocoretta.github.io/post/plotting-the-area-under-the-curve/</link>
      <pubDate>Sun, 04 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/plotting-the-area-under-the-curve/</guid>
      <description>knitr::opts_chunk$set(echo = TRUE) library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ── ## ✔ ggplot2 3.4.0 ✔ purrr 1.0.1 ## ✔ tibble 3.1.8 ✔ dplyr 1.0.10 ## ✔ tidyr 1.2.1 ✔ stringr 1.5.0 ## ✔ readr 2.1.3 ✔ forcats 0.5.2 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() library(ggthemr) ggthemr(&amp;quot;earth&amp;quot;) x &amp;lt;- 1:11 y &amp;lt;- (1.5:11.5)^2 low &amp;lt;- (0:10)^2 upp &amp;lt;- (3:13)^2 ggplot() + aes(x, y) + geom_line() + geom_ribbon(aes(ymin = low, ymax = upp), alpha = 0.</description>
    </item>
    
    <item>
      <title>Methods as theory</title>
      <link>https://stefanocoretta.github.io/post/methods-as-theory/</link>
      <pubDate>Sun, 28 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/methods-as-theory/</guid>
      <description>At least in linguistics, there is a general tendency to contrast theory with methods. This dichotomy is also reflected in the classification of academic papers as theoretical or methodological.
In this brief post I will argue that the theory/methods divide is epistemologically incoherent, and I will instead propose a taxonomy in which methods are subsumed under theory and are part of it.
1 What is theory? The term theory is used with different senses in different domains.</description>
    </item>
    
    <item>
      <title>On random effects</title>
      <link>https://stefanocoretta.github.io/post/2021-03-15-on-random-effects/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/2021-03-15-on-random-effects/</guid>
      <description>If you use mixed-effects models (aka multilevel models, hierarchical models), I am sure that at some point you asked yourself the following question at least once: Should I include variable X as a fixed or as a random effect?
To answer this question we need to ask first: what is a random effect?
Regrettably, there is no straightforward answer (disappointed, uh?).
The main reason is that, in fact, there are many possible (and most times mutually exclusive) definitions of what a random (vs fixed) effect is.</description>
    </item>
    
    <item>
      <title>How to globally set colour scales in ggplot2</title>
      <link>https://stefanocoretta.github.io/post/set-global-ggplot2/</link>
      <pubDate>Tue, 22 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/set-global-ggplot2/</guid>
      <description>After the post on using custom typefaces in ggplot2 (here), this time I’ll briefly discuss how to set colour scales in ggplot2 globally in an .Rmd file.
The perk of setting scales globally is that you can set the colours once at the beginning of the .Rmd file and all the plots in the file will adhere to the specified scales without the need to repeat code.
Set ggplot2 options The most robust way of specifying global colour scales for ggplot2 plots is to set the appropriate ggplot2 options with options() at the beginning of the .</description>
    </item>
    
    <item>
      <title>How to use custom typefaces in ggplot2 [macOS only]</title>
      <link>https://stefanocoretta.github.io/post/custom-fonts-ggplot2/</link>
      <pubDate>Mon, 21 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/custom-fonts-ggplot2/</guid>
      <description>I keep hitting my head against this particular (and seemingly simple) task: using custom typefaces in ggplot2 plots and being able to knit to PDF.
The main reason for why I would want to do that is that I often find myself in need of including IPA symbols in plots (more often than not, it’s vowels) and that I want those plots to be included in a knitted PDF.</description>
    </item>
    
    <item>
      <title>Plotting prior distributions with ggplot2</title>
      <link>https://stefanocoretta.github.io/post/priors-ggplot2/</link>
      <pubDate>Mon, 17 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/priors-ggplot2/</guid>
      <description>The choice of priors is a fundamental step of the Bayesian inference process. Vasishth et al. (2018) recommend plotting the chosen priors to see if they are reasonable.
In this post I will show how to easily plot prior distributions in ggplot2 (which is part of the tidyverse).
Let’s load the tidyverse first.
library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ── ## ✔ ggplot2 3.4.0 ✔ purrr 1.0.1 ## ✔ tibble 3.</description>
    </item>
    
    <item>
      <title>An estimate of number of speakers per study in phonetics</title>
      <link>https://stefanocoretta.github.io/post/speakers-per-study/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/speakers-per-study/</guid>
      <description>A few weeks ago, I’ve asked on Twitter what people thought was the average number of participants used in phonetic studies. Here’s the tweet.
Does anyone have an estimate of the average number of participants/tokens per context of recently published phonetic studies (let&#39;s say from the last 10 years)? #OpenScience #phonetics #replication — Stefano Coretta (@StefanoCoretta) April 12, 2019 Thankfully, Timo Roettger has pointed me to a dataset he and Matthew Gordon created for a study on the acoustic correlates of word stress, and he suggested to look at how the median number of speakers changed (or not) through the years.</description>
    </item>
    
    <item>
      <title>Literate programming with Praat</title>
      <link>https://stefanocoretta.github.io/post/literate-programming-with-praat/</link>
      <pubDate>Thu, 21 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/literate-programming-with-praat/</guid>
      <description>This post quickly illustrates how to apply a literate programming workflow to Praat scripting. To be able to reproduce the steps described here you need the latest version of pandoc and the Literate Markdown Tangler (lmt, you will need to install Go first to install lmt).
What is literate programming? In literate programming, one writes both code and plain text which explains what the code does in a single document.</description>
    </item>
    
  </channel>
</rss>
