<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>On phonologisation | Stefano Coretta</title>

<meta name="keywords" content="phonology, concepts" />
<meta name="description" content="After the post on the definition of random effects, I thought about writing another one on the definition of phonologisation.
As part of my PhD thesis on the effect of consonant voicing on vowel duration, I briefly reviewed the five definitions of phonologisation I could find in the literature. This post includes text from my thesis and expands on a few points.
The main take-away of the sections to follow is that what one means with phonologisation is (unsurprisingly) dependent on the set of assumptions that are part of the framework within which the term is used.">
<meta name="author" content="Stefano Coretta">
<link rel="canonical" href="https://stefanocoretta.github.io/post/2021-04-24-on-phonologisation/" />
<link href="/assets/css/stylesheet.min.a31c75ee58abbdfa57a7c3ce443a8651fe82bb20fcdb7c710d6200a7094b5ce4.css" integrity="sha256-oxx17lirvfpXp8PORDqGUf6CuyD823xxDWIApwlLXOQ=" rel="preload stylesheet"
    as="style">

<link rel="icon" href="https://stefanocoretta.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://stefanocoretta.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://stefanocoretta.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://stefanocoretta.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://stefanocoretta.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.86.0" />




<script src="https://kit.fontawesome.com/0019a3da9c.js" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">


<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?family=Alegreya+Sans+SC:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">


<link rel="stylesheet" href="/leaflet/leaflet.css"/>
<script src="/leaflet/leaflet.js"></script>
<link rel="stylesheet" href="/Leaflet.awesome-markers-2.0-develop/dist/leaflet.awesome-markers.css">
<script src="/Leaflet.awesome-markers-2.0-develop/dist/leaflet.awesome-markers.js"></script>
<meta property="og:title" content="On phonologisation" />
<meta property="og:description" content="After the post on the definition of random effects, I thought about writing another one on the definition of phonologisation.
As part of my PhD thesis on the effect of consonant voicing on vowel duration, I briefly reviewed the five definitions of phonologisation I could find in the literature. This post includes text from my thesis and expands on a few points.
The main take-away of the sections to follow is that what one means with phonologisation is (unsurprisingly) dependent on the set of assumptions that are part of the framework within which the term is used." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://stefanocoretta.github.io/post/2021-04-24-on-phonologisation/" />
<meta property="og:image" content="https://stefanocoretta.github.io/img/twitter-card-phonologisation.png" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-04-24T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2021-04-24T00:00:00&#43;00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://stefanocoretta.github.io/img/twitter-card-phonologisation.png" />
<meta name="twitter:title" content="On phonologisation"/>
<meta name="twitter:description" content="After the post on the definition of random effects, I thought about writing another one on the definition of phonologisation.
As part of my PhD thesis on the effect of consonant voicing on vowel duration, I briefly reviewed the five definitions of phonologisation I could find in the literature. This post includes text from my thesis and expands on a few points.
The main take-away of the sections to follow is that what one means with phonologisation is (unsurprisingly) dependent on the set of assumptions that are part of the framework within which the term is used."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://stefanocoretta.github.io/post/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "On phonologisation",
      "item": "https://stefanocoretta.github.io/post/2021-04-24-on-phonologisation/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "On phonologisation",
  "name": "On phonologisation",
  "description": "After the post on the definition of random effects, I thought about writing another one on the definition of phonologisation.\nAs part of my PhD thesis on the effect of consonant voicing on vowel duration, I briefly reviewed the five definitions of phonologisation I could find in the literature. This post includes text from my thesis and expands on a few points.\nThe main take-away of the sections to follow is that what one means with phonologisation is (unsurprisingly) dependent on the set of assumptions that are part of the framework within which the term is used.",
  "keywords": [
    "phonology", "concepts"
  ],
  "articleBody": "  After the post on the definition of random effects, I thought about writing another one on the definition of phonologisation.\nAs part of my PhD thesis on the effect of consonant voicing on vowel duration, I briefly reviewed the five definitions of phonologisation I could find in the literature. This post includes text from my thesis and expands on a few points.\nThe main take-away of the sections to follow is that what one means with phonologisation is (unsurprisingly) dependent on the set of assumptions that are part of the framework within which the term is used. Secondly, these definitions are mutually exclusive, to an extent such that one’s argument based on one definition might be inappropriate under another definition. It is thus important to always contextualise the use of the term when employed, even when the meaning might be self-evident from the context.\n1 Five definitions of phonologisation I could identify at least five different definitions of phonologisation (but there are surely more). These differ substantially, as mentioned above, and are in the most part incompatible with one another. The five definitions are found within the following general phonological frameworks:\n Structuralism (i.e. classical/traditional phonology). Lexical Phonology. Stratal Optimality Theory. Life-Cycle of Phonological Processes (an extension of Stratal OT). Exemplar-based models.  I will discuss each of these in turn.\n 2 Structuralism The classical or structuralist definition states that phonologisation occurs when a contextual allophone becomes contrastive, or in other words it becomes a phoneme (Kiparsky 2015), generally after the disappearance or replacement of the conditioning context.\nA classical example of phonologisation concerns the development of a contrast between velar and palatal consonants from velar consonants in Sanskrit (Hock 1991, 149). At some point in the history of Sanskrit, the velar stops /k/ and /g/ (which derived from PIE velars and labialised velars) where palatalised when followed by /i/ and /e/, creating an allophonic distinction between velars proper and palatal consonants.\nThe subsequent change of /e/ (and /o/) to /a/ removed the context conditioning palatalisation (the front vowel /e/), thus creating minimal pairs opposing /ka, ga/ and /tʃa, dʒa/. At this stage, the palatal allophones were phonologised.\n  sound change phonemic phonetic     /ka, ke/ [ka, ke]  palatalisation /ka, ke/ [ka, tʃe]  /e/  /a/ /ka, tʃa/ [ka, tʃa]    The IE roots for ‘what’ and ‘and’ illustrate the phonologisation of the palatal consonants.\n PIE *kʷod  Skt. /kad/ kád ‘what’ (cf. Lat. quod). PIE *-kʷe  Skt. /ke/ [tʃe]  /tʃa/ -ca ‘and’ (cf. Lat. -que).  This conceptualisation of phonologisation amounts to saying that phonetic features that were previously computed procedurally (during phonological/phonetic derivation) from an underlying lexical representation are now instead already part of the lexical representation (which is, in structural terms, a string of phonemes/features/elements).\n 3 Lexical Phonology Phonologisation assumes a different meaning within the framework of Lexical Phonology (Kiparsky 1988). Lexical Phonology argues that there exist two types of phonological processes: processes that apply at the lexical level (stem and prosodic word), and processes that are post-lexical and apply across the board.1 According to the view of Lexical Phonology, a process is phonologised when it goes from being post-lexical to being lexical.\nTo carry on with the Sanskrit example, palatalisation was initially post-lexical, in other words it was applied across the board during the phonological derivation process after all lexical processes have been applied to the stem and then word. At some point in the history of Sanskrit, the process of velar palatalisation started being applied also at the lexical level (with the original “copy” of the process possibly still being applied post-lexically). Velar palatalisation has been phonologised, creating so called “quasi-phonemes” (i.e. categorical, distinctive units, not yet able to create lexical contrast, Janda 1999).\n 4 Stratal Optimality Theory Kiparsky (2000) borrows the definition of phonologisation from Lexical Phonology and applies it to Stratal Optimality Theory (Kiparsky 2000; Bermúdez-Otero 2017).\nStratal OT assumes that the phonological module of the grammar is divided into three levels (called strata, or domains) as in Lexical Phonology: the stem, the word, and the phrasal level.\nOT constraints, in Stratal OT, are independently ordered in each level, so that within each level different orders allow for different outputs to be selected. Stratal OT also stipulates that phonological constraints apply iteratively (cyclically) from the narrower domain, namely the stem, through the word domain, to the phrasal domain. Under cyclicity, the output of one domain is passed over as input to the next, and so on.\nFor Kiparsky (2000), phonologisation occurs when the constraint ordering of the phrasal domain (the post-lexical level of Lexical Phonology) is copied over to the word and stem domains (the lexical level of Lexical Phonology).\n 5 Life-Cycle of Phonological Processes An extension of Stratal OT, the Life-Cycle of Phonological Processes (Bermúdez-Otero 2007, 2015), offers yet another definition of phonologisation and a more fine-grained terminological set. Bermúdez-Otero (2015) reserves the term phonologisation for when a physio-physiological (mechanic) phenomenon comes under the control of the speaker/hearer and becomes part of their grammar (more specifically, part of the phonetic module of the grammar).\nThe process, once it has entered the grammar, can further ascend through increasingly deeper grammatical modules. A (gradient) phonologised process is said to be stabilised (and thus categorical) once it is generated by a categorical phonological process, which applies at the phrase level. At this stage, a stabilised process has entered the phonological module of the speaker/hearer.\nA stabilised process further undergoes domain narrowing when it starts being applied at the word level and then at the stem level. In the final step in the ascent of a sound pattern through the grammar, a phonological process comes under morphological and lexical control, until “it may die altogether, leaving behind no more than inert traces in underlying representations” (Bermúdez-Otero 2015, 12).\n 6 Exemplar Theory A further definition of phonologisation comes from exemplar models of speech perception and production (Johnson 1997; Pierrehumbert 2001; Sóskuthy et al. 2018; Ambridge 2018; Todd, Pierrehumbert, and Hay 2019).\nA core tenet of these models is that speech tokens are stored in memory as so-called exemplars after having being experienced. Depending on the specifics of the particular model, exemplars are stored at varying degrees of granularity and richness of detail.\nEach exemplar consists of a (more or less) faithful representation of the experienced token that generated it, and it thus contains information from multiple levels and factors (phonetic, lexical, syntactic, sociolinguistic, contextual, and so on). Lexical and other linguistic units are represented as sets of exemplars, or exemplar clouds. The representational space of exemplar clouds is multi-dimensional and can be operationalised as a multivariate distribution (i.e. a joint distribution of multiple variables).\nIn modular approaches to grammar as briefly expounded above, sound alternations can be encoded (in terms of derivational rules and/or constraints) either at the phonological level or at the phonetic level of representation.\nOn the other hand, as Sóskuthy (2013), pp. 183 illustrates, in exemplar-based models all sound alternations are directly encoded by exemplars within the exemplar cloud, at one single level of representation. As soon as an exemplar with new phonetic characteristics is experienced and stored, the representation of that lexical item already contains information about the sound alternation. In this sense, every type of variation is phonologised (i.e. represented) from the outset as soon as it is experienced by the speaker/hearer and stored in memory.\nReferences Ambridge, Ben. 2018. “Against Stored Abstractions: A Radical Exemplar Model of Language Acquisition.” Pre-print available at PsyArXiv. https://doi.org/10.2139/ssrn.3219847.  Bermúdez-Otero, Ricardo. 2007. “Diachronic Phonology.” In The Cambridge Handbook of Phonology, 517. Cambridge: Cambridge University Press. https://doi.org/10.1017/CBO9780511486371.022.  ———. 2015. “Amphichronic Explanation and the Life Cycle of Phonological Processes.” In The Oxford Handbook of Historical Phonology, 374–99. Oxford: Oxford University Press.  ———. 2017. “Stratal Phonology.” In The Routledge Handbook of Phonological Theory, edited by S. J. Hannahs and Anna R. K. Bosch, 100–134. Routledge. https://doi.org/10.4324/9781315675428-5.  Hock, Hans Henrich. 1991. Principles of Historical Linguistics. Berlin: Mouton de Gruyter. https://doi.org/10.1515/9783110871975.  Janda, Richard D. 1999. “Accounts of Phonemic Split Have Been Greatly Exaggerated—but Not Enough.” In Proceedings of the 14th International Congress of Phonetic Sciences, 14:329–32.  Johnson, Keith. 1997. “Speech Perception Without Speaker Normalization: An Exemplar Model.” In Talker Variability in Speech Processing, edited by Keith Johnson and John W. Mullenix, 145–65. San Diego, CA: Academic Press.  Kiparsky, Paul. 1988. “Phonological Change.” In Linguistics: The Cambridge Survey, edited by Frederick J. Newmeyer, 1 Linguistic theory: foundations:363–415. Cambridge: Cambridge University Press.  ———. 2000. “Opacity and Cyclicity.” The Linguistic Review 17 (2-4): 351–66. https://doi.org/10.1515/tlir.2000.17.2-4.351.  ———. 2015. “Phonologization.” In The Oxford Handbook of Historical Phonology. 563–579: Oxford: Oxford University Press.  Pierrehumbert, Janet B. 2001. “Exemplar Dynamics: Word Frequency, Lenition and Contrast.” In Frequency and the Emergence of Linguistic Structure, edited by Joan L. Bybee and Paul J. Hopper, 137–57. Amsterdam Philadelphia: John Benjamins Publishing Company. https://doi.org/10.1075/tsl.45.08pie.  Sóskuthy, Márton. 2013. “Phonetic Biases and Systemic Effects in the Actuation of Sound Change.” PhD thesis, Edinburgh: University of Edinburgh.  Sóskuthy, Márton, Paul Foulkes, Vincent Hughes, and Bill Haddican. 2018. “Changing Words and Sounds: The Roles of Different Cognitive Units in Sound Change.” Topics in Cognitive Science 10 (4): 1–16. https://doi.org/10.1111/tops.12346.  Todd, Simon, Janet B. Pierrehumbert, and Jennifer Hay. 2019. “Word Frequency Effects in Sound Change as a Consequence of Perceptual Asymmetries: An Exemplar-Based Model.” Cognition 185: 1–20. https://doi.org/10.1016/j.cognition.2019.01.004.      Note that in generative phonology, of which Lexical Phonology is a strand, speakers are assumed to store abstract, underlying phonemic forms, or representations, in memory. These underlying forms, to be produced, go through a series of neuro-cognitive processes, or derivation, that generate a surface representation which is then sent to the motor system which executes the motor plan corresponding to that surface representation. The details widely vary depending on the model or framework.↩︎\n   ",
  "wordCount" : "1610",
  "inLanguage": "en",
  "image":"https://stefanocoretta.github.io/img/twitter-card-phonologisation.png","datePublished": "2021-04-24T00:00:00Z",
  "dateModified": "2021-04-24T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Stefano Coretta"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://stefanocoretta.github.io/post/2021-04-24-on-phonologisation/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Stefano Coretta",
    "logo": {
      "@type": "ImageObject",
      "url": "https://stefanocoretta.github.io/favicon.ico"
    }
  }
}
</script>





</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<noscript>
    <style type="text/css">
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: #1d1e20;
                --entry: #2e2e33;
                --primary: rgba(255, 255, 255, 0.84);
                --secondary: rgba(255, 255, 255, 0.56);
                --tertiary: rgba(255, 255, 255, 0.16);
                --content: rgba(255, 255, 255, 0.74);
                --hljs-bg: #2e2e33;
                --code-bg: #37383e;
                --border: #333;
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }
    </style>

</noscript>
<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://stefanocoretta.github.io" accesskey="h" title="Stefano Coretta (Alt + H)">Stefano Coretta</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                
                
            </span>
        </div>
        <ul id="menu" onscroll="menu_on_scroll()">
            <li>
                <a href="https://stefanocoretta.github.io" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://stefanocoretta.github.io/research/" title="Research">
                    <span>Research</span>
                </a>
            </li>
            <li>
                <a href="https://stefanocoretta.github.io/meta/" title="Meta">
                    <span>Meta</span>
                </a>
            </li>
            <li>
                <a href="https://stefanocoretta.github.io/output/" title="Output">
                    <span>Output</span>
                </a>
            </li>
            <li>
                <a href="https://stefanocoretta.github.io/workshops/" title="Workshops">
                    <span>Workshops</span>
                </a>
            </li>
            <li>
                <a href="https://stefanocoretta.github.io/archives/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://stefanocoretta.github.io/docs/CorettaCV.pdf" title="CV">
                    <span>CV</span>
                </a>
            </li></ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">

    <h1 class="post-title">
      On phonologisation
    </h1>
    <div class="post-meta">

April 24, 2021&nbsp;·&nbsp;8 min&nbsp;·&nbsp;Stefano Coretta


</div>
  </header> 
<div id="images"><img class="streami" border="0" src="https://stefanocoretta.github.io/img/twitter-card-phonologisation.png" alt="Schematics of a typical case of phonologisation of palatalised velars">
        
</div>

  <div class="post-content">

<script src="https://stefanocoretta.github.io/post/2021-04-24-on-phonologisation/index_files/header-attrs/header-attrs.js"></script>


<!-- NOTE: Add that it is a diachronic process -->
<p>After the <a href="../2021-03-15-on-random-effects/">post</a> on the definition of random effects, I thought about writing another one on the definition of <span class="smallcaps">phonologisation</span>.</p>
<p>As part of my <a href="https://stefanocoretta.github.io/phd-dissertation/s-ve.html#s:ve-phonologise">PhD thesis</a> on the effect of consonant voicing on vowel duration, I briefly reviewed the five definitions of phonologisation I could find in the literature.
This post includes text from my thesis and expands on a few points.</p>
<p>The main take-away of the sections to follow is that what one means with phonologisation is (unsurprisingly) dependent on the set of assumptions that are part of the framework within which the term is used.
Secondly, these definitions are mutually exclusive, to an extent such that one’s argument based on one definition might be inappropriate under another definition.
It is thus important to always contextualise the use of the term when employed, even when the meaning might be self-evident from the context.</p>
<div id="five-definitions-of-phonologisation" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Five definitions of phonologisation</h1>
<p>I could identify at least five different definitions of phonologisation (but there are surely more).
These differ substantially, as mentioned above, and are in the most part incompatible with one another.
The five definitions are found within the following general phonological frameworks:</p>
<ul>
<li>Structuralism (i.e. classical/traditional phonology).</li>
<li>Lexical Phonology.</li>
<li>Stratal Optimality Theory.</li>
<li>Life-Cycle of Phonological Processes (an extension of Stratal OT).</li>
<li>Exemplar-based models.</li>
</ul>
<p>I will discuss each of these in turn.</p>
</div>
<div id="structuralism" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Structuralism</h1>
<p>The <strong>classical</strong> or <strong>structuralist</strong> definition states that <strong><em>phonologisation</em> occurs when a contextual allophone becomes contrastive</strong>, or in other words it becomes a phoneme <span class="citation">(<a href="#ref-kiparsky2015" role="doc-biblioref">Kiparsky 2015</a>)</span>, generally after the disappearance or replacement of the conditioning context.</p>
<p>A classical example of phonologisation concerns the development of a contrast between velar and palatal consonants from velar consonants in Sanskrit <span class="citation">(<a href="#ref-hock1991" role="doc-biblioref">Hock 1991, 149</a>)</span>.
At some point in the history of Sanskrit, the velar stops /k/ and /g/ (which derived from PIE velars and labialised velars) where palatalised when followed by /i/ and /e/, creating an allophonic distinction between velars proper and palatal consonants.</p>
<p>The subsequent change of /e/ (and /o/) to /a/ removed the context conditioning palatalisation (the front vowel /e/), thus creating minimal pairs opposing /ka, ga/ and /tʃa, dʒa/.
At this stage, the palatal allophones were phonologised.</p>
<table>
<thead>
<tr class="header">
<th>sound change</th>
<th>phonemic</th>
<th>phonetic</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>/ka, ke/</td>
<td>[ka, ke]</td>
</tr>
<tr class="even">
<td>palatalisation</td>
<td>/ka, ke/</td>
<td>[ka, tʃe]</td>
</tr>
<tr class="odd">
<td>/e/ &gt; /a/</td>
<td>/ka, tʃa/</td>
<td>[ka, tʃa]</td>
</tr>
</tbody>
</table>
<p>The IE roots for ‘what’ and ‘and’ illustrate the phonologisation of the palatal consonants.</p>
<ul>
<li>PIE *<em>kʷod</em> &gt; Skt. /kad/ <em>kád</em> ‘what’ (cf. Lat. <em>quod</em>).</li>
<li>PIE *-<em>kʷe</em> &gt; Skt. /ke/ [tʃe] &gt; /tʃa/ -<em>ca</em> ‘and’ (cf. Lat. <em>-que</em>).</li>
</ul>
<p>This conceptualisation of phonologisation amounts to saying that phonetic features that were previously computed procedurally (during phonological/phonetic derivation) from an underlying lexical representation are now instead already part of the lexical representation (which is, in structural terms, a string of phonemes/features/elements).</p>
</div>
<div id="lexical-phonology" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Lexical Phonology</h1>
<p>Phonologisation assumes a different meaning within the framework of <strong>Lexical Phonology</strong> <span class="citation">(<a href="#ref-kiparsky1988" role="doc-biblioref">Kiparsky 1988</a>)</span>.
Lexical Phonology argues that there exist two types of phonological processes: processes that apply at the lexical level (stem and prosodic word), and processes that are post-lexical and apply across the board.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>
According to the view of Lexical Phonology, <strong>a process is <em>phonologised</em> when it goes from being post-lexical to being lexical</strong>.</p>
<p>To carry on with the Sanskrit example, palatalisation was initially post-lexical, in other words it was applied across the board during the phonological derivation process after all lexical processes have been applied to the stem and then word.
At some point in the history of Sanskrit, the process of velar palatalisation started being applied also at the lexical level (with the original “copy” of the process possibly still being applied post-lexically).
Velar palatalisation has been phonologised, creating so called “quasi-phonemes” <span class="citation">(i.e. categorical, distinctive units, not yet able to create lexical contrast, <a href="#ref-janda1999" role="doc-biblioref">Janda 1999</a>)</span>.</p>
</div>
<div id="stratal-optimality-theory" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Stratal Optimality Theory</h1>
<p><span class="citation"><a href="#ref-kiparsky2000" role="doc-biblioref">Kiparsky</a> (<a href="#ref-kiparsky2000" role="doc-biblioref">2000</a>)</span> borrows the definition of phonologisation from Lexical Phonology and applies it to <strong>Stratal Optimality Theory</strong> <span class="citation">(<a href="#ref-kiparsky2000" role="doc-biblioref">Kiparsky 2000</a>; <a href="#ref-bermudezotero2017" role="doc-biblioref">Bermúdez-Otero 2017</a>)</span>.</p>
<p>Stratal OT assumes that the <span class="smallcaps">phonological module of the grammar</span> is divided into three levels (called strata, or domains) as in Lexical Phonology: the <span class="smallcaps">stem</span>, the <span class="smallcaps">word</span>, and the <span class="smallcaps">phrasal</span> level.</p>
<p>OT constraints, in Stratal OT, are independently ordered in each level, so that within each level different orders allow for different outputs to be selected.
Stratal OT also stipulates that phonological constraints apply iteratively (cyclically) from the narrower domain, namely the stem, through the word domain, to the phrasal domain.
Under cyclicity, the output of one domain is passed over as input to the next, and so on.</p>
<p>For <span class="citation"><a href="#ref-kiparsky2000" role="doc-biblioref">Kiparsky</a> (<a href="#ref-kiparsky2000" role="doc-biblioref">2000</a>)</span>, <strong><em>phonologisation</em> occurs when the constraint ordering of the phrasal domain (the post-lexical level of Lexical Phonology) is copied over to the word and stem domains (the lexical level of Lexical Phonology)</strong>.</p>
</div>
<div id="life-cycle-of-phonological-processes" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Life-Cycle of Phonological Processes</h1>
<p>An extension of Stratal OT, the <strong>Life-Cycle of Phonological Processes</strong> <span class="citation">(<a href="#ref-bermudezotero2007" role="doc-biblioref">Bermúdez-Otero 2007</a>, <a href="#ref-bermudezotero2015" role="doc-biblioref">2015</a>)</span>, offers yet another definition of phonologisation and a more fine-grained terminological set.
<span class="citation"><a href="#ref-bermudezotero2015" role="doc-biblioref">Bermúdez-Otero</a> (<a href="#ref-bermudezotero2015" role="doc-biblioref">2015</a>)</span> reserves the term <strong><em>phonologisation</em> for when a physio-physiological (mechanic) phenomenon comes under the control of the speaker/hearer</strong> and becomes part of their grammar (more specifically, part of the phonetic module of the grammar).</p>
<p>The process, once it has entered the grammar, can further ascend through increasingly deeper grammatical modules.
A (gradient) phonologised process is said to be <span class="smallcaps">stabilised</span> (and thus categorical) once it is generated by a categorical phonological process, which applies at the phrase level.
At this stage, a stabilised process has entered the phonological module of the speaker/hearer.</p>
<p>A stabilised process further undergoes <span class="smallcaps">domain narrowing</span> when it starts being applied at the word level and then at the stem level.
In the final step in the ascent of a sound pattern through the grammar, a phonological process comes under morphological and lexical control, until “it may die altogether, leaving behind no more than inert traces in underlying representations” <span class="citation">(<a href="#ref-bermudezotero2015" role="doc-biblioref">Bermúdez-Otero 2015, 12</a>)</span>.</p>
</div>
<div id="exemplar-theory" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Exemplar Theory</h1>
<p>A further definition of phonologisation comes from <strong>exemplar models of speech perception and production</strong> <span class="citation">(<a href="#ref-johnson1997" role="doc-biblioref">Johnson 1997</a>; <a href="#ref-pierrehumbert2001" role="doc-biblioref">Pierrehumbert 2001</a>; <a href="#ref-soskuthy2018" role="doc-biblioref">Sóskuthy et al. 2018</a>; <a href="#ref-ambridge2018" role="doc-biblioref">Ambridge 2018</a>; <a href="#ref-todd2019" role="doc-biblioref">Todd, Pierrehumbert, and Hay 2019</a>)</span>.</p>
<p>A core tenet of these models is that speech tokens are stored in memory as so-called <span class="smallcaps">exemplars</span> after having being experienced.
Depending on the specifics of the particular model, exemplars are stored at varying degrees of granularity and richness of detail.</p>
<p>Each exemplar consists of a (more or less) faithful representation of the experienced token that generated it, and it thus contains information from multiple levels and factors (phonetic, lexical, syntactic, sociolinguistic, contextual, and so on).
Lexical and other linguistic units are represented as sets of exemplars, or <span class="smallcaps">exemplar clouds</span>.
The representational space of exemplar clouds is multi-dimensional and can be operationalised as a multivariate distribution (i.e. a joint distribution of multiple variables).</p>
<p>In modular approaches to grammar as briefly expounded above, sound alternations can be encoded (in terms of derivational rules and/or constraints) either at the phonological level or at the phonetic level of representation.</p>
<p>On the other hand, as <span class="citation"><a href="#ref-soskuthy2013" role="doc-biblioref">Sóskuthy</a> (<a href="#ref-soskuthy2013" role="doc-biblioref">2013</a>)</span>, pp. 183 illustrates, in exemplar-based models all sound alternations are directly encoded by exemplars within the exemplar cloud, at one single level of representation.
As soon as an exemplar with new phonetic characteristics is experienced <em>and</em> stored, the representation of that lexical item already contains information about the sound alternation.
In this sense, <strong>every type of variation is <em>phonologised</em> (i.e. represented) from the outset as soon as it is experienced by the speaker/hearer and stored in memory</strong>.</p>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-ambridge2018" class="csl-entry">
Ambridge, Ben. 2018. <span>“Against Stored Abstractions: A Radical Exemplar Model of Language Acquisition.”</span> Pre-print available at PsyArXiv. <a href="https://doi.org/10.2139/ssrn.3219847">https://doi.org/10.2139/ssrn.3219847</a>.
</div>
<div id="ref-bermudezotero2007" class="csl-entry">
Bermúdez-Otero, Ricardo. 2007. <span>“Diachronic Phonology.”</span> In <em>The Cambridge Handbook of Phonology</em>, 517. Cambridge: Cambridge University Press. <a href="https://doi.org/10.1017/CBO9780511486371.022">https://doi.org/10.1017/CBO9780511486371.022</a>.
</div>
<div id="ref-bermudezotero2015" class="csl-entry">
———. 2015. <span>“Amphichronic Explanation and the Life Cycle of Phonological Processes.”</span> In <em>The Oxford Handbook of Historical Phonology</em>, 374–99. Oxford: Oxford University Press.
</div>
<div id="ref-bermudezotero2017" class="csl-entry">
———. 2017. <span>“Stratal Phonology.”</span> In <em>The Routledge Handbook of Phonological Theory</em>, edited by S. J. Hannahs and Anna R. K. Bosch, 100–134. Routledge. <a href="https://doi.org/10.4324/9781315675428-5">https://doi.org/10.4324/9781315675428-5</a>.
</div>
<div id="ref-hock1991" class="csl-entry">
Hock, Hans Henrich. 1991. <em>Principles of Historical Linguistics</em>. Berlin: Mouton de Gruyter. <a href="https://doi.org/10.1515/9783110871975">https://doi.org/10.1515/9783110871975</a>.
</div>
<div id="ref-janda1999" class="csl-entry">
Janda, Richard D. 1999. <span>“Accounts of Phonemic Split Have Been Greatly Exaggerated—but Not Enough.”</span> In <em>Proceedings of the 14th International Congress of Phonetic Sciences</em>, 14:329–32.
</div>
<div id="ref-johnson1997" class="csl-entry">
Johnson, Keith. 1997. <span>“Speech Perception Without Speaker Normalization: An Exemplar Model.”</span> In <em>Talker Variability in Speech Processing</em>, edited by Keith Johnson and John W. Mullenix, 145–65. San Diego, CA: Academic Press.
</div>
<div id="ref-kiparsky1988" class="csl-entry">
Kiparsky, Paul. 1988. <span>“Phonological Change.”</span> In <em>Linguistics: The Cambridge Survey</em>, edited by Frederick J. Newmeyer, 1 Linguistic theory: foundations:363–415. Cambridge: Cambridge University Press.
</div>
<div id="ref-kiparsky2000" class="csl-entry">
———. 2000. <span>“Opacity and Cyclicity.”</span> <em>The Linguistic Review</em> 17 (2-4): 351–66. <a href="https://doi.org/10.1515/tlir.2000.17.2-4.351">https://doi.org/10.1515/tlir.2000.17.2-4.351</a>.
</div>
<div id="ref-kiparsky2015" class="csl-entry">
———. 2015. <span>“Phonologization.”</span> In <em>The Oxford Handbook of Historical Phonology</em>. 563–579: Oxford: Oxford University Press.
</div>
<div id="ref-pierrehumbert2001" class="csl-entry">
Pierrehumbert, Janet B. 2001. <span>“Exemplar Dynamics: Word Frequency, Lenition and Contrast.”</span> In <em>Frequency and the Emergence of Linguistic Structure</em>, edited by Joan L. Bybee and Paul J. Hopper, 137–57. Amsterdam Philadelphia: John Benjamins Publishing Company. <a href="https://doi.org/10.1075/tsl.45.08pie">https://doi.org/10.1075/tsl.45.08pie</a>.
</div>
<div id="ref-soskuthy2013" class="csl-entry">
Sóskuthy, Márton. 2013. <span>“Phonetic Biases and Systemic Effects in the Actuation of Sound Change.”</span> PhD thesis, Edinburgh: University of Edinburgh.
</div>
<div id="ref-soskuthy2018" class="csl-entry">
Sóskuthy, Márton, Paul Foulkes, Vincent Hughes, and Bill Haddican. 2018. <span>“Changing Words and Sounds: The Roles of Different Cognitive Units in Sound Change.”</span> <em>Topics in Cognitive Science</em> 10 (4): 1–16. <a href="https://doi.org/10.1111/tops.12346">https://doi.org/10.1111/tops.12346</a>.
</div>
<div id="ref-todd2019" class="csl-entry">
Todd, Simon, Janet B. Pierrehumbert, and Jennifer Hay. 2019. <span>“Word Frequency Effects in Sound Change as a Consequence of Perceptual Asymmetries: An Exemplar-Based Model.”</span> <em>Cognition</em> 185: 1–20. <a href="https://doi.org/10.1016/j.cognition.2019.01.004">https://doi.org/10.1016/j.cognition.2019.01.004</a>.
</div>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Note that in generative phonology, of which Lexical Phonology is a strand, speakers are assumed to store abstract, underlying phonemic forms, or representations, in memory. These underlying forms, to be produced, go through a series of neuro-cognitive processes, or derivation, that generate a surface representation which is then sent to the motor system which executes the motor plan corresponding to that surface representation. The details widely vary depending on the model or framework.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>

</div>
  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://stefanocoretta.github.io/tags/phonology/">phonology</a></li>
      <li><a href="https://stefanocoretta.github.io/tags/concepts/">concepts</a></li>
    </ul>
  </footer>
</article>
    </main><footer class="footer">
    <span>&copy; 2021 <a href="https://stefanocoretta.github.io">Stefano Coretta</a></span>
    <span>&middot;</span>
    <span>Powered by <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a></span>
    <span>&middot;</span>
    <span>Theme <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a></span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)">
    <button class="top-link" id="top-link" type="button" accesskey="g">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z" />
        </svg>
    </button>
</a>



<script defer src="/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js" integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5&#43;kdJvBz5iKbt6B5PJI="
    onload="hljs.initHighlightingOnLoad();"></script>
<script>
    window.onload = function () {
        if (localStorage.getItem("menu-scroll-position")) {
            document.getElementById('menu').scrollLeft = localStorage.getItem("menu-scroll-position");
        }
    }

    function menu_on_scroll() {
        localStorage.setItem("menu-scroll-position", document.getElementById('menu').scrollLeft);
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>

</body>

</html>
