<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Linear models: a cheat-sheet | Stefano Coretta</title>

<meta name="keywords" content="linear, regression, brms, lmer, gamm" />
<meta name="description" content="One model to rule them all Linear models, aka linear regression models or regression models, are a group of statistical models based on the simple idea that we can predict an outcome variable \(Y\) based on a function \(f(X)\).
The “simplest” linear model is the formula of a line:1
\[ y = \alpha &#43; \beta x \]
where \(\alpha\) is the intercept of the line and \(\beta\) the slope.">
<meta name="author" content="Stefano Coretta">
<link rel="canonical" href="https://stefanocoretta.github.io/post/2021-08-21-regression-models-a-cheat-sheet/" />
<link href="/assets/css/stylesheet.min.a31c75ee58abbdfa57a7c3ce443a8651fe82bb20fcdb7c710d6200a7094b5ce4.css" integrity="sha256-oxx17lirvfpXp8PORDqGUf6CuyD823xxDWIApwlLXOQ=" rel="preload stylesheet"
    as="style">

<link rel="icon" href="https://stefanocoretta.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://stefanocoretta.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://stefanocoretta.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://stefanocoretta.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://stefanocoretta.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.89.4" />


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>



<script src="https://kit.fontawesome.com/0019a3da9c.js" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">


<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?family=Alegreya+Sans+SC:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">


<link rel="stylesheet" href="/leaflet/leaflet.css"/>
<script src="/leaflet/leaflet.js"></script>
<link rel="stylesheet" href="/Leaflet.awesome-markers-2.0-develop/dist/leaflet.awesome-markers.css">
<script src="/Leaflet.awesome-markers-2.0-develop/dist/leaflet.awesome-markers.js"></script>
<meta property="og:title" content="Linear models: a cheat-sheet" />
<meta property="og:description" content="One model to rule them all Linear models, aka linear regression models or regression models, are a group of statistical models based on the simple idea that we can predict an outcome variable \(Y\) based on a function \(f(X)\).
The “simplest” linear model is the formula of a line:1
\[ y = \alpha &#43; \beta x \]
where \(\alpha\) is the intercept of the line and \(\beta\) the slope." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://stefanocoretta.github.io/post/2021-08-21-regression-models-a-cheat-sheet/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-08-21T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2021-08-21T00:00:00&#43;00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Linear models: a cheat-sheet"/>
<meta name="twitter:description" content="One model to rule them all Linear models, aka linear regression models or regression models, are a group of statistical models based on the simple idea that we can predict an outcome variable \(Y\) based on a function \(f(X)\).
The “simplest” linear model is the formula of a line:1
\[ y = \alpha &#43; \beta x \]
where \(\alpha\) is the intercept of the line and \(\beta\) the slope."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://stefanocoretta.github.io/post/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Linear models: a cheat-sheet",
      "item": "https://stefanocoretta.github.io/post/2021-08-21-regression-models-a-cheat-sheet/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Linear models: a cheat-sheet",
  "name": "Linear models: a cheat-sheet",
  "description": "One model to rule them all Linear models, aka linear regression models or regression models, are a group of statistical models based on the simple idea that we can predict an outcome variable \\(Y\\) based on a function \\(f(X)\\).\nThe “simplest” linear model is the formula of a line:1\n\\[ y = \\alpha + \\beta x \\]\nwhere \\(\\alpha\\) is the intercept of the line and \\(\\beta\\) the slope.",
  "keywords": [
    "linear", "regression", "brms", "lmer", "gamm"
  ],
  "articleBody": "  One model to rule them all Linear models, aka linear regression models or regression models, are a group of statistical models based on the simple idea that we can predict an outcome variable \\(Y\\) based on a function \\(f(X)\\).\nThe “simplest” linear model is the formula of a line:1\n\\[ y = \\alpha + \\beta x \\]\nwhere \\(\\alpha\\) is the intercept of the line and \\(\\beta\\) the slope.\nThe principles behind this formula can be extended to represent virtually any other model, independent of the nature of the outcome variable(s) (\\(y\\)), the predictor(s), the types of relationship between outcome and predictor, and so on.\nThis means that if you master the principles of linear models, then you can virtually fit any kind of data using linear models You can bid farewell to ANOVAs, \\(t\\)-tests, \\(\\chi^2\\)-tests, and what not. In fact, these can all be thought of as specific cases of linear models. It just so happens that they got themselves a specific name. But the underlying mechanics is the same.\nSame goes with “regressions”, “logistic regression”, “generalised linear models”, “mixed-effects regression” and so on. These are all linear models, so they all follow the same principles. And again, the fact that they got specific name is a historical “accident”.\nUnderstanding that these named models are in fact all linear models gives you super powers you can use on data (Sauron would be so jealous):\n One model to rule them all, one model to fit them,\nOne model to shrink them all, and in probability bind them;\nIn the Land of Inference where the distributions lie.\n Ehm… perhaps this is not gonna win a poetry context, but…\nThe message is that with a single tool, i.e. linear models, you can go a long way!\nEach of the following sections asks you about the nature of your data and/or experimental design. By answering each, you will find out which “pieces” you need to add to your model structure.\n(This is a work in progress, so still rough around the edges).\n Step 0: Number of outcome variables We will get back to this step at the end of this post, since it makes things a bit more complex.\n Step 1: Choose a distribution for your outcome variable The first step towards building a linear model is to choose the family of distributions you believe the outcome variable belongs to.\nYou can start by answering this question: is your outcome variable continuous or discrete?\nContinuous outcome variable  The variable can take on any positive and negative real number, including 0: Gaussian (aka normal) distribution.\n There are very few truly Gaussian variables, although in some cases one can speak of “approximate” or “assumed” normality.\n This family is fitted by default in lm(), lme4::lmer() and brms::brm().\n  The variable can take on any positive number only: Log-normal distribution.\n Duration of segments, words, pauses, etc, are known to be log-normally distributed.\n Measurements taken in Hz (like f0, formants, centre of gravity, …) could be considered to be log-normal.\n There other families that could potentially be used depending on the nature of the variable: exponential-Gaussian (reaction times), gamma, …\n  The variable can take on any number between 0 and 1, but not 0 nor 1: Beta distribution.\n Proportions fall into this category (for example proportion of voicing within closure), although 0 and 1 are not allowed in the beta distribution.  The variable can take on any number between 0 and 1, including 0 or 0 and 1: Zero-inflated or Zero/one-inflated beta (ZOIB) distribution.\n If the proportion data includes many 0s and 1s, then this is the ideal distribution to use. ZOIB distributions are somewhat more difficult to fit than a simple beta distribution, so a common practice is to transform the data so that it doesn’t include 0s nor 1s (this can be achieved using different techniques, some better than others).    Discrete outcome variable  The variable is dichotomous, i.e. it can take one of two levels: Bernoulli distribution.\n Categorical outcome variables like yes/no, correct/incorrect, voiced/voiceless, follow this distribution.\n This family is fitted by default when you run glm(family = binomial), aka “logistic regression” or “binomial regression”.\n  The variable is counts: Poisson distribution.\n Counts of words, segments, gestures, f0 peaks, …  The variable is a scale: ordinal linear model.\n Likert scales and ratings, language attitude questionnaires.\n Ordinal linear models, a.k.a. ordinal logistic regression, can be fitted with the ordinal and the brms package.\n     Step 2: Are there hierarchical groupings and/or repeated measures? The second step is to ensure that, if the data is structured hierarchically or repeated measures were taken, this is taken into account in the model. Here is where so-called “random effects” or “group-level effects/terms” come in.\nAs an example, let’s assume you asked a number of participants to read a list of words and each word was repeated 5 times by each participant. You then took f0 measurements from the stressed vowel of each word, of each repetition.\nNow, the data has a structure to it:\n First, observations are grouped by participant (some observations belong to one participant and others to another and so on). Second, observations are grouped by word (some observations belong to one word and others to another and so on). Third, within the observations of each word, some belong to the same participant (or, from a different perspective, within the observations of each participant, some belong to the same word).  The presence of “groupings” within the data (whether they come from natural groupings like participant or word, or from repeated measures) breaks one of the assumptions of linear models: that each observation must be independent.\nIf you don’t include any random effect/group-level terms, your model will expect that each observation is independent and hence it will underestimate variance and return unreliable results.\nIn the toy-example of f0 measurements, you will want to include group-level terms for participant and word. These will take care to let the model know of the structure of the data mentioned above.\nIf you have other predictors in the model, you should also add them as (random) slopes in the random effects/group-level terms. For example: (question | participant) + (question | word) (where question = statement vs question).\nA quick terminological note: models that include random effects/group-level terms are called:\n Random-effects models. Mixed-effects models. Hierarchical models. Nested models. Multilevel models.  These terms are for all intents and purposes equivalent (it just happens that different traditions uses different terms).\n Step 3: Are there non-linear effects? A typical use-case of non-linear terms is when you are dealing with time-series data or spatial data (i.e. geographic coordinates).\nGeneralised Additive Models allow you to fit non-linear effects using so called “smooth” (or “smoother”) terms.\nYou can fit a linear model with smooth terms with brms (simply add smooth terms to the formula) or with mgcv (using gam() or bam()), among others.\n Step 0-bis: Number of outcome variables If you want to model just one outcome variable, you are already covered if you went through steps 1-3.\nIf instead your design has two or more outcome variables (for example F1 and F2, or duration of the stressed and unstressed vowel of a word) then you want to fit a multivariate model (i.e. a model with multiple outcome variables*).\nThe same steps we went through before can be applied to multiple outcome variables. In some cases, you will want to use the same model structure for all the outcome variables, while in others you might want to use a different model structure for each.\nTo learn more about multivariate models, I really recommend Paul Bürkner’s vignette Estimating Multivariate Models with brms.\n  Technically, the “simplest” linear model is \\(y = f(x)\\), but oh well…↩︎\n   ",
  "wordCount" : "1279",
  "inLanguage": "en",
  "datePublished": "2021-08-21T00:00:00Z",
  "dateModified": "2021-08-21T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Stefano Coretta"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://stefanocoretta.github.io/post/2021-08-21-regression-models-a-cheat-sheet/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Stefano Coretta",
    "logo": {
      "@type": "ImageObject",
      "url": "https://stefanocoretta.github.io/favicon.ico"
    }
  }
}
</script>





</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<noscript>
    <style type="text/css">
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: #1d1e20;
                --entry: #2e2e33;
                --primary: rgba(255, 255, 255, 0.84);
                --secondary: rgba(255, 255, 255, 0.56);
                --tertiary: rgba(255, 255, 255, 0.16);
                --content: rgba(255, 255, 255, 0.74);
                --hljs-bg: #2e2e33;
                --code-bg: #37383e;
                --border: #333;
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }
    </style>

</noscript>
<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://stefanocoretta.github.io" accesskey="h" title="Stefano Coretta (Alt + H)">Stefano Coretta</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                
                
            </span>
        </div>
        <ul id="menu" onscroll="menu_on_scroll()">
            <li>
                <a href="https://stefanocoretta.github.io" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://stefanocoretta.github.io/research/" title="Research">
                    <span>Research</span>
                </a>
            </li>
            <li>
                <a href="https://stefanocoretta.github.io/meta/" title="Meta">
                    <span>Meta</span>
                </a>
            </li>
            <li>
                <a href="https://stefanocoretta.github.io/output/" title="Output">
                    <span>Output</span>
                </a>
            </li>
            <li>
                <a href="https://stefanocoretta.github.io/workshops/" title="Workshops">
                    <span>Workshops</span>
                </a>
            </li>
            <li>
                <a href="https://stefanocoretta.github.io/archives/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://stefanocoretta.github.io/docs/CorettaCV.pdf" title="CV">
                    <span>CV</span>
                </a>
            </li></ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">

    <h1 class="post-title">
      Linear models: a cheat-sheet
    </h1>
    <div class="post-meta">

August 21, 2021&nbsp;·&nbsp;7 min&nbsp;·&nbsp;Stefano Coretta


</div>
  </header> 

  <div class="post-content">

<script src="https://stefanocoretta.github.io/post/2021-08-21-regression-models-a-cheat-sheet/index_files/header-attrs/header-attrs.js"></script>


<div id="one-model-to-rule-them-all" class="section level1">
<h1>One model to rule them all</h1>
<p><strong>Linear models</strong>, aka linear regression models or regression models, are a group of statistical models based on the simple idea that we can predict an outcome variable <span class="math inline">\(Y\)</span> based on a function <span class="math inline">\(f(X)\)</span>.</p>
<p>The “simplest” linear model is the formula of a line:<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<p><span class="math display">\[
y = \alpha + \beta x
\]</span></p>
<p>where <span class="math inline">\(\alpha\)</span> is the <strong>intercept</strong> of the line and <span class="math inline">\(\beta\)</span> the <strong>slope</strong>.</p>
<p>The principles behind this formula can be extended to represent virtually any other model, independent of the nature of the outcome variable(s) (<span class="math inline">\(y\)</span>), the predictor(s), the types of relationship between outcome and predictor, and so on.</p>
<p><strong>This means that if you master the principles of linear models, then you can virtually fit any kind of data using linear models</strong>
You can bid farewell to ANOVAs, <span class="math inline">\(t\)</span>-tests, <span class="math inline">\(\chi^2\)</span>-tests, and what not.
In fact, these can all be thought of as specific cases of linear models.
It just so happens that they got themselves a specific name.
But the underlying mechanics is the same.</p>
<p>Same goes with “regressions”, “logistic regression”, “generalised linear models”, “mixed-effects regression” and so on.
These are all linear models, so they all follow the same principles.
And again, the fact that they got specific name is a historical “accident”.</p>
<p>Understanding that these named models are in fact all linear models gives you super powers you can use on data (Sauron would be so jealous):</p>
<blockquote>
<p>One model to rule them all, one model to fit them,<br />
One model to shrink them all, and in probability bind them;<br />
In the Land of Inference where the distributions lie.</p>
</blockquote>
<p>Ehm… perhaps this is not gonna win a poetry context, but…</p>
<p>The message is that with a single tool, i.e. linear models, you can go a long way!</p>
<p>Each of the following sections asks you about the nature of your data and/or experimental design.
By answering each, you will find out which “pieces” you need to add to your model structure.</p>
<p>(This is a work in progress, so still rough around the edges).</p>
</div>
<div id="step-0-number-of-outcome-variables" class="section level1">
<h1>Step 0: Number of outcome variables</h1>
<p>We will get back to this step at the end of this post, since it makes things a bit more complex.</p>
</div>
<div id="step-1-choose-a-distribution-for-your-outcome-variable" class="section level1">
<h1>Step 1: Choose a distribution for your outcome variable</h1>
<p>The first step towards building a linear model is to choose the <strong>family of distributions</strong> you believe the outcome variable belongs to.</p>
<p>You can start by answering this question: is your outcome variable continuous or discrete?</p>
<div id="continuous-outcome-variable" class="section level2">
<h2>Continuous outcome variable</h2>
<ul>
<li><p>The variable can take on <em>any positive and negative real number, including 0</em>: <strong>Gaussian</strong> (aka normal) distribution.</p>
<ul>
<li><p>There are very few truly Gaussian variables, although in some cases one can speak of “approximate” or “assumed” normality.</p></li>
<li><p>This family is fitted by default in <code>lm()</code>, <code>lme4::lmer()</code> and <code>brms::brm()</code>.</p></li>
</ul></li>
<li><p>The variable can take on <em>any positive number only</em>: <strong>Log-normal</strong> distribution.</p>
<ul>
<li><p>Duration of segments, words, pauses, etc, are known to be log-normally distributed.</p></li>
<li><p>Measurements taken in Hz (like f0, formants, centre of gravity, …) could be considered to be log-normal.</p></li>
<li><p>There other families that could potentially be used depending on the nature of the variable: exponential-Gaussian (reaction times), gamma, …</p></li>
</ul></li>
<li><p>The variable can take on <em>any number between 0 and 1, but not 0 nor 1</em>: <strong>Beta</strong> distribution.</p>
<ul>
<li>Proportions fall into this category (for example proportion of voicing within closure), although 0 and 1 are not allowed in the beta distribution.</li>
</ul></li>
<li><p>The variable can take on <em>any number between 0 and 1, including 0 or 0 and 1</em>: <strong>Zero-inflated</strong> or <strong>Zero/one-inflated beta</strong> (ZOIB) distribution.</p>
<ul>
<li>If the proportion data includes many 0s and 1s, then this is the ideal distribution to use. ZOIB distributions are somewhat more difficult to fit than a simple beta distribution, so a common practice is to transform the data so that it doesn’t include 0s nor 1s (this can be achieved using different techniques, some better than others).</li>
</ul></li>
</ul>
</div>
<div id="discrete-outcome-variable" class="section level2">
<h2>Discrete outcome variable</h2>
<ul>
<li><p>The variable is <em>dichotomous</em>, i.e. it can take one of two levels: <strong>Bernoulli</strong> distribution.</p>
<ul>
<li><p>Categorical outcome variables like yes/no, correct/incorrect, voiced/voiceless, follow this distribution.</p></li>
<li><p>This family is fitted by default when you run <code>glm(family = binomial)</code>, aka “logistic regression” or “binomial regression”.</p></li>
</ul></li>
<li><p>The variable is <em>counts</em>: <strong>Poisson</strong> distribution.</p>
<ul>
<li>Counts of words, segments, gestures, f0 peaks, …</li>
</ul></li>
<li><p>The variable is a <em>scale</em>: <strong>ordinal</strong> linear model.</p>
<ul>
<li><p>Likert scales and ratings, language attitude questionnaires.</p></li>
<li><p>Ordinal linear models, a.k.a. ordinal logistic regression, can be fitted with the <a href="https://cran.r-project.org/web/packages/ordinal/index.html">ordinal</a> and the <a href="https://paul-buerkner.github.io/brms/">brms</a> package.</p></li>
</ul></li>
</ul>
</div>
</div>
<div id="step-2-are-there-hierarchical-groupings-andor-repeated-measures" class="section level1">
<h1>Step 2: Are there hierarchical groupings and/or repeated measures?</h1>
<p>The second step is to ensure that, if the data is structured hierarchically or repeated measures were taken, this is taken into account in the model.
Here is where so-called “random effects” or “group-level effects/terms” come in.</p>
<p>As an example, let’s assume you asked a number of participants to read a list of words and each word was repeated 5 times by each participant.
You then took f0 measurements from the stressed vowel of each word, of each repetition.</p>
<p>Now, the data has a structure to it:</p>
<ul>
<li>First, observations are grouped by participant (some observations belong to one participant and others to another and so on).</li>
<li>Second, observations are grouped by word (some observations belong to one word and others to another and so on).</li>
<li>Third, within the observations of each word, some belong to the same participant (or, from a different perspective, within the observations of each participant, some belong to the same word).</li>
</ul>
<p>The presence of “groupings” within the data (whether they come from natural groupings like participant or word, or from repeated measures) breaks one of the assumptions of linear models: that each observation must be independent.</p>
<p>If you don’t include any random effect/group-level terms, your model will expect that each observation is independent and hence it will underestimate variance and return unreliable results.</p>
<p>In the toy-example of f0 measurements, you will want to include group-level terms for <em>participant</em> and <em>word</em>.
These will take care to let the model know of the structure of the data mentioned above.</p>
<p>If you have other predictors in the model, you should also add them as (random) slopes in the random effects/group-level terms.
For example: <code>(question | participant) + (question | word)</code> (where <code>question</code> = statement vs question).</p>
<p>A quick terminological note: models that include random effects/group-level terms are called:</p>
<ul>
<li>Random-effects models.</li>
<li>Mixed-effects models.</li>
<li>Hierarchical models.</li>
<li>Nested models.</li>
<li>Multilevel models.</li>
</ul>
<p>These terms are for all intents and purposes equivalent (it just happens that different traditions uses different terms).</p>
</div>
<div id="step-3-are-there-non-linear-effects" class="section level1">
<h1>Step 3: Are there non-linear effects?</h1>
<p>A typical use-case of non-linear terms is when you are dealing with time-series data or spatial data (i.e. geographic coordinates).</p>
<p>Generalised Additive Models allow you to fit non-linear effects using so called “smooth” (or “smoother”) terms.</p>
<p>You can fit a linear model with smooth terms with brms (simply add smooth terms to the formula) or with mgcv (using <code>gam()</code> or <code>bam()</code>), among others.</p>
</div>
<div id="step-0-bis-number-of-outcome-variables" class="section level1">
<h1>Step 0-bis: Number of outcome variables</h1>
<p>If you want to model just one outcome variable, you are already covered if you went through steps 1-3.</p>
<p>If instead your design has two or more outcome variables (for example F1 and F2, or duration of the stressed and unstressed vowel of a word) then you want to fit a <strong>multivariate model</strong> (i.e. a model with <em>multiple outcome </em>variables*).</p>
<p>The same steps we went through before can be applied to multiple outcome variables.
In some cases, you will want to use the same model structure for all the outcome variables, while in others you might want to use a different model structure for each.</p>
<p>To learn more about multivariate models, I really recommend Paul Bürkner’s vignette <a href="https://cran.r-project.org/web/packages/brms/vignettes/brms_multivariate.html">Estimating Multivariate Models with brms</a>.</p>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>Technically, the “simplest” linear model is <span class="math inline">\(y = f(x)\)</span>, but oh well…<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>

</div>
  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://stefanocoretta.github.io/tags/linear/">linear</a></li>
      <li><a href="https://stefanocoretta.github.io/tags/regression/">regression</a></li>
      <li><a href="https://stefanocoretta.github.io/tags/brms/">brms</a></li>
      <li><a href="https://stefanocoretta.github.io/tags/lmer/">lmer</a></li>
      <li><a href="https://stefanocoretta.github.io/tags/gamm/">gamm</a></li>
    </ul>
  </footer>
</article>
    </main><footer class="footer">
    <span>&copy; 2021 <a href="https://stefanocoretta.github.io">Stefano Coretta</a></span>
    <span>&middot;</span>
    <span>Powered by <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a></span>
    <span>&middot;</span>
    <span>Theme <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a></span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)">
    <button class="top-link" id="top-link" type="button" accesskey="g">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z" />
        </svg>
    </button>
</a>



<script defer src="/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js" integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5&#43;kdJvBz5iKbt6B5PJI="
    onload="hljs.initHighlightingOnLoad();"></script>
<script>
    window.onload = function () {
        if (localStorage.getItem("menu-scroll-position")) {
            document.getElementById('menu').scrollLeft = localStorage.getItem("menu-scroll-position");
        }
    }

    function menu_on_scroll() {
        localStorage.setItem("menu-scroll-position", document.getElementById('menu').scrollLeft);
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>

</body>

</html>
