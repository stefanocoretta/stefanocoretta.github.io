<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Stefano Coretta</title>
    <link>https://stefanocoretta.github.io/post/</link>
    <description>Recent content in Posts on Stefano Coretta</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <lastBuildDate>Fri, 22 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://stefanocoretta.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>One Thousand and One names</title>
      <link>https://stefanocoretta.github.io/post/2022-07-22-one-thousand-and-one-names/</link>
      <pubDate>Fri, 22 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/2022-07-22-one-thousand-and-one-names/</guid>
      <description>The following table lists common “portmanteau” names for linear models. Note that different traditions/disciplines might use one particular name more often than the others.
My usual recommendation is to move away from using specific names like “logistic regression” or “mixed-effects models” and instead just specify what kind of components your linear model has (see the Description column in the table).
Formula Description Names lm(y ~ x) Linear model with one predictor x using a Gaussian distribution for the outcome variable y simple linear regression, simple linear model lm(y ~ x + z + .</description>
    </item>
    
    <item>
      <title>Bayesian CrI-width power analysis</title>
      <link>https://stefanocoretta.github.io/post/2022-04-05-bayesian-ci-width-power-analysis/</link>
      <pubDate>Tue, 05 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/2022-04-05-bayesian-ci-width-power-analysis/</guid>
      <description>This post shows how to do a quick and dirty Bayesian power analysis.
“Power” analysis might not be a very appropriate term when Bayesian statistics is concerned. A good alternative could be “precision” analysis, since the method presented in this post is about estimate precision.
More specifically, the aim of this type of analysis is to find the approximate minimum sample size required to reach a given level of precision.</description>
    </item>
    
    <item>
      <title>How to simplify your study design</title>
      <link>https://stefanocoretta.github.io/post/2021-12-01-how-to-simplify-your-study-design/</link>
      <pubDate>Wed, 01 Dec 2021 17:38:53 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/2021-12-01-how-to-simplify-your-study-design/</guid>
      <description>Content Warning: there are A LOT of gifs in this post
We have all been there.
We have run a study with a thoroughly thought-out research design. We got participants from the selected target population. Each participant has gone through the tasks of the study, to gather data from several crossing conditions and now the time has come for you to run (the analysis) FOR. YOUR. LIFE.
And then THE HORROR.</description>
    </item>
    
    <item>
      <title>R gist — Dot matrix charts with ggplot2</title>
      <link>https://stefanocoretta.github.io/post/2021-11-21-dot-matrix-charts/</link>
      <pubDate>Sun, 21 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/2021-11-21-dot-matrix-charts/</guid>
      <description>Set up knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE) knitr::opts_knit$set(root.dir = here::here()) library(tidyverse) ## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.1 ── ## ✔ ggplot2 3.3.5 ✔ purrr 0.3.4 ## ✔ tibble 3.1.6 ✔ dplyr 1.0.8 ## ✔ tidyr 1.2.0 ✔ stringr 1.4.0 ## ✔ readr 2.1.2 ✔ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() Create data dots &amp;lt;- tibble( group = as.</description>
    </item>
    
    <item>
      <title>Linear models: a cheat-sheet</title>
      <link>https://stefanocoretta.github.io/post/2021-08-21-regression-models-a-cheat-sheet/</link>
      <pubDate>Sat, 21 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/2021-08-21-regression-models-a-cheat-sheet/</guid>
      <description>One model to rule them all Linear models, aka linear regression models or regression models, are a group of statistical models based on the simple idea that we can predict an outcome variable \(Y\) based on a function \(f(X)\).
The “simplest” linear model is the formula of a line:1
\[ y = \alpha + \beta x \]
where \(\alpha\) is the intercept of the line and \(\beta\) the slope.</description>
    </item>
    
    <item>
      <title>Factors, coding and contrasts</title>
      <link>https://stefanocoretta.github.io/post/contrasts/</link>
      <pubDate>Tue, 20 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/contrasts/</guid>
      <description>This post is an overview of how factors (i.e. categorical variables) are coded under the hood and which types of coding can be set in R.1
Introduction There’s seems to be a bit of terminological mix-up in the wild, so we first present a terminological set that will be used throughout the vignette.
Categorical variables in R are generally stored using factors. A factor is a vector of values from a categorical variable.</description>
    </item>
    
    <item>
      <title>R gist — Plotting the area under the curve with ggplot</title>
      <link>https://stefanocoretta.github.io/post/plotting-the-area-under-the-curve/</link>
      <pubDate>Sun, 04 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/plotting-the-area-under-the-curve/</guid>
      <description>knitr::opts_chunk$set(echo = TRUE) library(tidyverse) ## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.1 ── ## ✔ ggplot2 3.3.5 ✔ purrr 0.3.4 ## ✔ tibble 3.1.6 ✔ dplyr 1.0.8 ## ✔ tidyr 1.2.0 ✔ stringr 1.4.0 ## ✔ readr 2.1.2 ✔ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() library(ggthemr) ggthemr(&amp;quot;earth&amp;quot;) x &amp;lt;- 1:11 y &amp;lt;- (1.5:11.5)^2 low &amp;lt;- (0:10)^2 upp &amp;lt;- (3:13)^2 ggplot() + aes(x, y) + geom_line() + geom_ribbon(aes(ymin = low, ymax = upp), alpha = 0.</description>
    </item>
    
    <item>
      <title>My researcher&#39;s positionality statement</title>
      <link>https://stefanocoretta.github.io/post/positionality/</link>
      <pubDate>Thu, 29 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/positionality/</guid>
      <description>1 Overview This is my researcher’s positionality statement (for context, see Darwin Holmes 2020; Jafar 2018).
The term positionality both describes an individual’s world view and the position they adopt about a research task and its social and political context. The individual’s world view or ‘where the researcher is coming from’ concerns ontological assumptions (an individual’s beliefs about the nature of social reality and what is knowable about the world), epistemological assumptions (an individual’s beliefs about the nature of knowledge) and assumptions about human nature and agency (individual’s assumptions about the way we interact with our environment and relate to it).</description>
    </item>
    
    <item>
      <title>On phonologisation</title>
      <link>https://stefanocoretta.github.io/post/2021-04-24-on-phonologisation/</link>
      <pubDate>Sat, 24 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/2021-04-24-on-phonologisation/</guid>
      <description>After the post on the definition of random effects, I thought about writing another one on the definition of phonologisation.
As part of my PhD thesis on the effect of consonant voicing on vowel duration, I briefly reviewed the five definitions of phonologisation I could find in the literature. This post includes text from my thesis and expands on a few points.
The main take-away of the sections to follow is that what one means with phonologisation is (unsurprisingly) dependent on the set of assumptions that are part of the framework within which the term is used.</description>
    </item>
    
    <item>
      <title>R gist — VOT and place of articulation</title>
      <link>https://stefanocoretta.github.io/post/2021-04-22-vot-and-place-of-articulation/</link>
      <pubDate>Thu, 22 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/2021-04-22-vot-and-place-of-articulation/</guid>
      <description>knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE) knitr::opts_knit$set(root.dir = here::here()) library(tidyverse) library(plotly) Read data vot &amp;lt;- read_csv(&amp;quot;./static/data/chodroff2019/ChodroffGoldenWilson2019_vot_avg.csv&amp;quot;) %&amp;gt;% group_by(vot.category) %&amp;gt;% mutate(vot.mu_z = scale(vot.mu)) %&amp;gt;% ungroup() %&amp;gt;% pivot_wider(names_from = poa.broad, values_from = c(vot.mu, vot.mu_z)) %&amp;gt;% mutate(vot_category = recode(vot.category, long.lag = &amp;quot;long lag&amp;quot;, short.lag = &amp;quot;short lag&amp;quot;)) Mean VOT vot %&amp;gt;% plot_ly( x = ~vot.mu_labial, y = ~vot.mu_coronal, z = ~vot.mu_dorsal, color = ~vot_category, text = ~language, marker = list(size = 5, opacity = 0.</description>
    </item>
    
    <item>
      <title>Methods as theory</title>
      <link>https://stefanocoretta.github.io/post/methods-as-theory/</link>
      <pubDate>Sun, 28 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/methods-as-theory/</guid>
      <description>At least in linguistics, there is a general tendency to contrast theory with methods. This dichotomy is also reflected in the classification of academic papers as theoretical or methodological.
In this brief post I will argue that the theory/methods divide is epistemologically incoherent, and I will instead propose a taxonomy in which methods are subsumed under theory and are part of it.
1 What is theory? The term theory is used with different senses in different domains.</description>
    </item>
    
    <item>
      <title>On random effects</title>
      <link>https://stefanocoretta.github.io/post/2021-03-15-on-random-effects/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/2021-03-15-on-random-effects/</guid>
      <description>If you use mixed-effects models (aka multilevel models, hierarchical models), I am sure that at some point you asked yourself the following question at least once: Should I include variable X as a fixed or as a random effect?
To answer this question we need to ask first: what is a random effect?
Regrettably, there is no straightforward answer (disappointed, uh?).
The main reason is that, in fact, there are many possible (and most times mutually exclusive) definitions of what a random (vs fixed) effect is.</description>
    </item>
    
    <item>
      <title>Quotables — Rebecca Posner</title>
      <link>https://stefanocoretta.github.io/post/2021-03-07-quotables-rebecca-posner/</link>
      <pubDate>Sun, 07 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/2021-03-07-quotables-rebecca-posner/</guid>
      <description>How many Romance languages are there? An answer to this question that has been slightingly labelled &lt;em&gt;sancta simplicitas&lt;/em&gt; is that there is only one.</description>
    </item>
    
    <item>
      <title>R gist — Plot an interactive 3D RGB colour space</title>
      <link>https://stefanocoretta.github.io/post/rgb-space/</link>
      <pubDate>Fri, 29 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/rgb-space/</guid>
      <description> library(plotly) codes &amp;lt;- seq(0, 255, 25.5) rgb &amp;lt;- expand.grid( r = codes, g = codes, b = codes ) %&amp;gt;% mutate(colour = rgb(r, g, b, maxColorValue = 255)) rgb %&amp;gt;% plot_ly(x = ~r, y = ~g, z = ~b, marker = list(color = ~colour, size = 6)) </description>
    </item>
    
    <item>
      <title>How to globally set colour scales in ggplot2</title>
      <link>https://stefanocoretta.github.io/post/set-global-ggplot2/</link>
      <pubDate>Tue, 22 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/set-global-ggplot2/</guid>
      <description>After the post on using custom typefaces in ggplot2 (here), this time I’ll briefly discuss how to set colour scales in ggplot2 globally in an .Rmd file.
The perk of setting scales globally is that you can set the colours once at the beginning of the .Rmd file and all the plots in the file will adhere to the specified scales without the need to repeat code.
Set ggplot2 options The most robust way of specifying global colour scales for ggplot2 plots is to set the appropriate ggplot2 options with options() at the beginning of the .</description>
    </item>
    
    <item>
      <title>How to use custom typefaces in ggplot2 [macOS only]</title>
      <link>https://stefanocoretta.github.io/post/custom-fonts-ggplot2/</link>
      <pubDate>Mon, 21 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/custom-fonts-ggplot2/</guid>
      <description>I keep hitting my head against this particular (and seemingly simple) task: using custom typefaces in ggplot2 plots and being able to knit to PDF.
The main reason for why I would want to do that is that I often find myself in need of including IPA symbols in plots (more often than not, it’s vowels) and that I want those plots to be included in a knitted PDF.</description>
    </item>
    
    <item>
      <title>Plotting prior distributions with ggplot2</title>
      <link>https://stefanocoretta.github.io/post/priors-ggplot2/</link>
      <pubDate>Mon, 17 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/priors-ggplot2/</guid>
      <description>The choice of priors is a fundamental step of the Bayesian inference process. Vasishth et al. (2018) recommend plotting the chosen priors to see if they are reasonable.
In this post I will show how to easily plot prior distributions in ggplot2 (which is part of the tidyverse).
Let’s load the tidyverse first.
library(tidyverse) ## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.1 ── ## ✔ ggplot2 3.3.5 ✔ purrr 0.3.4 ## ✔ tibble 3.</description>
    </item>
    
    <item>
      <title>An estimate of number of speakers per study in phonetics</title>
      <link>https://stefanocoretta.github.io/post/speakers-per-study/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/speakers-per-study/</guid>
      <description>A few weeks ago, I’ve asked on Twitter what people thought was the average number of participants used in phonetic studies. Here’s the tweet.
Does anyone have an estimate of the average number of participants/tokens per context of recently published phonetic studies (let&#39;s say from the last 10 years)? #OpenScience #phonetics #replication — Stefano Coretta (@StefanoCoretta) April 12, 2019 Thankfully, Timo Roettger has pointed me to a dataset he and Matthew Gordon created for a study on the acoustic correlates of word stress, and he suggested to look at how the median number of speakers changed (or not) through the years.</description>
    </item>
    
    <item>
      <title>Literate programming with Praat</title>
      <link>https://stefanocoretta.github.io/post/literate-programming-with-praat/</link>
      <pubDate>Thu, 21 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/literate-programming-with-praat/</guid>
      <description>This post quickly illustrates how to apply a literate programming workflow to Praat scripting. To be able to reproduce the steps described here you need the latest version of pandoc and the Literate Markdown Tangler (lmt, you will need to install Go first to install lmt).
What is literate programming? In literate programming, one writes both code and plain text which explains what the code does in a single document.</description>
    </item>
    
    <item>
      <title>On the phonotactic restrictions of Proto-Indoeuropean roots</title>
      <link>https://stefanocoretta.github.io/post/phono-restrictions-pie/</link>
      <pubDate>Sun, 06 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/phono-restrictions-pie/</guid>
      <description>Proto-Indoeuropean lexicon is based on monosyllabic roots which have an alternating (ablaut) root vowel preceded and followed by consonants. In this post, I will share some thoughts on the phonotactic restrictions which seem to dictate which consonants can cooccur in a root. I will focus here on stops and laryngeal features. Although I have some formal training in Indoeuropean linguistics, what follows is more of an academic game, so I invite the reader not to expect a fully developed argument.</description>
    </item>
    
    <item>
      <title>Plotting tongue contours with ggplot2</title>
      <link>https://stefanocoretta.github.io/post/tongue-ggplot2/</link>
      <pubDate>Thu, 23 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/tongue-ggplot2/</guid>
      <description>When plotting tongue contours data obtained from ultrasound tongue imaging in R using ggplot2, a common option to smooth over the individual contours and show the general pattern is to use geom_smooth(methood = &#34;loess&#34;). However, as I will show in this post, in certain cases this method leads to very disorted contours. Such distortion is more or less always present, although at a lower degree in less extreme cases.</description>
    </item>
    
    <item>
      <title>Vowel formants trajectories and tidy data</title>
      <link>https://stefanocoretta.github.io/post/formants-tidy/</link>
      <pubDate>Fri, 02 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/formants-tidy/</guid>
      <description>With the advent of more powerful statistical methods for assessing time series data, it is now becoming more common to compare whole vowel formant trajectories rather then just using average values.
In this post I will show how to tidy a formant measurements dataset and plot formants using the tidyverse (Wickham 2017).
From wide to long To illustrate the process, I will use formant data that was kindly provided by Stephen Nichols.</description>
    </item>
    
    <item>
      <title>Wikipedia and the &#34;Dialects of Italy&#34;</title>
      <link>https://stefanocoretta.github.io/post/dialects-italy/</link>
      <pubDate>Tue, 04 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/dialects-italy/</guid>
      <description>The Italian Wikipedia has reached a number of 1,215,574 articles, with 1,247,172 registered users (source: Italian Wikipedia Statistics). That’s more or less one user per article. The Italian encyclopaedia counts an average of 358,814 views per hour (source: Wikipedia Statistics).
Nevertheless, the linguistics presence suffers from a variety of cyber-diseases. According to the figures described on the page of the Italian Linguistics WikiProject, out of 890 articles, 250 don’t cite proper sources for their information and about 270 are stubs that need to be expanded.</description>
    </item>
    
    <item>
      <title>Short review of phonological databases</title>
      <link>https://stefanocoretta.github.io/post/2021-01-09-short-review/</link>
      <pubDate>Mon, 30 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://stefanocoretta.github.io/post/2021-01-09-short-review/</guid>
      <description>A review of available phonological databases (2014).</description>
    </item>
    
  </channel>
</rss>
