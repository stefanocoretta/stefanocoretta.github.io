[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Stefano Coretta",
    "section": "",
    "text": "One Thousand and One names\n\n\n\nMethods\n\nLinear models\n\n\n\n\n\n\n\n\n\nJul 22, 2022\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nBayesian CrI-width power analysis\n\n\n\nLinear models\n\nBayesian\n\nbrms\n\n\n\n\n\n\n\n\n\nApr 5, 2022\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nHow to simplify your study design\n\n\n\nLinear models\n\n\n\n\n\n\n\n\n\nDec 1, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nR gist — Dot matrix charts with ggplot2\n\n\n\nGist\n\n\n\n\n\n\n\n\n\nNov 21, 2021\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nLinear models: a cheat-sheet\n\n\n\nMethods\n\nLinear models\n\n\n\n\n\n\n\n\n\nAug 21, 2021\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nFactors, coding and contrasts\n\n\n\nMethods\n\nLinear models\n\n\n\n\n\n\n\n\n\nJul 20, 2021\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nR gist — Plotting the area under the curve with ggplot\n\n\n\nMethods\n\n\n\n\n\n\n\n\n\nJul 4, 2021\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nOn phonologisation\n\n\n\nLinguistics\n\n\n\n\n\n\n\n\n\nApr 24, 2021\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nR gist — VOT and place of articulation\n\n\n\nLinguistics\n\nGist\n\n\n\n\n\n\n\n\n\nApr 22, 2021\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nMethods as theory\n\n\n\nMethods\n\nMeta-models\n\n\n\n\n\n\n\n\n\nMar 28, 2021\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nOn random effects\n\n\n\nMethods\n\nLinear models\n\nRstats\n\n\n\n\n\n\n\n\n\nMar 15, 2021\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nQuotables — Rebecca Posner\n\n\n\nQuotables\n\n\n\n\n\n\n\n\n\nMar 7, 2021\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nR gist — Plot an interactive 3D RGB colour space\n\n\n\nGist\n\n\n\n\n\n\n\n\n\nJan 29, 2021\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nHow to globally set colour scales in ggplot2\n\n\n\nMethods\n\n\n\n\n\n\n\n\n\nDec 22, 2020\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nHow to use custom typefaces in ggplot2 [macOS only]\n\n\n\nMethods\n\n\n\n\n\n\n\n\n\nDec 21, 2020\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nPlotting prior distributions with ggplot2\n\n\n\nMethods\n\nLinear models\n\n\n\n\n\n\n\n\n\nJun 17, 2019\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nAn estimate of number of speakers per study in phonetics\n\n\n\nLinguistics\n\nMethods\n\n\n\n\n\n\n\n\n\nMay 3, 2019\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nLiterate programming with Praat\n\n\n\nLinguistics\n\nMethods\n\n\n\n\n\n\n\n\n\nMar 21, 2019\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nOn the phonotactic restrictions of Proto-Indoeuropean roots\n\n\n\nLinguistics\n\n\n\n\n\n\n\n\n\nJan 6, 2019\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nPlotting tongue contours with ggplot2\n\n\n\nLinguistics\n\n\n\n\n\n\n\n\n\nAug 23, 2018\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nVowel formants trajectories and tidy data\n\n\n\nLinguistics\n\n\n\n\n\n\n\n\n\nMar 2, 2018\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nWikipedia and the “Dialects of Italy”\n\n\n\nLinguistics\n\n\n\n\n\n\n\n\n\nAug 4, 2015\n\n\nStefano Coretta\n\n\n\n\n\n\n\n\n\n\n\n\nShort review of phonological databases\n\n\n\nLinguistics\n\n\n\n\n\n\n\n\n\nJun 30, 2014\n\n\nStefano Coretta\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stefano Coretta",
    "section": "",
    "text": "Stefano Coretta\n[ˈsteˑfano koˈrɛtta]\nLecturer (Assistant Professor)\nUniversity of Edinburgh\ns.coretta@ed.ac.uk\n\n     \n\n\n\n\nI am a Lecturer (Assistant Professor) in the Linguistics and English Language department of the University of Edinburgh (UK). As part of my duties, I develop and coordinate the statistical curriculum of undergraduate and postgraduate degrees within the department, teach statistics and research methods courses, and provide training for staff and students. I received my PhD degree in linguistics (with a thesis on ultrasound tongue imaging and electroglottography) from the University of Manchester (UK) in 2020. I was a postdoc researcher at the Institute of Phonetics and Speech Processing at the Ludwig-Maximilians-Universität München (Germany) from 2019 until 2021, when I joined the University of Edinburgh.\nI am available as instructor for a range of Workshops on statistics and research methods and as collaborator on projects or papers requiring the planning and execution of statistical analyses. Get in contact with me for info.\nMy past and current research covers different areas of linguistics, with a focus on phonetology—the study of speech sounds and their relation to Human Language—and research methods including statistics and Open Science practices. For more details on my research interests, past/current research projects, and an overview of meta-models informing my research, check out the Research and Meta-models pages. You can find a list of research outputs (papers, software, etc) in Output.\nMy philosophical stance is based on a syncretic synthesis of holistic monism, anti-realism, idealism, panpsychism, subjective Bayesian epistemology and ecological awareness. I engage in spiritual practices and pagan magick, and in my free time I enjoy conlanging (the art of constructing artificial languages), watching sci-fi and fantasy movies, playing the recorder and taking care of plants.\n\n\nInterests\n\nPhonetology (i.e. Phonetics and Phonology)\nResearch Methods and Statistics\nLanguage description\nTypology and Diachronic linguistics\nGraphemics\n\n\n\nPhD supervision\nI am available for PhD supervision on topics from my interests list. Please note that I do NOT supervise projects in applied or developmental linguistics."
  },
  {
    "objectID": "meta.html",
    "href": "meta.html",
    "title": "Research meta-models",
    "section": "",
    "text": "In the following sections, I outline some of the conceptual and methodological aspects (meta-models) that fuel and back-up my research. I hope these will some day make it into a proper publication, after some more thorough thinking.\nThis is a work in progress, in two senses:"
  },
  {
    "objectID": "meta.html#phonetological-systems",
    "href": "meta.html#phonetological-systems",
    "title": "Research meta-models",
    "section": "2.1 Phonetological systems",
    "text": "2.1 Phonetological systems\nA phonetological system is comprised of a set of phonetological units and their relationships. Alas, I could not come up yet with a proper definition of “phonetological unit” that would subsume units of both visual and sound systems. Thoughts on this are much appreciated.\nIn my view of phonetology, a phonetological system has the following properties:\n\nIt is a dynamic system (Thelen & Smith 2006; Vihman 2014).\nIt is a physio-neuro-cognitive system. It has:\n\nA physical component (Ohala 1990; Ohala 2005).\nA neuro-cognitive component.\n\nIt is rich in details (Johnson 1997; Pierrehumbert 2001; Bybee 2002).\nIt is self-organising and emergent (Wedel 2007; Wedel 2011).\nIt uses both stored exemplars and stored abstractions at multiple levels (Ambridge 2020).\n\n\nIt is part of a complex socio-cultural system (de Boer 2015; Foulkes & Docherty 2006; Thompson, Kirby & Smith 2016).\n\nI also consider these statements to be extendible more generally to Human Language as a holistic system."
  },
  {
    "objectID": "meta.html#ontological",
    "href": "meta.html#ontological",
    "title": "Research meta-models",
    "section": "4.1 Ontological",
    "text": "4.1 Ontological\n\nHuman Language is the human ability to communicate through a language, and a language is a specific communicative system used by a specific group of humans.\nlinguisticality is the prerequisite for Human Language (Haspelmath 2020).\nIf one defines Human Language as the human ability to communicate through a language, then saying that only humans have Human Language is a tautology.\nAll living beings are capable of communicating (even plants and fungi, Mancuso & Viola 2015)."
  },
  {
    "objectID": "meta.html#epistemological",
    "href": "meta.html#epistemological",
    "title": "Research meta-models",
    "section": "4.2 Epistemological",
    "text": "4.2 Epistemological\n\nLinguistics is usually defined as a “science that studies Human Language”, however there is no agreement as to what science actually is.\nScience is not the only way to obtain knowledge. There are many epistemological practices or “ways of knowing”. Like all ways of knowing, science is human activity.\nI prefer to use the term research instead of science for all purposes.\nResearch has both objective and subjective components.\nStatistics and statistical inference have both objective and subjective components (Gelman & Hennig 2017).\nThere is no agreement as to what language, Human Language, linguisticality actually are.\nThere is no agreement as to whether language, Human Language, linguisticality are the same thing or if they in principle refer to different entities.\nThere is no agreement as to which components of the human ability to communicate through a language are innate and which are learned.\nThere is no agreement as to what innate actually means.\nThere is no agreement as to whether the human ability to communicate through a language is entirely domain-specific or entirely domain-general, or if it is a bit of both.\n\nIf it is a bit of both, there is no agreement as to which components are domain-specific and which are domain-general.\n\nThere is no agreement as to what a language is. In fact, in English language is used at times to mean either the human ability/capacity to communicate with a language or to mean a specific language (sometimes written Language and language respectively). See Section 3."
  },
  {
    "objectID": "meta.html#footnotes",
    "href": "meta.html#footnotes",
    "title": "Research meta-models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOpen Research is a more inclusive term than the more common Open Science term.↩︎"
  },
  {
    "objectID": "posts/2021-01-29-rgb-space/index.html",
    "href": "posts/2021-01-29-rgb-space/index.html",
    "title": "R gist — Plot an interactive 3D RGB colour space",
    "section": "",
    "text": "library(plotly)\n\n\ncodes &lt;- seq(0, 255, 25.5)\n\nrgb &lt;- expand.grid(\n  r = codes,\n  g = codes,\n  b = codes\n) %&gt;%\n  mutate(colour = rgb(r, g, b, maxColorValue = 255))\n\n\nrgb %&gt;%\n  plot_ly(x = ~r, y = ~g, z = ~b, marker = list(color = ~colour, size = 6))"
  },
  {
    "objectID": "posts/2020-12-22-set-global-ggplot2/index.html",
    "href": "posts/2020-12-22-set-global-ggplot2/index.html",
    "title": "How to globally set colour scales in ggplot2",
    "section": "",
    "text": "After the post on using custom typefaces in ggplot2 (here), this time I’ll briefly discuss how to set colour scales in ggplot2 globally in an .Rmd file.\nThe perk of setting scales globally is that you can set the colours once at the beginning of the .Rmd file and all the plots in the file will adhere to the specified scales without the need to repeat code."
  },
  {
    "objectID": "posts/2020-12-22-set-global-ggplot2/index.html#colour-name",
    "href": "posts/2020-12-22-set-global-ggplot2/index.html#colour-name",
    "title": "How to globally set colour scales in ggplot2",
    "section": "Colour name",
    "text": "Colour name\n\noptions(ggplot2.discrete.fill = c(\"red\", \"blue\", \"green\", \"purple\", \"yellow\"))\n\nmpg %&gt;%\n  filter(!(class %in% c(\"subcompact\", \"suv\"))) %&gt;%\n  ggplot(aes(class, fill = class)) +\n  geom_bar()"
  },
  {
    "objectID": "posts/2020-12-22-set-global-ggplot2/index.html#hex-value",
    "href": "posts/2020-12-22-set-global-ggplot2/index.html#hex-value",
    "title": "How to globally set colour scales in ggplot2",
    "section": "Hex value",
    "text": "Hex value\n\noptions(ggplot2.discrete.fill = c(\"#264653\", \"#2a9d8f\", \"#a8dadc\", \"#457b9d\", \"#e76f51\"))\n\nmpg %&gt;%\n  filter(!(class %in% c(\"subcompact\", \"suv\"))) %&gt;%\n  ggplot(aes(class, fill = class)) +\n  geom_bar()"
  },
  {
    "objectID": "posts/2020-12-22-set-global-ggplot2/index.html#set3",
    "href": "posts/2020-12-22-set-global-ggplot2/index.html#set3",
    "title": "How to globally set colour scales in ggplot2",
    "section": "Set3",
    "text": "Set3\n\noptions(ggplot2.discrete.fill = RColorBrewer::brewer.pal(12, \"Set3\"))\n\nmpg %&gt;%\n  filter(!(class %in% c(\"subcompact\", \"suv\"))) %&gt;%\n  ggplot(aes(class, fill = class)) +\n  geom_bar()"
  },
  {
    "objectID": "posts/2020-12-22-set-global-ggplot2/index.html#interp",
    "href": "posts/2020-12-22-set-global-ggplot2/index.html#interp",
    "title": "How to globally set colour scales in ggplot2",
    "section": "Palette interpolation",
    "text": "Palette interpolation\n\ndefault_palettes &lt;- list(\n  # palette with 5 colours\n  wesanderson::wes_palette(\"Darjeeling1\"),\n  # same palette interpolated to 8 colours\n  grDevices::colorRampPalette(wesanderson::wes_palette(\"Darjeeling1\"), alpha = TRUE)(8)\n)\n\noptions(ggplot2.discrete.fill = default_palettes)\n\n# 5 levels\nggplot(mpg, aes(class, fill = fl)) + geom_bar()\n\n\n\n\n\n\n\n# 7 levels\nggplot(mpg, aes(class, fill = class)) + geom_bar()"
  },
  {
    "objectID": "posts/2018-12-26-literate-programming-with-praat/index.html",
    "href": "posts/2018-12-26-literate-programming-with-praat/index.html",
    "title": "Literate programming with Praat",
    "section": "",
    "text": "This post quickly illustrates how to apply a literate programming workflow to Praat scripting. To be able to reproduce the steps described here you need the latest version of pandoc and the Literate Markdown Tangler (lmt, you will need to install Go first to install lmt)."
  },
  {
    "objectID": "posts/2018-12-26-literate-programming-with-praat/index.html#what-is-literate-programming",
    "href": "posts/2018-12-26-literate-programming-with-praat/index.html#what-is-literate-programming",
    "title": "Literate programming with Praat",
    "section": "What is literate programming?",
    "text": "What is literate programming?\nIn literate programming, one writes both code and plain text which explains what the code does in a single document. Natural language and programming language are interleaved in the document in a way that is reader-oriented, rather than software oriented. So, for example, the code can be included in an order that is different from the order it should have had the document been a script.\nThis programming paradigm allows developers to focus on documenting their code in a more natural way. This has the double advantage of aiding a new user in understanding what the code does and helping the author of the code to develop the code following a logic that can be different from the logic of the code’s programming language.\nIn general, from a literate source file (a file containing both natural language and programming code) it is possible to obtain a documentation file (by the process called weaving) and a script file (by the process called tangling) which is interpretable by the target programming language.\nMarkdown, a simple but effective mark-up language, allows mixing natural language (with rich formatting) and code in a single document. Pandoc is a software utility which can convert documents from and to a variety of formats. The conversion relevant to us is from Markdown to PDF. Converting Markdown to PDF corresponds to the weaving process mentioned above, i.e. creating a richly formatted documentation of the code. Pandoc has syntax highlighting capabilities, and Praat syntax is supported, so that your documentation will also be easier to interpret. The Literate Markdown Tangler, by Dave MacFarlane, is a software written in Go that instead can be used to tangle (extract) the code from the source file into a scripting file.\nPandoc and lmt can be used together to develop a literate programming workflow with Praat scripting. This means that you can develop a Praat script by laying out the pieces of the script in the source file and explain what the various parts of the script do in using natural language. lmt further allows the user to create “blocks” of code that can be referenced in other blocks and reused. If you wanna generate a PDF version of the documentation, you can convert the source file to a PDF with Pandoc.\nThe figure at the top of this post shows an example of a literate Praat source file.\nThe following sections will point you to the software and files that need to be installed/copied and will show how to use literate programming with Praat scripting."
  },
  {
    "objectID": "posts/2018-12-26-literate-programming-with-praat/index.html#necessary-software",
    "href": "posts/2018-12-26-literate-programming-with-praat/index.html#necessary-software",
    "title": "Literate programming with Praat",
    "section": "Necessary software",
    "text": "Necessary software\n\nYou need to install the latest version of Pandoc, which can be found here. After installing, be sure you can run this command from your command line GUI: pandoc --version. If a version is returned, Pandoc is working on your system.\nInstall Go from here and set it up, then download and install lmt from here.\nDownload and unzip the content of this zip to a convenient directory (usually, in .pandoc/ in your user folder). This folder contains the files which allow Pandoc to highlight Praat syntax."
  },
  {
    "objectID": "posts/2018-12-26-literate-programming-with-praat/index.html#literate-praat",
    "href": "posts/2018-12-26-literate-programming-with-praat/index.html#literate-praat",
    "title": "Literate programming with Praat",
    "section": "Literate Praat",
    "text": "Literate Praat\nTo generate the Praat script and its documentation, you have to:\n\nWrite your script in a Markdown source file with Praat code enclosed in code chunks that follow the format required by lmt.\nUse lmt to tangle the code from the source file into a standalone Praat script.\nUse pandoc with a custom syntax highlighter to generate the documentation of the script.\n\n\nThe source file\nThe source file will contain text, Markdown markup, and code enclosed between back-ticks. The following is an example of how such file would look like.\n\n\n\nLiterate Praat basic example\n\n\n\n\nTangle the code\nTo tangle the code into a standalone Praat script, run the following line from your command line GUI, where my-script.praat.md is your Praat source file:\nlmt my-script.praat.md\nThe scripts defined in the source file will be output in the same directory as the source file (to learn more on how this works, check the lmt README on GitHub).\n\n\nWeave the documentation\nTo weave the documentation, run the following by replacing the syntax definition path with the path to the pandoc-praat/ folder on your computer:\npandoc -f gfm -o doc.pdf script.praat.md -N --syntax-definition=&lt;your-path-here&gt;/pandoc-praat/praat.xml\nThis line of code tells Pandoc to convert from Markdown to PDF and where to find the files for highlighting Praat code.\nA .pdf file named doc.pdf containing the documentation of the script will be created when the line is run."
  },
  {
    "objectID": "posts/2021-08-21-regression-models-a-cheat-sheet/index.html",
    "href": "posts/2021-08-21-regression-models-a-cheat-sheet/index.html",
    "title": "Linear models: a cheat-sheet",
    "section": "",
    "text": "Linear models, aka linear regression models or regression models, are a group of statistical models based on the simple idea that we can predict an outcome variable \\(Y\\) based on a function \\(f(X)\\).\nThe “simplest” linear model is the formula of a line:1\n\\[\ny = \\alpha + \\beta x\n\\]\nwhere \\(\\alpha\\) is the intercept of the line and \\(\\beta\\) the slope.\nThe principles behind this formula can be extended to represent virtually any other model, independent of the nature of the outcome variable(s) (\\(y\\)), the predictor(s), the types of relationship between outcome and predictor, and so on.\nThis means that if you master the principles of linear models, then you can virtually fit any kind of data using linear models You can bid farewell to ANOVAs, \\(t\\)-tests, \\(\\chi^2\\)-tests, and what not. In fact, these can all be thought of as specific cases of linear models. It just so happens that they got themselves a specific name. But the underlying mechanics is the same.\nSame goes with “regressions”, “logistic regression”, “generalised linear models”, “mixed-effects regression” and so on. These are all linear models, so they all follow the same principles. And again, the fact that they got specific name is a historical “accident”.\nUnderstanding that these named models are in fact all linear models gives you super powers you can use on data (Sauron would be so jealous):\n\nOne model to rule them all, one model to fit them,\nOne model to shrink them all, and in probability bind them;\nIn the Land of Inference where the distributions lie.\n\nEhm… perhaps this is not gonna win a poetry context, but…\nThe message is that with a single tool, i.e. linear models, you can go a long way!\nEach of the following sections asks you about the nature of your data and/or experimental design. By answering each, you will find out which “pieces” you need to add to your model structure.\n(This is a work in progress, so still rough around the edges)."
  },
  {
    "objectID": "posts/2021-08-21-regression-models-a-cheat-sheet/index.html#continuous-outcome-variable",
    "href": "posts/2021-08-21-regression-models-a-cheat-sheet/index.html#continuous-outcome-variable",
    "title": "Linear models: a cheat-sheet",
    "section": "Continuous outcome variable",
    "text": "Continuous outcome variable\n\nThe variable can take on any positive and negative real number, including 0: Gaussian (aka normal) distribution.\n\nThere are very few truly Gaussian variables, although in some cases one can speak of “approximate” or “assumed” normality.\nThis family is fitted by default in lm(), lme4::lmer() and brms::brm().\n\nThe variable can take on any positive number only: Log-normal distribution.\n\nDuration of segments, words, pauses, etc, are known to be log-normally distributed.\nMeasurements taken in Hz (like f0, formants, centre of gravity, …) could be considered to be log-normal.\nThere other families that could potentially be used depending on the nature of the variable: exponential-Gaussian (reaction times), gamma, …\n\nThe variable can take on any number between 0 and 1, but not 0 nor 1: Beta distribution.\n\nProportions fall into this category (for example proportion of voicing within closure), although 0 and 1 are not allowed in the beta distribution.\n\nThe variable can take on any number between 0 and 1, including 0 or 0 and 1: Zero-inflated or Zero/one-inflated beta (ZOIB) distribution.\n\nIf the proportion data includes many 0s and 1s, then this is the ideal distribution to use. ZOIB distributions are somewhat more difficult to fit than a simple beta distribution, so a common practice is to transform the data so that it doesn’t include 0s nor 1s (this can be achieved using different techniques, some better than others)."
  },
  {
    "objectID": "posts/2021-08-21-regression-models-a-cheat-sheet/index.html#discrete-outcome-variable",
    "href": "posts/2021-08-21-regression-models-a-cheat-sheet/index.html#discrete-outcome-variable",
    "title": "Linear models: a cheat-sheet",
    "section": "Discrete outcome variable",
    "text": "Discrete outcome variable\n\nThe variable is dichotomous, i.e. it can take one of two levels: Bernoulli distribution.\n\nCategorical outcome variables like yes/no, correct/incorrect, voiced/voiceless, follow this distribution.\nThis family is fitted by default when you run glm(family = binomial), aka “logistic regression” or “binomial regression”.\n\nThe variable is counts: Poisson distribution.\n\nCounts of words, segments, gestures, f0 peaks, …\n\nThe variable is a scale: ordinal linear model.\n\nLikert scales and ratings, language attitude questionnaires.\nOrdinal linear models, a.k.a. ordinal logistic regression, can be fitted with the ordinal and the brms package."
  },
  {
    "objectID": "posts/2021-08-21-regression-models-a-cheat-sheet/index.html#footnotes",
    "href": "posts/2021-08-21-regression-models-a-cheat-sheet/index.html#footnotes",
    "title": "Linear models: a cheat-sheet",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTechnically, the “simplest” linear model is \\(y = f(x)\\), but oh well…↩︎"
  },
  {
    "objectID": "posts/2020-12-21-custom-fonts-ggplot2/index.html",
    "href": "posts/2020-12-21-custom-fonts-ggplot2/index.html",
    "title": "How to use custom typefaces in ggplot2 [macOS only]",
    "section": "",
    "text": "I keep hitting my head against this particular (and seemingly simple) task: using custom typefaces in ggplot2 plots and being able to knit to PDF.\nThe main reason for why I would want to do that is that I often find myself in need of including IPA symbols in plots (more often than not, it’s vowels) and that I want those plots to be included in a knitted PDF.\nFor some reason, when I think I got it, I have to search again because the solution I previously found no longer works.\nSo now I took the time to play around with different options and packages, and I found the minimal configuration one needs to use custom typefaces in ggplot2 plots and get a PDF document with those plots embedded in it (it is working as of December 2020, not sure what the year will bring).\nIn the following sections I will show what this configuration looks like. Note that this post covers only R running on macOS and that things will be different perhaps on Linux and for sure on Windows (maybe I’ll cover those OSs in an update later on).\nYou can check out my full session info below, but just be aware that I am using R 4.0.3 in macOS Big Sur 11.1, with the latest version of the tidyverse packages at the time of writing."
  },
  {
    "objectID": "posts/2020-12-21-custom-fonts-ggplot2/index.html#enable-custom-typefaces-in-ggplot2-plots-when-knitting-to-pdf",
    "href": "posts/2020-12-21-custom-fonts-ggplot2/index.html#enable-custom-typefaces-in-ggplot2-plots-when-knitting-to-pdf",
    "title": "How to use custom typefaces in ggplot2 [macOS only]",
    "section": "Enable custom typefaces in ggplot2 plots when knitting to PDF",
    "text": "Enable custom typefaces in ggplot2 plots when knitting to PDF\nI was surprised to find out that to include custom typefaces in ggplot2 plots and knit the .Rmd to a PDF document, you just need the following options in your YAML preamble (no need for extra packages!!!).\n\n---\noutput:\n  pdf_document:\n    latex_engine: xelatex\n    dev: cairo_pdf\n---\n\nIn particular, the dev option sets cairo_pdf() (shipped with ggplot2) as the default device for rendering the plots within the knitted PDF document.\nAs Miranda Priestly would say, that’s all…1\nWithin your document you can then specify the typeface you want to use in the plots. The most straightforward way is to set a ggplot2 theme and specify the base_family argument.\nI chose the Fira Sans fonts here because they include the Unicode range of the IPA.\nBoth when running a chunk with a ggplot2 plot interactively in the .Rmd file and when knitting the .Rmd to a PDF, the plot typeface will be Fira Sans. And we are done."
  },
  {
    "objectID": "posts/2020-12-21-custom-fonts-ggplot2/index.html#extra-saving-ggplot2-plots-to-a-file",
    "href": "posts/2020-12-21-custom-fonts-ggplot2/index.html#extra-saving-ggplot2-plots-to-a-file",
    "title": "How to use custom typefaces in ggplot2 [macOS only]",
    "section": "Extra: Saving ggplot2 plots to a file",
    "text": "Extra: Saving ggplot2 plots to a file\nNow, what if you want to save the plots with your custom typeface to a file that you can include in another document?\nYou have two options:\n\nYou can save the plot as a standalone PDF file (with embedded fonts).\nOr you can save the plot as a .png image.\n\nAchieving that is quite simple with ggsave():\nThe magic is done by ggsave(..., device = cairo_pdf) (that’s the same cairo_pdf device we set in the YAML preamble). Note that it’s cairo_pdf and not cairo_pdf() (for reasons beyond my comprehension, it does not work if you add the parentheses).\nHere you find a gist with an example .Rmd file that you can download on your machine and knit as a test."
  },
  {
    "objectID": "posts/2020-12-21-custom-fonts-ggplot2/index.html#supported-fonts",
    "href": "posts/2020-12-21-custom-fonts-ggplot2/index.html#supported-fonts",
    "title": "How to use custom typefaces in ggplot2 [macOS only]",
    "section": "Supported fonts",
    "text": "Supported fonts\nAs far as I can tell, any .ttf (TrueType font) installed on your system with Font Book can be set as the typeface to be used in the ggplot2 plots."
  },
  {
    "objectID": "posts/2020-12-21-custom-fonts-ggplot2/index.html#session-info",
    "href": "posts/2020-12-21-custom-fonts-ggplot2/index.html#session-info",
    "title": "How to use custom typefaces in ggplot2 [macOS only]",
    "section": "Session info",
    "text": "Session info\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.2 (2023-10-31)\n os       macOS Sonoma 14.0\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2023-12-25\n pandoc   3.1.11 @ /opt/homebrew/bin/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package     * version date (UTC) lib source\n P cachem        1.0.8   2023-05-01 [?] CRAN (R 4.3.0)\n P callr         3.7.3   2022-11-02 [?] CRAN (R 4.3.0)\n P cli           3.6.2   2023-12-11 [?] RSPM (R 4.3.0)\n P crayon        1.5.2   2022-09-29 [?] CRAN (R 4.3.0)\n P devtools      2.4.5   2022-10-11 [?] CRAN (R 4.3.0)\n P digest        0.6.33  2023-07-07 [?] CRAN (R 4.3.0)\n P ellipsis      0.3.2   2021-04-29 [?] CRAN (R 4.3.0)\n P evaluate      0.22    2023-09-29 [?] CRAN (R 4.3.1)\n P fastmap       1.1.1   2023-02-24 [?] CRAN (R 4.3.0)\n P fs            1.6.3   2023-07-20 [?] CRAN (R 4.3.0)\n P glue          1.6.2   2022-02-24 [?] CRAN (R 4.3.0)\n P htmltools     0.5.7   2023-11-03 [?] CRAN (R 4.3.1)\n P htmlwidgets   1.6.2   2023-03-17 [?] CRAN (R 4.3.0)\n P httpuv        1.6.11  2023-05-11 [?] CRAN (R 4.3.0)\n P jsonlite      1.8.7   2023-06-29 [?] CRAN (R 4.3.0)\n P knitr         1.44    2023-09-11 [?] CRAN (R 4.3.0)\n P later         1.3.1   2023-05-02 [?] CRAN (R 4.3.0)\n P lifecycle     1.0.4   2023-11-07 [?] CRAN (R 4.3.1)\n P magrittr      2.0.3   2022-03-30 [?] CRAN (R 4.3.0)\n P memoise       2.0.1   2021-11-26 [?] CRAN (R 4.3.0)\n P mime          0.12    2021-09-28 [?] CRAN (R 4.3.0)\n P miniUI        0.1.1.1 2018-05-18 [?] CRAN (R 4.3.0)\n P pkgbuild      1.4.2   2023-06-26 [?] CRAN (R 4.3.0)\n P pkgload       1.3.3   2023-09-22 [?] CRAN (R 4.3.1)\n P prettyunits   1.2.0   2023-09-24 [?] CRAN (R 4.3.1)\n P processx      3.8.2   2023-06-30 [?] CRAN (R 4.3.0)\n P profvis       0.3.8   2023-05-02 [?] CRAN (R 4.3.0)\n P promises      1.2.1   2023-08-10 [?] CRAN (R 4.3.0)\n P ps            1.7.5   2023-04-18 [?] CRAN (R 4.3.0)\n P purrr         1.0.2   2023-08-10 [?] CRAN (R 4.3.0)\n P R6            2.5.1   2021-08-19 [?] CRAN (R 4.3.0)\n P Rcpp          1.0.11  2023-07-06 [?] CRAN (R 4.3.0)\n P remotes       2.4.2.1 2023-07-18 [?] CRAN (R 4.3.0)\n   renv          1.0.3   2023-09-19 [1] CRAN (R 4.3.1)\n P rlang         1.1.2   2023-11-04 [?] CRAN (R 4.3.1)\n P rmarkdown     2.25    2023-09-18 [?] CRAN (R 4.3.1)\n P rstudioapi    0.15.0  2023-07-07 [?] CRAN (R 4.3.0)\n P sessioninfo   1.2.2   2021-12-06 [?] CRAN (R 4.3.0)\n P shiny         1.7.5.1 2023-10-14 [?] CRAN (R 4.3.1)\n P stringi       1.7.12  2023-01-11 [?] CRAN (R 4.3.0)\n P stringr       1.5.0   2022-12-02 [?] CRAN (R 4.3.0)\n P urlchecker    1.0.1   2021-11-30 [?] CRAN (R 4.3.0)\n P usethis       2.2.2   2023-07-06 [?] CRAN (R 4.3.0)\n P vctrs         0.6.5   2023-12-01 [?] CRAN (R 4.3.1)\n P xfun          0.40    2023-08-09 [?] CRAN (R 4.3.0)\n P xtable        1.8-4   2019-04-21 [?] CRAN (R 4.3.0)\n P yaml          2.3.8   2023-12-11 [?] RSPM (R 4.3.0)\n\n [1] /Users/ste/repos/stefanocoretta.github.io/renv/library/R-4.3/aarch64-apple-darwin20\n [2] /Users/ste/Library/Caches/org.R-project.R/R/renv/sandbox/R-4.3/aarch64-apple-darwin20/ac5c2659\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2020-12-21-custom-fonts-ggplot2/index.html#footnotes",
    "href": "posts/2020-12-21-custom-fonts-ggplot2/index.html#footnotes",
    "title": "How to use custom typefaces in ggplot2 [macOS only]",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://media.giphy.com/media/3o6gDY8zzwvNQdFCaQ/giphy.gif↩︎"
  },
  {
    "objectID": "posts/2019-05-03-speakers-per-study/index.html",
    "href": "posts/2019-05-03-speakers-per-study/index.html",
    "title": "An estimate of number of speakers per study in phonetics",
    "section": "",
    "text": "A few weeks ago, I’ve asked on Twitter what people thought was the average number of participants used in phonetic studies. Here’s the tweet.\nThankfully, Timo Roettger has pointed me to a dataset he and Matthew Gordon created for a study on the acoustic correlates of word stress, and he suggested to look at how the median number of speakers changed (or not) through the years. The dataset reports, among other things, the number of participants in the surveyed studies. Christian DiCanio has also thoughtfully noted that language endangerment should be taken into consideration in any enquiry about number of speakers."
  },
  {
    "objectID": "posts/2019-05-03-speakers-per-study/index.html#general-trends",
    "href": "posts/2019-05-03-speakers-per-study/index.html#general-trends",
    "title": "An estimate of number of speakers per study in phonetics",
    "section": "General trends",
    "text": "General trends\nThe dataset contains data from 113 studies, published between 1955 and 2017 (the bulk of studies is within the range 1990-2017 though). The median number of speakers per study is 5. The histogram below illustrates that most studies have around 10 speakers or less, and that there are a few outliers with 30-40 speakers."
  },
  {
    "objectID": "posts/2019-05-03-speakers-per-study/index.html#number-of-speakers-through-the-years",
    "href": "posts/2019-05-03-speakers-per-study/index.html#number-of-speakers-through-the-years",
    "title": "An estimate of number of speakers per study in phonetics",
    "section": "Number of speakers through the years",
    "text": "Number of speakers through the years\nWe now turn to the number of speakers through the years. I can’t really say that there is a clear trend, if not for the fact that the studies with more than 30 speakers are (unsurprisingly) more recent."
  },
  {
    "objectID": "posts/2019-05-03-speakers-per-study/index.html#number-of-speakers-by-linguistic-affiliation",
    "href": "posts/2019-05-03-speakers-per-study/index.html#number-of-speakers-by-linguistic-affiliation",
    "title": "An estimate of number of speakers per study in phonetics",
    "section": "Number of speakers by linguistic affiliation",
    "text": "Number of speakers by linguistic affiliation\nThe following bar chart shows the median number of speakers in studies by genetic affiliation. The colour of the bars indicates the number of studies. Indo-European languages stand out in terms of number of studies (&gt; 30), although the number of speakers does not fare better than other less-reachable language families.\n\n\n\n\n\n\n\n\n\nThis plot is the same as the one above, but families have been categorised by number of studies in two categories: up to 5 studies vs. 5 or more. It is not surprising that Uralic, Indo-European, Turkic, Afro-Asiatic and Austronesian stand out."
  },
  {
    "objectID": "posts/2019-05-03-speakers-per-study/index.html#number-of-speakers-by-endangerment-status",
    "href": "posts/2019-05-03-speakers-per-study/index.html#number-of-speakers-by-endangerment-status",
    "title": "An estimate of number of speakers per study in phonetics",
    "section": "Number of speakers by endangerment status",
    "text": "Number of speakers by endangerment status\nInformation on the endangerment status of the languages in the dataset was obtained from GlottoLog. The following strip chart show the number of speakers for each of the studies (each point) categorised by the endangerment of the language. Of course there are way more studies on safe languages, and if we focus on the first three categories of endangerment (safe, vulnerable, definitely endangered) there is a tendency to have a decreasing number of speakers. Considering though that we are talking of very low numbers of speakers (5-10) I am not sure it is actually relevant that definitely endangered languages have a lower median than safe languages. Difficult to say anything about higher endangerment levels given the low number of studies.\n\n\n\n\n\n\n\n\n\nWhile of course making generalisations based on this cursory analysis would not be wise, there seems to be a tendency for studies to have a very low number of speakers (median 5 speakers over study). The majority of studies have obtained data from 10 speakers or less, independent of publication year and endangerment status of the language enquired."
  },
  {
    "objectID": "posts/2022-04-05-bayesian-ci-width-power-analysis/index.html",
    "href": "posts/2022-04-05-bayesian-ci-width-power-analysis/index.html",
    "title": "Bayesian CrI-width power analysis",
    "section": "",
    "text": "This post shows how to do a quick and dirty Bayesian power analysis.\n“Power” analysis might not be a very appropriate term when Bayesian statistics is concerned. A good alternative could be “precision” analysis, since the method presented in this post is about estimate precision.\nMore specifically, the aim of this type of analysis is to find the approximate minimum sample size required to reach a given level of precision. By precision, I mean the width of the posterior probability of the effect of interest and, by corollary, the widths of its Credible Intervals (CrI). The smaller the width of posterior/CrI, the greater the precision of the estimate.\nTo calculate the minimum sample size for a particular precision value, we can take advantage of the formula of the standard error of the mean:\n\\[\nse = \\frac{\\sigma}{\\sqrt{n}}\n\\]\nwhere \\(se\\) is the standard error of the mean, \\(\\sigma\\) is the sample standard deviation and \\(n\\) is the sample size.\nNote that in Bayesian statistics, the \\(se\\) is the standard deviation of the posterior probability of the effect of interest.\nIn the scenario of a power analysis, we want to know which \\(n_e\\) we need to get a specific \\(se_e\\). We can calculate the expected sample size \\(n_e\\) to get a specific \\(se_e\\) by plugging in the observed \\(se_o\\), the known sample size \\(n_o\\) and the chosen \\(se_e\\), in the following formula (which is derived from the standard error formula above).\n\\[\nn_e = \\left( \\frac{\\sqrt{n_o} \\times se_o}{se_e}\\right)^2\n\\]\nLet’s see how to calculate \\(n_e\\).\nImagine you have fitted a Bayesian linear model to f0 values with formality as a predictor (formal vs informal speech). Let’s say the posterior probability of the effect of formality has a 95% CrI = [-10, +30] Hz, meaning that the standard deviation is 10 Hz. In total, there were 150 data points.\nSo, the observed standard error (i.e. the standard deviation of the posterior) is \\(se_o = 10\\), the sample size is \\(n_o = 150\\).\nThen we need to choose the standard error \\(se_e\\) we would want to be able to get if we ran a second iteration of the study. Let’s say we want an \\(se_e\\) of 5 Hz. Now, which is the \\(n_e\\) we need to get \\(se_e = 5\\)?\nEasy! We just plug in the numbers to get \\(n_e\\).\n\nn_o &lt;- 150\nse_o &lt;- 10\nse_e &lt;- 5\n\nn_e &lt;- ( ( sqrt(n_o) * se_o ) / se_e )^2\nn_e\n\n[1] 600\n\n\nThe sample size required to go from an \\(se_o\\) of 10 Hz to an \\(se_e\\) of 4 Hz is 600. 😱\nSo to get an \\(se\\) that is half of the observed one we would need 4 times the number of data points.\n\nFunctions ex machina\nLet’s spice our coding up a bit and write a few functions we can use to calculate samples sizes for different &se_e$s.\nAlso, so far we’ve been talking about \\(se_e\\) or, in other words, the standard deviation of the of the posterior probability of the effect of interest. If you remember your probability 101, you should know that the width of the 95% CrI of a posterior probability is 4 times the standard deviation.\nSo let’s write a function to calculate \\(n_e\\) based on the width of the 95% CrI, rather than on the \\(se_e\\).\n\nestimate_n &lt;- function(obs_se, obs_n, width, divide = 1) {\n  sigma &lt;- sqrt(obs_n) * obs_se\n  se &lt;- width / 4\n  new_n &lt;- (sigma / se)^2\n  return(new_n / divide)\n}\n\nLet’s take it for a spin, using the numbers from the example above. The \\(se_o\\) we observed was 10 Hz, that’s corresponds to a width of \\(10 * 4 = 40\\) Hz. (Note that the first argument is the \\(se_o\\), not the width, but you can change that for consistency if you wish). The sample size \\(n_o\\) was 150. The \\(se_e\\) we want was 5 Hz, so the width is \\(5 * 4 = 20\\) Hz.\nLet’s plug in these numbers.\n\nestimate_n(obs_se = 10, obs_n = 150, width = 20)\n\n[1] 600\n\n\nAs we have already seen above, to get a 95% CrI width of 20 Hz, we would need at least 600 observations.\nNow let’s define a few functions that calculate the required sample size at different widths and create a plot.\n\nget_obs_range &lt;- function(obs_se, obs_n, min_width = 1, max_width, by = 1, divide = 1) {\n  obs_range &lt;- NULL\n  for (i in seq(min_width, max_width, by = by)) {\n    obs_range &lt;- c(obs_range, estimate_n(obs_se, obs_n, i, divide))\n  }\n  return(obs_range)\n}\n\nplot_obs_range &lt;- function(obs_se, obs_n, min_width = 1, max_width, by = 1, divide = 1) {\n  obs_range &lt;- get_obs_range(obs_se, obs_n, min_width, max_width, by, divide)\n\n  ggplot2::ggplot() +\n    aes(x = seq(min_width, max_width, by = by), y = obs_range) +\n    geom_point() +\n    geom_path() +\n    labs(\n      caption = paste0(\"SE = \", obs_se, \", \", obs_n, \" obs\"),\n      x = \"CI width\",\n      y = paste0(\"Estimated N \", \"(N/\", divide, \")\")\n    )\n}\n\nLet’s now plot the required sample sizes to reach a 95% CrI width in the range from 10 to 50, by 5.\n\nplot_obs_range(10, 150, min_width = 10, max_width = 50, by = 5) +\n  scale_y_continuous(breaks = seq(0, 3000, 250))"
  },
  {
    "objectID": "posts/2021-04-24-on-phonologisation/index.html",
    "href": "posts/2021-04-24-on-phonologisation/index.html",
    "title": "On phonologisation",
    "section": "",
    "text": "After the post on the definition of random effects, I thought about writing another one on the definition of phonologisation.\nAs part of my PhD thesis on the effect of consonant voicing on vowel duration, I briefly reviewed the five definitions of phonologisation I could find in the literature. This post includes text from my thesis and expands on a few points.\nThe main take-away of the sections to follow is that what one means with phonologisation is (unsurprisingly) dependent on the set of assumptions that are part of the framework within which the term is used. Secondly, these definitions are mutually exclusive, to an extent such that one’s argument based on one definition might be inappropriate under another definition. It is thus important to always contextualise the use of the term when employed, even when the meaning might be self-evident from the context."
  },
  {
    "objectID": "posts/2021-04-24-on-phonologisation/index.html#footnotes",
    "href": "posts/2021-04-24-on-phonologisation/index.html#footnotes",
    "title": "On phonologisation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that in generative phonology, of which Lexical Phonology is a strand, speakers are assumed to store abstract, underlying phonemic forms, or representations, in memory. These underlying forms, to be produced, go through a series of neuro-cognitive processes, or derivation, that generate a surface representation which is then sent to the motor system which executes the motor plan corresponding to that surface representation. The details widely vary depending on the model or framework.↩︎"
  },
  {
    "objectID": "posts/2021-03-28-methods-as-theory/index.html",
    "href": "posts/2021-03-28-methods-as-theory/index.html",
    "title": "Methods as theory",
    "section": "",
    "text": "At least in linguistics, there is a general tendency to contrast theory with methods. This dichotomy is also reflected in the classification of academic papers as theoretical or methodological.\nIn this brief post I will argue that the theory/methods divide is epistemologically incoherent, and I will instead propose a taxonomy in which methods are subsumed under theory and are part of it."
  },
  {
    "objectID": "posts/2021-03-28-methods-as-theory/index.html#footnotes",
    "href": "posts/2021-03-28-methods-as-theory/index.html#footnotes",
    "title": "Methods as theory",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe tacit role of the “community” in the process of accepting theories is brilliantly explored and systematised in the classic work by Kuhn (1962). See Bird (2018) for an overview of Kuhn’s ideas.↩︎\nI use science here in the most inclusive sense, as opposed to pseudo-science.↩︎\nIn future posts I would like to expand on the idea that methods become embedded within theory by focussing on statistical modelling, and on the helpful but often neglected concepts of basic (pure) and applied science and how these can further illuminate the epistemology of theory I sketched here.↩︎"
  },
  {
    "objectID": "posts/2021-12-01-how-to-simplify-your-study-design/index.html",
    "href": "posts/2021-12-01-how-to-simplify-your-study-design/index.html",
    "title": "How to simplify your study design",
    "section": "",
    "text": "We have all been there.\nWe have run a study with a thoroughly thought-out research design. We got participants from the selected target population. Each participant has gone through the tasks of the study, to gather data from several crossing conditions and now the time has come for you to run (the analysis) FOR. YOUR. LIFE.\nAnd then THE HORROR.\nYou don’t know how to deal with all of the conditions, your statistical models are overwhelmed by too many 3 or 4-way interactions, although in most cases they just don’t converge… So you drop some interactions, but you feel you are doing something cheeky. Then you decide to conflate a few groups: that will at least reduce the number of values for some conditions.\nBut you just feel lost…\nUnfortunately I do not have a simple solution to that.\nSorry to disappoint you! (But read on…)\nNot all is lost!\nBecause now you are planning a new study. Starting afresh. After all… tomorrow is another day!\nHere’s a few tips on how to make your study design simpler and save your… face."
  },
  {
    "objectID": "posts/2021-12-01-how-to-simplify-your-study-design/index.html#think-ahead-about-the-statistical-analysis",
    "href": "posts/2021-12-01-how-to-simplify-your-study-design/index.html#think-ahead-about-the-statistical-analysis",
    "title": "How to simplify your study design",
    "section": "Think ahead about the statistical analysis",
    "text": "Think ahead about the statistical analysis\n\n\n\n\n\nWe say this all the time, but we rarely actually do it: choosing the statistical analysis should be part of the study design process.\nVery often, we spend a lot of time on what research questions/hypotheses we want to empirically test, which conditions we need, which population, and so on. But not so often we then think of the actual statistical analysis of the data we will collect based on the planned study design.\nThinking ahead about what type of analysis you will perform will help you figure out if perhaps the overall design is too ambitious and will give you the time to make changes to the design so that the data analysis will be easier.\nFor example, let’s assume we want to test people’s ability to recognise pitch differences across three different conditions. A set of recordings is played first with no background noise, then with white noise, and finally with a recording of people chatting in the background. We decide to have 30 trials in the no-noise condition (since this is just the baseline and we don’t need that many trials) and 50 trials in the other two conditions. After data collection you will compare the mean baseline of each subject with what happens in the other two conditions.\nYou start the study and collect data.\nNow it’s time to compare how the second and third condition differ from the baseline. You realise that you can’t simply compare the mean baseline, because you also want to account for the fact that listeners get attuned to the noise or task while performing it, so that later trials might show less of an effect. You could look at the change in performance of pitch change recognition across time within each condition, so that you can check if white noise and people chatter are different from the baseline condition with no noise.\nBut you have one problem…the number of trials are less in the baseline condition then in the other two conditions. It’s too late now!\nWhat the story teaches us is that, if we had carefully thought of the kind of analysis we wanted to do (i.e. compare the performance across time) we would have realised that to do so the number of trials needs to be the same.\nThis is why we always recommend thinking the specifics of the analysis before hand: why statistical model will you use? which predictors will be in the model? which data transformation will you apply? …"
  },
  {
    "objectID": "posts/2021-12-01-how-to-simplify-your-study-design/index.html#minimise-the-factorial-design",
    "href": "posts/2021-12-01-how-to-simplify-your-study-design/index.html#minimise-the-factorial-design",
    "title": "How to simplify your study design",
    "section": "Minimise the factorial design",
    "text": "Minimise the factorial design\n\n\n\n\n\nAnother simple tip is to minimise the “factorial design” of the study.\nBy factorial design I mean the tabulated structure of conditions/groups/contexts that are controlled in the study.\nA simple factorial design is the following:\n\n\n\n\ncity\nvillage\n\n\n\n\nyoung\n\n\n\n\nold\n\n\n\n\n\nThis is a classic 2-by-2 design (\\(2 \\times 2\\)), with Age (young or old) and Place (city or village).\nYou plan to have 40 participants in total, which means these are the tabulated counts:\n\n\n\n\ncity\nvillage\n\n\n\n\nyoung\n10\n10\n\n\nold\n10\n10\n\n\n\nBut you also want to know if level of education interacts with Age and/or Place. So you decide to go with this design:\n\n\n\nDiploma\ncity\nvillage\n\n\n\n\nyoung\n\n\n\n\nold\n\n\n\n\n\n\n\n\nDegree\ncity\nvillage\n\n\n\n\nyoung\n\n\n\n\nold\n\n\n\n\n\nSo now we went from a \\(2 \\times 2\\) to a \\(2 \\times 2 \\times 2\\) design. Before we had 4 contextual combinations (young from the city, old from the city, young from the village, old from the village), but now we have 8 combinations.\nThe new design now would require us to be able to check three 2-way interactions and a 3-way interaction. Checking interactions requires sufficient data, and the more interactions you have and the higher the order of the interaction, the more data you need.\nSo assuming you had 40 participants in total, well distributed across the factorial design, that means that you are trying to estimate effects based on only 5 participants per combination.\n\n\n\nDiploma\ncity\nvillage\n\n\n\n\nyoung\n5\n5\n\n\nold\n5\n5\n\n\n\n\n\n\nDegree\ncity\nvillage\n\n\n\n\nyoung\n5\n5\n\n\nold\n5\n5\n\n\n\nIn fact, a \\(2 \\times 2 \\times 2\\) design would already be an improvement on the average factorial design we normally employ in linguistics.\nLet’s think phonetics: 5 vowel qualities, 3 consonant places of articulation, 3 phonation types, 2 conditions of lexical stress, 3 prosodic conditions.\nWhich means you have to estimate 270 “cells” from the factorial table. A monster!!!\n\n\n\n\n\n\nIt is immediately clear that this would not be feasible, at least with the limited time and resources we researchers have.\nSo, the moral of the story is: simplify your factorial design as much as possible, by focussing on those contexts that are critical to the research question.\nIn other words, don’t add contexts in just because “they are expected to make a difference”, if these are not the critical ones. Of course, any type of context can potentially make a difference, but if we had to control for all the imaginable contexts within a single study, we would be collecting data for centuries."
  },
  {
    "objectID": "posts/2021-12-01-how-to-simplify-your-study-design/index.html#if-you-care-about-interactions-only-include-the-critical-ones-in-the-model",
    "href": "posts/2021-12-01-how-to-simplify-your-study-design/index.html#if-you-care-about-interactions-only-include-the-critical-ones-in-the-model",
    "title": "How to simplify your study design",
    "section": "If you care about interactions, only include the critical ones in the model",
    "text": "If you care about interactions, only include the critical ones in the model\n\n\n\n\n\nYou have a \\(3 \\times 4 \\times 2 \\times 3\\) design. This means that, if you include all the logical interactions, you end up with trying to estimate N different interactions.\nUnless you have an impractical amount of data at hand, you will very likely have troubles fitting the model.\nWhat you can do, in these cases, is to add the main effects plus only those interactions that are relevant for your research question/hypothesis.\nIn other words, if you are investigating whether there is a specific interaction between two of the four predictors, then you could just include that interaction.\nNote that if you go this route, you have to decide with interactions to include before collecting data, based on expectations.\nIf you are interested in all logical interactions because you have really no expectations, then perhaps you should stick to exploratory and descriptive analyses."
  },
  {
    "objectID": "posts/2021-12-01-how-to-simplify-your-study-design/index.html#make-sure-your-factorial-design-is-not-rank-deficient",
    "href": "posts/2021-12-01-how-to-simplify-your-study-design/index.html#make-sure-your-factorial-design-is-not-rank-deficient",
    "title": "How to simplify your study design",
    "section": "Make sure your factorial design is not “rank deficient”",
    "text": "Make sure your factorial design is not “rank deficient”\n\n\n\n\n\nSometimes we work with data that naturally lacks some of the combinations of conditions we are interested in.\nFor example, you might be working with a vocalic system in which one or two vowel qualities lack a long counterpart, while all the other qualities have both a short and a long counterpart.\nYou might be tempted then to have two separate predictors: vowel quality and length. This means that for some of the quality/length combinations there won’t be any data.\nThe situation when a factorial design has some “cells” that are not represented in the data is described as rank deficiency. Or to put it differently, the data is rank deficient.\nThis is not a problem per se, since linear models can cope with rank deficient data, and you usually just get a warning from R.\nBut with more complex models, and especially if you are also including random effects, having rank deficient data can at times result in singular fit/non-convergence."
  },
  {
    "objectID": "posts/2021-12-01-how-to-simplify-your-study-design/index.html#collect-enough-data",
    "href": "posts/2021-12-01-how-to-simplify-your-study-design/index.html#collect-enough-data",
    "title": "How to simplify your study design",
    "section": "Collect enough data",
    "text": "Collect enough data\n\n\n\n\n\nNo way you can make the design simpler?\nThen one solution is to collect enough data for that design. Depending on whether you will be using frequentist or Bayesian statistics, you have different options.\nTo know in advance how much data is enough when doing frequentist statistics, you will have to run a prospective power analysis. The main idea of a power analysis is that you pick the smallest meaningful effect size you want to be able to detect (i.e. p &lt; 0.05) and you can get an estimate of statistical power at varying sample sizes. Note that to be able to run a prospective power analysis you need to have a fair amount of information on the target population variance. Check out the simr package for power analyses in R.\nOne option if you will be using Bayesian statistics, is to define a Region Of Practical Equivalence (ROPE), which is a range of values around 0 that you would consider not to be meaningful (in other words, values below the smallest meaningful effect size). Then you can collect data until the Credible Interval width of the effect estimate of interest is equal or smaller of that of the ROPE. See a full description of this method in the following paper: https://doi.org/10.1016/j.jml.2018.07.004."
  },
  {
    "objectID": "posts/2021-12-01-how-to-simplify-your-study-design/index.html#use-dimensionality-reduction-techniques",
    "href": "posts/2021-12-01-how-to-simplify-your-study-design/index.html#use-dimensionality-reduction-techniques",
    "title": "How to simplify your study design",
    "section": "Use dimensionality-reduction techniques",
    "text": "Use dimensionality-reduction techniques\n\n\n\n\n\nDo you have a lot of predictors and you are trying to figure out which one is correlated with the outcome variable? You have tried many different models, and most of those don’t converge or you find it overwhelming to try and decipher those models that did converge?\nThen you can use one of several techniques for dimensionality reduction.\nTwo very common techniques are Principal Component Analysis and Discriminant Analysis for continuous outcome variables and Correspondence Analysis for discrete outcome variables.\nYou can find tutorials on http://www.sthda.com/english/ and in the related book, Practical Guide To Principal Component Methods in R."
  },
  {
    "objectID": "posts/2021-12-01-how-to-simplify-your-study-design/index.html#go-bayesian",
    "href": "posts/2021-12-01-how-to-simplify-your-study-design/index.html#go-bayesian",
    "title": "How to simplify your study design",
    "section": "Go Bayesian",
    "text": "Go Bayesian\n\n\n\n\n\nIf you are still reading, probably you are hoping for an easier and more straightforward solution. This is the last resort.\nGo Bayesian.1\nBayesian statistics is a framework of statistical inference, in which uncertainty plays a central role.\nOne of the assets of Bayesian statistics is that you can get an estimate, not only of the effect of interest, but also of the uncertainty around that estimate in more intuitive terms than what you would get under a frequentist framework.\nNote that Bayesian statistics is not a different kind of test or set of models. You can run the same models you are familiar with (logistic regression, mixed-effects models, etc), but with a more robust estimation method.\nOne practical advantage of Bayesian statistics is that model convergence is rarely an issue. Even with very little data, the model will provide you with estimated effects.\nThe catch is that the less the data, the more the uncertainty.\nSo you will still get an estimate of the effect of interest even with little data, but that estimate will span a quite wide range of values.\nIf that will do for you and you don’t have the resources to collect more data or enough prior information to carry out prospective analyses, then you can be reassured that a Bayesian model will allow you to learn something from the data, even when you don’t have much of it.\nIf you worry about the uncertainty part of the deal, you should read this paper: https://doi.org/10.1515/ling-2019-0051.\nIf you wish to embark in the journey of learning Bayesian statistics, I recommend Statistical (Re)thinking: A Bayesian Course with Examples in R and Stan."
  },
  {
    "objectID": "posts/2021-12-01-how-to-simplify-your-study-design/index.html#footnotes",
    "href": "posts/2021-12-01-how-to-simplify-your-study-design/index.html#footnotes",
    "title": "How to simplify your study design",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWondering about the donkey gif? Read this: http://doingbayesiandataanalysis.blogspot.com/2011/07/horses-donkies-and-mules.html.↩︎\nI am referring to what is most commonly called theoretical work, but for several reasons I won’t go into here I think this label is epistemologically unhelpful.↩︎\nI have recently being appointed Senior Teaching Coordinator for Statistics in the Linguistics and English Language department of the University of Edinburgh. I just love this job, in every aspect, and it has opened a creative outlet that I would have sorely missed had I kept on with a research-based career. So here you go: I am one example of someone who was given the opportunity to give back to academia while redirecting my focus to teaching rather than research.↩︎"
  },
  {
    "objectID": "posts/2021-01-09-phono-restrictions-pie/index.html",
    "href": "posts/2021-01-09-phono-restrictions-pie/index.html",
    "title": "On the phonotactic restrictions of Proto-Indoeuropean roots",
    "section": "",
    "text": "Proto-Indoeuropean lexicon is based on monosyllabic roots which have an alternating (ablaut) root vowel preceded and followed by consonants. In this post, I will share some thoughts on the phonotactic restrictions which seem to dictate which consonants can cooccur in a root. I will focus here on stops and laryngeal features. Although I have some formal training in Indoeuropean linguistics, what follows is more of an academic game, so I invite the reader not to expect a fully developed argument.\nThe traditional reconstruction of Proto-Indoeuropean (PIE) stops includes the following laryngeal oppositions:\n\nVoiceless unaspirated stops (T),\nVoiced unaspirated stops (D), and\nVoiced aspirated (murmured) stops (Dʰ).\n\nThe possible logical combinations of these laryngeal contrasts in a CVC- root, reviewed in Cooper (2009), are the following (the base ablaut vowel /e/ is used for illustrative purposes):\n\n\n\n\nT\nD\nDʰ\n\n\n\n\nT\nTeT\nTeD\n**TeDʰ\n\n\nD\nDeT\n**DeD\nDeDʰ\n\n\nDʰ\n**DʰeT\nDʰeD\nDʰeDʰ\n\n\n\nThe double asterisks signal those combinations which are not attested in the reconstructed PIE lexicon, namely **TeDʰ, **DED, and **DʰeT. Typologically, these restrictions, in combination with the reconstructed laryngeal oppositions, are somewhat baffling. There are no known languages which unequivocably contrasts voiceless stops with voiced stops and voiced aspirated stops.\nGamkrelidze & Ivanov (1994) and others have used this typological incongruence (with other aspects of the reconstructed PIE phonology) to argue that the reconstructed voiced (D) stops were in fact a type of ejective or glottalised consonants (which gave the name ‘Glottalic theory’). I’ll argue here that a reinterpretation of the restrictions seen above within Glottalic theory offers a sensible and more typologically grounded account of such restrictions.\nAccording to Glottalic theory, voiced stops (D) are glottalised consonants (T’), voiced aspirated stops (Dʰ) are voiced stops with aspirated allophones (D), and the voiceless stops are voiceless stops with aspirated allophones (T). The re-thought laryngeal contrasts thus are:\n\nVoiceless stops (T),\nVoiced stops (D),\nGlottalised (ejective) stops (T’).\n\nLet’s now rewrite the restriction table above:\n\n\n\n\nT\nT’\nD\n\n\n\n\nT\nTeT\nTeT’\n**TeD\n\n\nT’\nT’eT\n**T’eT’\nT’eD\n\n\nD\n**DeT\nDeT’\nDeD\n\n\n\nThe restriction **T’eT’ seems now more plausible, since it involves a typologically less common type of stop. (I remember from my time at the University of Pavia Prof. Gianguido Manzelli telling us there are American languages which have exactly this phonotactic restriction. Unfortunately I fail to remember which these are.) But what about **TeD and **DeT?\nIf we observe the attested combinations, a pattern emerges:\n\n\n\nT\nD\n\n\n\n\nTeT\nDeD\n\n\nT’eT\nT’eD\n\n\nTeT’\nDeT’\n\n\n\nThere seems to be an opposition between ‘T-roots’ and ‘D-roots’, where T’ stops are kind of neutral stops (they can appear in both type of roots). My thought on this is that, speculatively, the T~D contrast derives from an earlier suprasegmental contrast that was assigned to the root, rather than to the individual stops. This could have been something like stress, tone, pitch, or else (also, think about word-level nasality in South American languages, in which a word is either all nasal or oral).\nIf indeed roots could be specified as having the T feature (whatever that was) or the D feature, then it is possible that the glottalised (ejective) stops T’ were immune to changes acted by the root-level T~D distinction. Ejective stops in particular are strongly articulated consonants, and this might explain their resilience to being affected by suprasegmental properties of the root.\nThus, the reconstructed original laryngeal system might have contrasted voiceless stops and ejective stops. There is indeed a dozen languages with this system in South America alone (data from the SAPhon database v1.1.4), for example Alacalufe (Alacalufan), Chulupí (Mataco), and Selk’nam (Chon).\nAll this is of course internal reconstruction, so highly speculative, and as mentioned above, it is not meant to be more than brainstorming. I hope that the potential readers had fun reading this anyway and I am happy to hear about their thoughts.\n\n\n\n\n\n\n\nReferences\n\nCooper, Adam I. 2009. Similarity avoidance in the Proto-Indo-European root. University of Pennsylvania Working Papers in Linguistics 15(1). 8.\n\n\nGamkrelidze, Thomas Valerianis & Vyacheslav Vsevolodovich Ivanov. 1994. Indo-European and the Indo-Europeans: A reconstruction and historical analysis of a proto-language and a proto-culture. Translated by J. Nichols. Berlin–New York: Mouton de Gruyter. https://doi.org/10.1515/9783110815030."
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "My research interests span a range of topics within linguistics, although the main focus is on the study of speech sounds, and in particular speech production, from a variety of intersecting perspectives, including:\n\nAcoustics and articulation.\nDescriptive, historical, and comparative linguistic (typology).\nLanguage endangerment.\nComputational modelling.\n\nThe other strand of my research expertise is related to research methods and statistics. In particular, I am an enthusiastic advocate of Open Research (aka Open Science) and Bayesian inference.\nFor an overview of the research meta-models that inform my research, see the Meta page.\n\nCurrent projects\n\n\n\n\n\n\nIntrinsic vowel duration and gestural distance\n\n\n\nIntrinsic vowel duration is the tendency for high vowels to be shorter and low vowels to be longer. In this project I will investigate if articulator origin-to-target distance is sufficient to explain vowel duration or if vowels include category-specific durational targets.\n\n\n\n\n\n\n\n\nHemispheric differences in specificity effects of priming\n\n\n\nProject with Jeremy Steffman looking at how auditory priming effects are modulated depending on which hemisphere processes the speech signal.\n\n\n\n\n\n\n\n\nGallo-Italian vitality\n\n\n\nIn this project with Jessica Hampton and Simone De Cia, we are conducting a survey study of the vitality of Gallo-Italian in the north of Italy.\n\n\n\n\nPast projects\n\n\n\n\n\n\nMany Speech Analyses\n\n\n\n\n\nThe Many Speech Analyses project (with Timo Roettger and Joseph V. Casillas) set out to quantify the analytic flexibility in the speech sciences and explored how it affects our scientific conclusions. To that end, we asked speech researchers to analyse the same data set in order to answer the same research question.\nThe paper with the study results has been published in AMPPS (DOI 10.1177/25152459231162567, Research Compendium https://osf.io/3bmcp/).\n\n\n\n\n\n\n\n\n\nThe sounds of Albanian\n\n\n\n\n\nIn collaboration with Lejda Kapia, Josianne Riverin-Coutlée, and Stephen Nichols, we have investigate the sound system of Albanian.\nThe first objective of the project was to produce an IPA illustration for Tosk Albanian which has been published in JIPA (DOI 10.1017/S0025100322000044, Research Compendium https://osf.io/vry3h/).\n\n\n\n\n\n\n\n\n\nHuman interaction and the evolution of spoken accent\n\n\n\n\n\nI worked within the ERC project Human interaction and the evolution of spoken accent (PI Prof. Jonathan Harrington) at the Institut für Phonetik und Sprachverarbeitung. This project employs real-time MRI data to investigate, among other things, how articulatory aspects of speech can pave the way for sound change.\n\n\n\n\n\n\n\n\n\nNasal coarticulation and sound-change: a real-time MRI study\n\n\n\n\n\nI conducted research within the DFG project Nasal coarticulation and sound-change: a real-time MRI study (PI Prof. Jonathan Harrington).\n\n\n\n\n\n\n\n\n\nVowel duration and consonant voicing: a production study\n\n\n\n\n\nAs part of my PhD research at the University of Manchester, supervised by Dr Ricardo Bermúdez-Otero and Dr Patrycja Strycharczuk), I investigated the effect of consonant voicing on vowel duration, using a combination of acoustic analyses, ultrasound tongue imaging and electroglottography. My thesis is available here.\n\n\n\n\n\nGlossolects\n\n\n\n\n\n\n\nThe map shows in blue the main glossolects I work(ed) with, and in red glossolects I have studied during my time at University and forgotten to different degrees (approximate locations).\nOverall, my interests and expertise cover the following macro-glossolects:\n\nIndo-European.\nOceanic.\nSouth American.\n\nI would very much welcome offers of collaboration on glossolects from other areas of the world, especially from Africa and Asia, which are alas the ones I am the least familiar with."
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Courses",
    "section": "",
    "text": "Courses\nCheck the Data Analysis @ UoE LEL website for learning resources on research methods in linguistics.\n\n\n\n\n\n\nCurrent\n\n\n\n\nQuantitative Methods for Linguistics and English Language (UG and PG). Course website\n\n\n\n\n\n\n\n\n\nPrevious\n\n\n\n\nData Analysis for Linguistics and English Language (undergraduate). Course website\nStatistics and Quantitative Methods [LASC11171]. Course website\nStatistics and Quantitative Methods [LASC11172]. Course website\nMaking a language: Conlanging and Linguistic Typology (Guided Research in Linguistics and English Language). Course website\nResearch Methods in Developmental Linguistics [LASC11127].\nIndividual classes taught in Introduction to Language Research [LASC11091], Phonetics and Laboratory Phonology [LASC11137], Speech Production and Perception [LASC11138].\n\n\n\n\n\nWorkshops\nHere you can find information on workshops I offer. Adaptations of pre-existing workshops (e.g. shorter/longer version, focus on a specific topic/field) are possible and proposals for new workshops are welcome. Get in contact with me for queries.\nIf you are looking for workshops run internally (in the LEL department of UoE), please check the STeW page on the Data Analysis @ UoE LEL.\n\n\n\n\n\n\nlearnBayes: Bayesian linear models for Linguistics\n\n\n\nAn introduction to Bayesian linear models in R for linguists.\nSee the worksop website.\n\n\n\n\n\n\n\n\nbasicBayes: Learn Bayesian Linear Models for Beginners\n\n\n\nThis workshop introduces Bayesian linear models in R to participants without previous knowledge of linear models (but knowledge of R).\nSee the worksop website.\n\n\n\n\n\n\n\n\nlearnGAM: Learn Generalised Additive (Mixed) Models\n\n\n\nThis workshop introduces participants to Generalised Additive (Mixed) Models, or GA(M)Ms, which can be used to model non-linear data (e.g. f0 contours, formant trajectories, tongue contours) and spatial data (Wood 2017).\nSee the worksop website.\n\n\n\n\n\n\n\n\nintro: Data visualisation with R\n\n\n\n The past two decades have seen a dramatic increase in availability of data, which has expanded the range of phenomena that can be investigated. The Humanities and Social Sciences can now benefit from such an abundance of data and integrate qualitative and quantitative methods.\nThis workshop introduces absolute beginners to computational principles and tools of data visualisation, processing, and exploration with the statistical software R.\nNo previous knowledge of quantitative analysis, statistics, nor programming required, just curiosity and a sense of adventure.\nYou can learn more about the workshop by visiting the website.\n\n\n\n\n\n\n\n\nlearnB4SS: Learn Bayesian Analysis for Speech Sciences\n\n\n\n Together with Timo Roettger and Joseph V. Casillas, we introduce the logic of Bayesian inference and compare it to Null Hypothesis Significance Testing (NHST). After providing a brief conceptual introduction, the course walks through a Bayesian statistical analysis using R (R Core Team 2020) and the package brms (Bürkner 2018).\nWe explain how to set up a Bayesian regression model (including setting appropriate priors), how to interpret the results, how to diagnose model convergence, and how to visualize and report the results. In hands-on exercises, the participants immediately apply their knowledge to a speech data set in R.\nCheck out the workshop website for more info.\n\n\n\n\n\n\n\n\nData Version Control for Researchers\n\n\n\nA fundamental aspect of Open Research is ensuring the reproducibility of data processing and analyses. Part of this endeavour is concerned with data versioning and backup. Many researchers have now become familiar with versioning systems like git, popularised by the GitHub online platform.\nThis workshop will introduce participants to the Data Version Control software (DVC), specifically designed to work efficiently with non-textual data types. DVC works in unison with git, so that git users can simply add it to their existing workflow and integrate code and data versioning.\nAfter a brief conceptual introduction to version control, git and DVC, participants are guided through a hands-on tutorial which teaches them the basics of git and DVC versioning using a toy project. Only basic familiarity with file management and command line is required (https://tutorial.djangogirls.org/en/intro_to_command_line/).\nFind here the workshop materials.\n\n\n\n\n\n\n\n\nIntroduction to (Xe)LaTeX\n\n\n\nXeLaTex is is a mark-up language for text editing and typesetting (and more). It’s a dialect of the LaTeX format that introduces full Unicode support and handling of TTF and OTF fonts.\nCheck out the workshop materials.\n\n\n\n\n\n\n\n\n\n\nReferences\n\nBürkner, Paul-Christian. 2018. Advanced Bayesian multilevel modeling with the R package brms. The R Journal 10(1). 395–411. https://doi.org/10.32614/RJ-2018-017.\n\n\nR Core Team. 2020. R: A language and environment for statistical computing.\n\n\nWood, Simon. 2017. Generalized additive models: An introduction with R. 2nd edn. Chapman and Hall/CRC. https://doi.org/10.1201/9781315370279."
  },
  {
    "objectID": "posts/2022-07-22-one-thousand-and-one-names/index.html",
    "href": "posts/2022-07-22-one-thousand-and-one-names/index.html",
    "title": "One Thousand and One names",
    "section": "",
    "text": "The following table lists common “portmanteau” names for linear models. Note that different traditions/disciplines might use one particular name more often than the others.\nMy usual recommendation is to move away from using specific names like “logistic regression” or “mixed-effects models” and instead just specify what kind of components your linear model has (see the Description column in the table).\n\n\n\n\n\n\n\n\nFormula\nDescription\nNames\n\n\n\n\nlm(y ~ x)\nLinear model with one predictor x using a Gaussian distribution for the outcome variable y\nsimple linear regression, simple linear model\n\n\nlm(y ~ x + z + ...)\nLinear model with two predictors or more using a Gaussian distribution for the outcome variable y\nmultiple linear regression, multiple linear model\n\n\nglm(y ~ x + ..., family = \"binomial\")\nLinear model with one or more predictors using a Bernoulli distribution for the outcome variable y\nlogistic regression, binomial regression, general(ised) linear model\n\n\nlmer(y ~ x + ... + (1 | z))\nLinear model with one or more predictors, including one or more random intercepts, using a Gaussian distribution for the outcome variable y.\nmixed-effects models, nested models, hierarchical models, multilevel models, cross-effects models (plus combinations of those and “linear” or “regression”)\n\n\nlmer(y ~ x + ... + (w | z))\nLinear model with one or more predictors, including one or more random intercepts and one or more random slopes, using a Gaussian distribution for the outcome variable y.\nSame as above. Sometimes “random-slope models”\n\n\nglmer(y ~ x + ... + (w | z), family = \"binomial\")\nLinear model with one or more predictors, including one or more random intercepts and one or more random slopes, using a Bernoulli distribution for the outcome variable y.\nSame as above, but includes “logistic”, “binomial” or “general(ised)” in the name\n\n\nglm(..., family = \"poisson\")\nLinear model with one or more predictors, including one or more random intercepts and one or more random slopes, using a Poisson distribution for the outcome variable y.\nSame as above but includes “Poisson” in the name\n\n\n\nNote: When specifying the binomial family in glmer(), the Bernoulli family is selected automatically under the hood"
  },
  {
    "objectID": "posts/2018-03-02-formants-tidy/index.html",
    "href": "posts/2018-03-02-formants-tidy/index.html",
    "title": "Vowel formants trajectories and tidy data",
    "section": "",
    "text": "With the advent of more powerful statistical methods for assessing time series data, it is now becoming more common to compare whole vowel formant trajectories rather then just using average values.\nIn this post I will show how to tidy a formant measurements dataset and plot formants using the tidyverse (Wickham 2017)."
  },
  {
    "objectID": "posts/2018-03-02-formants-tidy/index.html#the-pipe",
    "href": "posts/2018-03-02-formants-tidy/index.html#the-pipe",
    "title": "Vowel formants trajectories and tidy data",
    "section": "The pipe",
    "text": "The pipe\nAll the individual steps above can be chained by using the pipe %&gt;%. What the pipe does is simply “transferring” the output of the function before it as the input of the function after it.\n\ntrajectories &lt;- trajectories %&gt;%\n  pivot_longer(F1_05:F3_95, names_to = \"formant_int\", values_to = \"value\") %&gt;%\n  separate(formant_int, c(\"formant\", \"interval\"), convert = TRUE) %&gt;%\n  pivot_wider(names_from = formant, values_from = value)"
  },
  {
    "objectID": "posts/2021-04-22-vot-and-place-of-articulation/index.html",
    "href": "posts/2021-04-22-vot-and-place-of-articulation/index.html",
    "title": "R gist — VOT and place of articulation",
    "section": "",
    "text": "In this post, I plot data from Chodroff, Golden & Wilson (2019) in a 3D chart."
  },
  {
    "objectID": "posts/2021-04-22-vot-and-place-of-articulation/index.html#read-data",
    "href": "posts/2021-04-22-vot-and-place-of-articulation/index.html#read-data",
    "title": "R gist — VOT and place of articulation",
    "section": "Read data",
    "text": "Read data\n\nvot &lt;- read_csv(\"./data/chodroff2019/ChodroffGoldenWilson2019_vot_avg.csv\") %&gt;%\n  group_by(vot.category) %&gt;%\n  mutate(vot.mu_z = scale(vot.mu)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = poa.broad, values_from = c(vot.mu, vot.mu_z)) %&gt;%\n  mutate(vot_category = recode(vot.category, long.lag = \"long lag\", short.lag = \"short lag\"))"
  },
  {
    "objectID": "posts/2021-04-22-vot-and-place-of-articulation/index.html#mean-vot",
    "href": "posts/2021-04-22-vot-and-place-of-articulation/index.html#mean-vot",
    "title": "R gist — VOT and place of articulation",
    "section": "Mean VOT",
    "text": "Mean VOT\n\nvot %&gt;%\n  plot_ly(\n    x = ~vot.mu_labial, y = ~vot.mu_coronal, z = ~vot.mu_dorsal, color = ~vot_category, text = ~language,\n    marker = list(size = 5, opacity = 0.7),\n    hovertemplate = paste(\"&lt;b&gt;%{text}&lt;/b&gt;\", \"&lt;br&gt;Labial: %{x:.1r}\", \"&lt;br&gt;Coronal: %{y:.1r}\", \"&lt;br&gt;Dorsal: %{z:.1r}\")\n  )"
  },
  {
    "objectID": "posts/2021-04-22-vot-and-place-of-articulation/index.html#mean-vot-z-scores",
    "href": "posts/2021-04-22-vot-and-place-of-articulation/index.html#mean-vot-z-scores",
    "title": "R gist — VOT and place of articulation",
    "section": "Mean VOT (z-scores)",
    "text": "Mean VOT (z-scores)\n\nvot %&gt;%\n  plot_ly(\n    x = ~vot.mu_z_labial, y = ~vot.mu_z_coronal, z = ~vot.mu_z_dorsal, color = ~vot_category, text = ~language,\n    marker = list(size = 5, opacity = 0.7),\n    hovertemplate = paste(\"&lt;b&gt;%{text}&lt;/b&gt;\", \"&lt;br&gt;Labial: %{x:.1r}\", \"&lt;br&gt;Coronal: %{y:.1r}\", \"&lt;br&gt;Dorsal: %{z:.1r}\")\n  )"
  },
  {
    "objectID": "posts/2021-01-09-short-review/index.html",
    "href": "posts/2021-01-09-short-review/index.html",
    "title": "Short review of phonological databases",
    "section": "",
    "text": "List of available phonological databases (updated 2019-03-22):\n\nUCLA Phonological Segment Inventory Database (UPSID)\nLyon-Albuquerque Phonological Systems Database (LAPSyD)\nPhonetics Information Base and Lexicon (PHOIBLE)\nWorld Atlas of Language Structures (WALS)\nSouth American Phonological Inventory Database (SAPhon)\nBDPROTO Proto-language segment inventories (DBPROTO)\nDatabase of Eurasian phonological inventories (link)\nIndo-European Phonological Inventory Database (IEPhon, dead link)\n\n\nUCLA Phonological Segment Inventory Database\n\nnumber of records: 451 languages\ntype of sample: genetically balanced\ninterface: desktop and web\ndata: inventory, language family, comments, source\nsearchable: for language, number of sounds, frequency index, family and phonetic features\nsearch display: list\n\n\n\nLyon-Albuquerque Phonological Systems Database\n\nnumber of records: (in progress)\ntype of sample: not balanced\ninterface: web\ndata: consonant and vowel inventories, syllable structure, stress and tone systems, language location and classification\nsearchable: for language (name, iso, classification), sounds (table format), phonetic features, syllable\nsearch display: segment table, boolean (sound, feature, area, family, syllable)\n\n\n\nPhonetics Information Base and Lexicon\n\nnumber of records: 1,010 languages\ntype of sample: not balanced\ninterface: web\ndata: inventory, segment class, language location\nsearchable: for language (name, iso), sounds (list format), source\nsearch display: list\n\n\n\nWorld Atlas of Language Structures\n\nnumber of records: 2,679 languages\ntype of sample: balanced\ninterface: desktop and web\ndata: size of consonant inventory, size of vowel inventory, consonant-vowel ratio, voicing and gaps in plosive system, uvular consonant, glottalized consonants, velar nasal, reduplication\nsearchable: for language (name, iso, genus, family, macroarea; list format), characteristics (list format)\nsearch display: list and map\n\n\n\nSouth American Phonological Inventory Database\n\nnumber of records: 359 languages\ntype of sample: not balanced, South America\ninterface: web\ndata: segment inventory, suprasegmentals, language (name, iso, family, country)\nsearchable: for language (name, iso, family, country; list format and map), sounds (table)\nsearch display: table, list and map\n\n\n\nBDPROTO Proto-language segment inventories\n\nnumber of records: 137 languages\ntype of sample: genialogical diversity, convenience sample\ninterface: offline (csv, sql)\ndata: segment inventory, suprasegmentals, language (name, iso, family, homeland, time depth)\nsearchable: yes\nsearch display: none\n\n\n\nDatabase of Eurasian phonological inventories\n\nnumber of records: 416 languages\ntype of sample:\ninterface: web and offline (json)\ndata: segment inventory, suprasegmentals, language (name, family, group)\nsearchable: segment inventory, language, location\nsearch display: map, list, segments table\n\n\n\nIndo-European Phonological Inventory Database [dead link]\n\nnumber of records: 18 languages\ntype of sample: not balanced, Indo-European family\ninterface: web\ndata: segment inventory, language (name, family, area)\nsearchable: for language (name, family, country; list format and map), sounds (table)\nsearch display: table, list and map"
  },
  {
    "objectID": "posts/2021-07-20-contrasts/index.html",
    "href": "posts/2021-07-20-contrasts/index.html",
    "title": "Factors, coding and contrasts",
    "section": "",
    "text": "This post is an overview of how factors (i.e. categorical variables) are coded under the hood and which types of coding can be set in R.1"
  },
  {
    "objectID": "posts/2021-07-20-contrasts/index.html#summing-up",
    "href": "posts/2021-07-20-contrasts/index.html#summing-up",
    "title": "Factors, coding and contrasts",
    "section": "Summing up",
    "text": "Summing up\nTo sum up:\n\nFactors are vectors that code categorical variables.\nThe values in a factor are called levels.\nRegression models cannot work directly with factors, so these are coded using numbers.\nDummy coding is one way of coding factors as numbers using one or more numeric variables of 0s and 1s."
  },
  {
    "objectID": "posts/2021-07-20-contrasts/index.html#treatment-contrasts",
    "href": "posts/2021-07-20-contrasts/index.html#treatment-contrasts",
    "title": "Factors, coding and contrasts",
    "section": "Treatment contrasts",
    "text": "Treatment contrasts\nThe term treatment contrasts comes from the clinical sciences where you test, for example, the efficacy of a medical intervention (a drug, surgery, etc…) by comparing a control group (which has not received the “treatment”) with a group that has received the medical intervention (the treatment group).\nThe control group can be used as the reference group to see if the treatment group has benefited from the medical treatment (i.e. if the treatment group’s health has improved after the intervention relative to the control group, then one can infer that the treatment was effective).\nLet’s look at treatment contrasts in R.\nIn the previous section, we’ve been illustrating dummy coding by assigning 0s and 1s using one or more dummy variables. In practice, you do not need to do that to run real analyses, because R does that under the hood for you.\nFactors in R are coded with treatment contrasts by default. Also by default, the first level is set as the reference level (the order is alphabetical by default). The reference level is the level that gets coded only with 0s, as we have seen above for the dinosaur’s diet factor (carnivorous had dummy_1 = 0 and dummy_2 = 0).\nLet’s see an example using a data table with measurements of vowel duration.\n\nload(\"./data/vowels.rda\")\nglimpse(vowels)\n\nRows: 886\nColumns: 9\n$ item          &lt;dbl&gt; 20, 2, 11, 1, 15, 10, 13, 3, 14, 19, 4, 6, 16, 17, 5, 23…\n$ speaker       &lt;chr&gt; \"it01\", \"it01\", \"it01\", \"it01\", \"it01\", \"it01\", \"it01\", …\n$ word          &lt;chr&gt; \"pugu\", \"pada\", \"poco\", \"pata\", \"boco\", \"podo\", \"boto\", …\n$ v1_duration   &lt;dbl&gt; 95.23720, 138.96844, 126.93226, 127.49888, 132.33310, 12…\n$ c2_voicing    &lt;chr&gt; \"voiced\", \"voiced\", \"voiceless\", \"voiceless\", \"voiceless…\n$ vowel         &lt;chr&gt; \"u\", \"a\", \"o\", \"a\", \"o\", \"o\", \"o\", \"a\", \"o\", \"u\", \"a\", \"…\n$ c2_place      &lt;chr&gt; \"velar\", \"coronal\", \"velar\", \"coronal\", \"velar\", \"corona…\n$ speech_rate   &lt;dbl&gt; 4.893206, 5.015636, 4.819541, 5.031662, 5.063435, 5.0632…\n$ speech_rate_c &lt;dbl&gt; -0.55937531, -0.43694485, -0.63303978, -0.42091937, -0.3…\n\n\nFor example, let’s take the vowel column. This column indicates which vowel the measurement was taken from, and that can be /a/, /o/, or /u/.\nIf we convert the vowel column into a factor, the levels will be a, o and u, and a will be the reference level.\n\nvowels &lt;- vowels %&gt;%\n  mutate(vowel = as.factor(vowel))\n\nlevels(vowels$vowel)\n\n[1] \"a\" \"o\" \"u\"\n\n\nTo get a sense of how a factor would be coded with treatment contrasts, we can print a dummy coding table with the contr.treatment() function.\n\ncontr.treatment(levels(vowels$vowel))\n\n  o u\na 0 0\no 1 0\nu 0 1\n\n\nNow, let’s run a regression model with v1_duration as the outcome variable and vowel as the predictor.\n\nvow_lm &lt;- lm(v1_duration ~ vowel, data = vowels)\n\nsummary(vow_lm)\n\n\nCall:\nlm(formula = v1_duration ~ vowel, data = vowels)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-66.874 -22.567  -2.293  17.025 106.755 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  128.616      1.806  71.227   &lt;2e-16 ***\nvowelo        -5.641      2.549  -2.213   0.0272 *  \nvowelu       -29.763      2.603 -11.432   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 31.38 on 883 degrees of freedom\nMultiple R-squared:  0.1419,    Adjusted R-squared:  0.1399 \nF-statistic: 72.99 on 2 and 883 DF,  p-value: &lt; 2.2e-16\n\n\nThe summary returns three coefficients:\n\nIntercept.\nvowelo.\nvowelu.\n\nSince a is the reference level of vowel, the Intercept corresponds to the mean duration of the vowel a, i.e. 128 ms.\nThe coefficient of o is the difference between the mean duration of o and the mean duration of the reference level a (i.e. the Intercept). So o is 5.6 ms shorter than a on average (shorter because the coefficient is negative).\nFinally, the coefficient of u is the difference between the mean duration of u and the mean duration of the reference level a So u is 29.7 ms shorter than a.\nThis is how treatment contrasts work."
  },
  {
    "objectID": "posts/2021-07-20-contrasts/index.html#sum-contrasts",
    "href": "posts/2021-07-20-contrasts/index.html#sum-contrasts",
    "title": "Factors, coding and contrasts",
    "section": "Sum contrasts",
    "text": "Sum contrasts\nAnother type of coding is effect coding. In R, the corresponding contrast type are the so-called sum contrasts.\nWhen using sum contrasts, the levels in a factor are coded using 1s, -1s and 0s. If you sum the values of each dummy variable you always get 0 (hence the name “sum” contrast).\nLet’s see what happens to the factor vowel when using sum contrasts (remember that factors use treatment contrasts by default).\nThis is how sum coding would look like for this factor:\n\ncontr.sum(levels(vowels$vowel))\n\n  [,1] [,2]\na    1    0\no    0    1\nu   -1   -1\n\n\nSince there are 3 levels, we need two dummy variables. So a is coded as 1, 0, o is coded as 0, 1, and u as -1, -1.\nTo set the contrasts of a factor to sum coding, we can run the following:\n\ncontrasts(vowels$vowel) &lt;- \"contr.sum\"\n# If you want to change it back to treatment contrasts you can run\n# contrasts(vowels$vowel) &lt;- \"contr.treatment\"\n\nWith sum contrasts the reference level is in fact the grand mean.\nIn our model of vowel duration this means that the Intercept coefficient will be the grand mean of vowel duration.\nLet’s rerun the model and look at the output.\n\nvow_lm &lt;- lm(v1_duration ~ vowel, data = vowels)\n\nsummary(vow_lm)\n\n\nCall:\nlm(formula = v1_duration ~ vowel, data = vowels)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-66.874 -22.567  -2.293  17.025 106.755 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  116.815      1.055 110.728  &lt; 2e-16 ***\nvowel1        11.801      1.483   7.957 5.40e-15 ***\nvowel2         6.160      1.481   4.160 3.49e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 31.38 on 883 degrees of freedom\nMultiple R-squared:  0.1419,    Adjusted R-squared:  0.1399 \nF-statistic: 72.99 on 2 and 883 DF,  p-value: &lt; 2.2e-16\n\n\nThe Intercept now is 116 ms, which mean that the mean of vowel duration across the three vowels is 116 ms.\nWe can check this by taking the mean:\n\nmean(vowels$v1_duration)\n\n[1] 117.2747\n\n\nYup, pretty close (small differences are fine).\nSo what are now the coefficients called vowel1 and vowel2?\nThese are, respectively, the difference between the mean duration of a and the grand mean, and the difference between the mean duration of o and the grand mean.\nSo a is 11.8 ms longer than the grand mean, and o is 6.1 ms longer than the grand mean.\nWhat about u then?\nEasy. You just subtract the coefficients of both a and o from the grand mean: \\(116.8 - 11.8 - 6.1 = 98.9\\).\nIf you want to check that this is correct, the mean duration of u according to the model above where we used treatment contrasts was \\(128.616 - 29.763 = 98.853\\)."
  },
  {
    "objectID": "posts/2021-07-20-contrasts/index.html#sum-contrasts-and-interactions",
    "href": "posts/2021-07-20-contrasts/index.html#sum-contrasts-and-interactions",
    "title": "Factors, coding and contrasts",
    "section": "Sum contrasts and interactions",
    "text": "Sum contrasts and interactions\nSum contrasts can be very handy when the model contains interactions between factors.\nLet’s say we want to include in our model of vowel duration a predictor that specifies the voicing of the stop following the vowel. We also add an interaction between vowel and voicing, so that we can model differences in the effect of voicing across vowels.\n\nvow_lm_2 &lt;- lm(v1_duration ~ c2_voicing + vowel + c2_voicing:vowel, data = vowels)\n\nsummary(vow_lm_2)\n\n\nCall:\nlm(formula = v1_duration ~ c2_voicing + vowel + c2_voicing:vowel, \n    data = vowels)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-64.905 -23.262  -2.033  18.134 115.813 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 123.469      1.449  85.232  &lt; 2e-16 ***\nc2_voicingvoiceless         -13.309      2.049  -6.496 1.37e-10 ***\nvowel1                       14.606      2.037   7.171 1.57e-12 ***\nvowel2                        8.564      2.033   4.212 2.79e-05 ***\nc2_voicingvoiceless:vowel1   -5.609      2.880  -1.947   0.0518 .  \nc2_voicingvoiceless:vowel2   -4.808      2.876  -1.672   0.0949 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 30.47 on 880 degrees of freedom\nMultiple R-squared:  0.1937,    Adjusted R-squared:  0.1891 \nF-statistic: 42.29 on 5 and 880 DF,  p-value: &lt; 2.2e-16\n\n\nNow the Intercept is the mean vowel duration when the following stop is voiced (the reference level of c2_voicing). This means that the average vowel followed by a voiced stop is 123 ms long in our data.\nThe coefficient of c2_voicingvoiceless tells us the mean effect of c2_voicing on vowel duration, averaged across all vowels. So, on average, a vowel is about 13 ms shorter when followed by a voiceless stop.\nThe coefficients of vowel1 and vowel2 indicate the difference between the average vowel duration before a voiced stop (the Intercept) and a and o respectively. As before, to get the difference between the average vowel duration of u before a voiceless stop and the mean vowel duration, you just need to subtract the coefficients of vowel1 and vowel2 from the Intercept: \\(123.5 - 14.6 - 8.5 = 100.4\\).\nThe last two coefficients, c2_voicingvoiceless:vowel1 and c2_voicingvoiceless:vowel2 correspond to the difference in the effect of voicing between the average effect of voicing (c2_voicingvoiceless, i.e. -13 ms) and the effect of voicing in a and o respectively. That is, the decrease of vowel duration for a is 5.6 ms greater than the average effect, while the decrease of vowel duration for o is 4.8 ms greater than the average effect.\nFollowing the usual formula, the effect of voicing for u is \\(-13.309 - (-5.6) - (-4.8) = -2.9\\)."
  },
  {
    "objectID": "posts/2021-07-20-contrasts/index.html#footnotes",
    "href": "posts/2021-07-20-contrasts/index.html#footnotes",
    "title": "Factors, coding and contrasts",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA previous version of this post is also featured as a vignette in the learnB4SS package, https://learnb4ss.github.io/learnB4SS/articles/contrasts.html↩︎\nYou can learn about more coding schemes here: https://stats.idre.ucla.edu/spss/webbooks/reg/chapter5/regression-with-spsschapter-5-additional-coding-systems-for-categorical-variables-in-regressionanalysis/.↩︎"
  },
  {
    "objectID": "posts/2019-06-17-priors-ggplot2/index.html",
    "href": "posts/2019-06-17-priors-ggplot2/index.html",
    "title": "Plotting prior distributions with ggplot2",
    "section": "",
    "text": "The choice of priors is a fundamental step of the Bayesian inference process. Vasishth et al. (2018) recommend plotting the chosen priors to see if they are reasonable.\nIn this post I will show how to easily plot prior distributions in ggplot2 (which is part of the tidyverse).\nLet’s load the tidyverse first.\nlibrary(tidyverse)\ntheme_set(theme_minimal()) # I just like this theme :)"
  },
  {
    "objectID": "posts/2019-06-17-priors-ggplot2/index.html#plotting-your-priors",
    "href": "posts/2019-06-17-priors-ggplot2/index.html#plotting-your-priors",
    "title": "Plotting prior distributions with ggplot2",
    "section": "Plotting your priors",
    "text": "Plotting your priors\nLet’s start with a simple normal prior with \\(\\mu\\) = 0 and sd = 1.\nThe plot is initialised with an empty call to ggplot(). As aesthetics, you only need to specify the range of x values in aes(). Here, we use c(-4, 4), meaning that the x-axis of this plot will have these limits. For a normal distribution, it is useful to set the limits as the mean ± 4 times the standard deviation (this ensures all the distribution is shown).\nThe function ggplot2::stat_function() allows us to specify a distribution family with the fun argument. This arguments takes the density function (the R functions of the form dxxx) of the chosen distribution family, so for the normal (Gaussian) distribution we use dnorm(). The argument n specifies the number of points along which to calculate the distribution (here 101), while args takes a list with the parameters of the distribution (here the mean 0 and standard deviation 1).\n\nggplot(data = tibble(x = -4:4), aes(x)) +\n  stat_function(fun = dnorm, n = 101, args = list(1)) +\n  labs(title = \"Normal (Gaussian) distribution\")\n\n\n\n\n\n\n\n\nA beta prior will be bounded between 0 and 1, so we can specify that in aes(). The beta distribution has two arguments, shape1 and shape2 (here 2 and 5).\n\nggplot(data = tibble(x = 0:1), aes(x)) +\n  stat_function(fun = dbeta, n = 101, args = list(2, 5)) +\n  labs(title = \"Beta distribution\")\n\n\n\n\n\n\n\n\nAnother common distribution is the Cauchy.\n\nggplot(data = tibble(x = -10:10), aes(x)) +\n  stat_function(fun = dcauchy, n = 201, args = list(-2, 1)) +\n  labs(title = \"Cauchy distribution\")\n\n\n\n\n\n\n\n\nThe Poisson distribution can be plotted by changing the type of geom and using an n that creates only integers.\n\n# the range 0:20 includes 21 integers, so n = 21\nggplot(data = tibble(x = 0:20), aes(x)) +\n  stat_function(fun = dpois, n = 21, args = list(4), geom = \"point\") +\n  labs(title = \"Poisson distribution\")\n\n\n\n\n\n\n\n\nOf course any family with a corresponding dxxx function can be plotted (see ?Distributions and package-provided families)."
  },
  {
    "objectID": "posts/2015-08-04-dialects-italy/index.html",
    "href": "posts/2015-08-04-dialects-italy/index.html",
    "title": "Wikipedia and the “Dialects of Italy”",
    "section": "",
    "text": "The Italian Wikipedia has reached a number of 1,215,574 articles, with 1,247,172 registered users (source: Italian Wikipedia Statistics). That’s more or less one user per article. The Italian encyclopaedia counts an average of 358,814 views per hour (source: Wikipedia Statistics).\nNevertheless, the linguistics presence suffers from a variety of cyber-diseases. According to the figures described on the page of the Italian Linguistics WikiProject, out of 890 articles, 250 don’t cite proper sources for their information and about 270 are stubs that need to be expanded.\nBut one topic in particular has been recently called to our attention (I’m a Wikipedia editor myself): the “dialects of Italy.”\nThe problem is twofold: on the one hand, “dialects of Italy” refers to heterogeneous entities and, on the other, there is no agreement on how to define a “dialect” [nor a “language,” for that matter; see Cysouw and Good’s article about this, Cysouw & Good (2013)]. This is further complicated by the rooted misunderstanding of linguistics facts and concepts that the general public usually has.\nAll of this, together with the “poor sourcing” problem, led to chaos: see the lengthy discussion about what to call a dialect and what a language (the title Un argomento cruciale, ‘A critical topic,’ should be enough for grasping the seriousness of the matter).\nSome time ago, a decision has been made to use the term “language” for any linguistic entity that had a code from the ISO 639-3 (to be sure, that’s from Ethnologue, by SIL), and “dialect” for entities without a code. This created an inconvenient precedent: since no Italian scientific source uses labels like “Piedmontese language” (lingua piemontese) or “Calabrian language” (lingua calabrese), Wikipedia came to be a primary source of this use, thus contradicting one of the main tenets of the open encyclopaedia. That is: no original research (NOR).\nThe reaction of the laypeople is: “Wikipedia calls it a language, so it is indeed.” This is backed up by the (misled but widespread) notion of dialect as a “lower and/or corrupted variety of Italian,” further strengthened by the idea that Wikipedia is authoritative with no exceptions. But let me stress it again, no academic source labels the mentioned linguistic entities of Italy as “languages.” Sorry folks.\nBut why is that? Well, tradition. The dialects of Italy have been called that since long and it would be extremely difficult to ask Italian linguists to stop calling them that way. However, no (sensible) linguist would consider them as corruptions of the Italian language.\nAs an emblematic example, (Loporcaro 2009: 4–5) succinctly gives us an interesting perspective: “Derivando indipendentemente dal latino, i dialetti come il padovano, il napoletano ecc. sono lingue sorelle dell’italiano.” (trad: “Independently deriving from Latin, the dialects such as Paduan, Neapolitan, etc. are sister languages of Italian.”). Although Loporcaro stresses the fact that what are normally labelled as “dialects” are languages, he is probably forced to still call them “dialects.” The point is, no one has ever called the dialects of Italy using the apposition “language” (2018 EDIT: probably until recently): so no “Paduan language,” nor “Neapolitan language.” Hence, this use in Wikipedia is totally unjustified.\nLuckily, the trend in the encyclopaedia of abusing of the ISO 639 is in the process of being counteracted and some Wikipedians are making an effort to take the situation back under control. In the meantime, read the Cysouw and Good’s article mentioned early if you didn’t already.\n\n\n\n\n\n\n\nReferences\n\nCysouw, Michael & Jeff Good. 2013. Languoid, doculect, and glossonym: Formalizing the notion “language.” Language Documentation & Conservation 7. 331–359. http://hdl.handle.net/10125/4606.\n\n\nLoporcaro, Michele. 2009. Profilo linguistico dei dialetti italiani. Bari: Laterza."
  },
  {
    "objectID": "posts/2021-11-21-dot-matrix-charts/index.html",
    "href": "posts/2021-11-21-dot-matrix-charts/index.html",
    "title": "R gist — Dot matrix charts with ggplot2",
    "section": "",
    "text": "Set up\n\n\nCreate data\n\ndots &lt;- tibble(\n  group = as.character(unlist(mapply(rep, c(\"a\", \"b\", \"c\"), c(26, 11, 7)))),\n  x = rep(1:10, length.out = length(group)),\n  y = rep(1:(ceiling(length(group) / 10)), each = 10)[1:length(group)]\n)\n\n\n\nPlot dot matrix chart\n\ndots %&gt;%\n  ggplot(aes(x, -y, colour = group)) +\n  geom_point(size = 10) +\n  scale_color_brewer(type = \"qual\") +\n  theme_minimal() +\n  theme(\n    panel.grid = element_blank(),\n    axis.title = element_blank(),\n    axis.text = element_blank(),\n    legend.position = \"bottom\"\n  )\n\n\n\n\n\n\n\n\n\n\nTo do\n\nOrder groups by descending count.\nReduce spacing."
  },
  {
    "objectID": "posts/2021-03-07-quotables-rebecca-posner/index.html",
    "href": "posts/2021-03-07-quotables-rebecca-posner/index.html",
    "title": "Quotables — Rebecca Posner",
    "section": "",
    "text": "This is part of the post series ‘Quotables: notable quotes from notable linguists’.\n\nHow many Romance languages are there?\nAn answer to this question that has been slightingly labelled sancta simplicitas is that there is only one: the languages are all alike enough to be deeemed dialects of the same language. Another equally disingenous answer might be ‘thousands’—of distinctive local varieries—or ‘millions’—of individual idiolects. The usual textbook answer is ‘ten, or possibly eleven’, according priority to putative chronologically early differentiation from the common stock, allegedly linked to ethnic differences among speakers.\n\n—Posner (2004), p. 189.\n\n\n\n\nReferences\n\nPosner, Rebecca. 2004. The Romance languages. Cambridge: Cambridge University Press."
  },
  {
    "objectID": "posts/2018-08-23-tongue-ggplot2/index.html",
    "href": "posts/2018-08-23-tongue-ggplot2/index.html",
    "title": "Plotting tongue contours with ggplot2",
    "section": "",
    "text": "When plotting tongue contours data obtained from ultrasound tongue imaging in R using ggplot2, a common option to smooth over the individual contours and show the general pattern is to use geom_smooth(methood = \"loess\"). However, as I will show in this post, in certain cases this method leads to very disorted contours. Such distortion is more or less always present, although at a lower degree in less extreme cases.\nTo show the shortcomings of using geom_smooth() and present a viable alternative, we’ll be using ultrasound tongue imaging data from one speaker (me). This dataset includes tongue contours from within the closure of the conosonants /t, d/ preceeded by /a, o, u/. The dataset looks like this (some columns dropped):\n\nselect(tongue_data, rec_date, fan_line, X, Y, word, vowel, c2)\n\n# A tibble: 1,239 × 7\n   rec_date            fan_line     X     Y word  vowel c2   \n   &lt;chr&gt;                  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n 1 29/11/2016 15:10:52        6  37.4  9.25 pada  a     d    \n 2 29/11/2016 15:21:30        6  38.6 13.1  pada  a     d    \n 3 29/11/2016 15:10:52        7  34.4 10.3  pada  a     d    \n 4 29/11/2016 15:11:03        7  34.3  9.81 pata  a     t    \n 5 29/11/2016 15:11:14        7  34.6 11.0  podo  o     d    \n 6 29/11/2016 15:13:39        7  34.3  9.65 pada  a     d    \n 7 29/11/2016 15:16:05        7  34.8 11.5  pada  a     d    \n 8 29/11/2016 15:17:07        7  34.5 10.5  putu  u     t    \n 9 29/11/2016 15:19:45        7  34.3  9.64 putu  u     t    \n10 29/11/2016 15:21:30        7  35.4 13.8  pada  a     d    \n# ℹ 1,229 more rows\n\n\nrec_date is the date and time of recording. Each observed tongue contour has a unique rec_date (this will come in handy later). fan_line is the number of the line in the fan coordinate system used by Articulate Assistant Advanced (which I used to record the data). X and Y are the horizontal and vertical position of each point on the contour. The unit is millimeters. word, vowel and c2 are self-explanatory.\nLet’s start by plotting the smoothed contours by vowel and consonant.\n\ntongue_data %&gt;%\n  ggplot(aes(X, Y)) +\n  geom_smooth(aes(colour = vowel), method = \"loess\") +\n  coord_fixed() +\n  facet_grid(c2 ~ vowel) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWe can immediately notice that with /u/ there is something odd going on. That does not look like a tongue surface (maybe that of a chameleon! Definitely not one of a ‘hooman’.) The smooths for /a/ and /o/ seem quite standard.\nTo see what is going on, let’s plot now also the individual points as recorded in the data, whith a superimoposed smooth, for comparison.\n\ntongue_data %&gt;%\n  ggplot(aes(X, Y)) +\n  geom_point(alpha = 0.1) +\n  geom_smooth(aes(colour = vowel), method = \"loess\") +\n  coord_fixed() +\n  facet_grid(c2 ~ vowel) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWhile the smooths with /a/ and /o/ more or less have a good fit when compared to the points, with /u/ the smooths are really off.\nThis happpens because the tongue root (in this particular case) developpes vertically rather than slanted. The smooth isagnostic about the fact that points lying on the same X value but with different Y values belong to different portion of the tongue contour. The result is that smoothing happens across tongue parts.\nAn alternative (if you don’t like points) is to use geom_path() to plot the individual tongue contours as lines. geom_path() connects points with a line, following the order in which they appear in the dataset. So, before using this geometry, we need to arrange the dataframe such that the points are in the right order (now they are in the wrong order).\nTo do so, we can use rec_date (which identifies the individual contours) and fan_line which indicates the orders of points (for each contour, there a maximum 42 points/fan lines; NAs have been excluded).\n\ntongue_data &lt;- tongue_data %&gt;%\n  arrange(rec_date, fan_line)\n\ntongue_data\n\n# A tibble: 1,239 × 30\n   speaker seconds rec_date          prompt label TT_displacement_sm TT_velocity\n   &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt;              &lt;dbl&gt;       &lt;dbl&gt;\n 1 it01       1.11 29/11/2016 15:10… Dico … max_…               77.4       -7.18\n 2 it01       1.11 29/11/2016 15:10… Dico … max_…               77.4       -7.18\n 3 it01       1.11 29/11/2016 15:10… Dico … max_…               77.4       -7.18\n 4 it01       1.11 29/11/2016 15:10… Dico … max_…               77.4       -7.18\n 5 it01       1.11 29/11/2016 15:10… Dico … max_…               77.4       -7.18\n 6 it01       1.11 29/11/2016 15:10… Dico … max_…               77.4       -7.18\n 7 it01       1.11 29/11/2016 15:10… Dico … max_…               77.4       -7.18\n 8 it01       1.11 29/11/2016 15:10… Dico … max_…               77.4       -7.18\n 9 it01       1.11 29/11/2016 15:10… Dico … max_…               77.4       -7.18\n10 it01       1.11 29/11/2016 15:10… Dico … max_…               77.4       -7.18\n# ℹ 1,229 more rows\n# ℹ 23 more variables: TT_velocity_abs &lt;dbl&gt;, TD_displacement_sm &lt;dbl&gt;,\n#   TD_velocity &lt;dbl&gt;, TD_velocity_abs &lt;dbl&gt;, TR_displacement_sm &lt;dbl&gt;,\n#   TR_velocity &lt;dbl&gt;, TR_velocity_abs &lt;dbl&gt;, fan_line &lt;int&gt;, X &lt;dbl&gt;, Y &lt;dbl&gt;,\n#   word &lt;chr&gt;, language &lt;chr&gt;, sex &lt;chr&gt;, item &lt;int&gt;, ipa &lt;chr&gt;, c1 &lt;chr&gt;,\n#   c1_phonation &lt;chr&gt;, vowel &lt;chr&gt;, anteropost &lt;chr&gt;, height &lt;chr&gt;, c2 &lt;chr&gt;,\n#   c2_phonation &lt;chr&gt;, c2_place &lt;chr&gt;\n\n\nWe can now use geom_path(). The argument group = rec_date ensures that individual lines are plotted (without it, the last point of one contour is connected with the first of the contour following in the dataset).\n\ntongue_data %&gt;%\n  ggplot(aes(X, Y)) +\n  geom_path(aes(group = rec_date, colour = vowel), alpha = 0.5) +\n  coord_fixed() +\n  facet_grid(c2 ~ vowel) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe tongue root in /u/ is now properly rendered.\nBut what fif you want to plot a single contour (possibly with confidence intervals) for each of the 6 panels in the previous figure, rather than all the contours?\nAn option is to plot an average contour (litterally, the aveages of X and Y). We can easily do that by grouping the data by fan_line and then summarise() it. Plotting can then be done with geom_path() and geom_polygon(). All together, the code looks like this.\n\nxy_mean &lt;- tongue_data %&gt;%\n  group_by(fan_line, vowel, c2) %&gt;%\n  summarise(\n    X_mean = mean(X, na.rm = TRUE),\n    Y_mean = mean(Y, na.rm = TRUE)\n  )\n\nxy_ci &lt;- tongue_data %&gt;%\n  group_by(fan_line, vowel, c2) %&gt;%\n  summarise(\n    X_CI_low = t.test(X)$conf.int[1],\n    X_CI_up = t.test(X)$conf.int[2],\n    Y_CI_low = t.test(Y)$conf.int[1],\n    Y_CI_up = t.test(Y)$conf.int[2]\n  )\n\nci_upper &lt;- xy_ci %&gt;%\n  dplyr::select(-X_CI_low, -Y_CI_low) %&gt;%\n  dplyr::rename(\n    CI_X = X_CI_up,\n    CI_Y = Y_CI_up\n  )\n\nci_lower &lt;- xy_ci %&gt;%\n  dplyr::select(-X_CI_up, -Y_CI_up) %&gt;%\n  dplyr::arrange(dplyr::desc(fan_line)) %&gt;%\n  dplyr::rename(\n    CI_X = X_CI_low,\n    CI_Y = Y_CI_low\n  )\n\nci &lt;- rbind(ci_upper, ci_lower)\n\nggplot(xy_mean, aes(X_mean, Y_mean)) +\n  geom_polygon(data = ci, aes(x = CI_X, y = CI_Y), alpha = 0.2) +\n  geom_path(aes(X_mean, Y_mean, colour = vowel)) +\n  facet_grid(c2 ~ vowel) +\n  coord_fixed() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/2021-03-15-on-random-effects/index.html",
    "href": "posts/2021-03-15-on-random-effects/index.html",
    "title": "On random effects",
    "section": "",
    "text": "If you use mixed-effects models (aka multilevel models, hierarchical models), I am sure that at some point you asked yourself the following question at least once: Should I include variable X as a fixed or as a random effect?\nTo answer this question we need to ask first: what is a random effect?\nRegrettably, there is no straightforward answer (disappointed, uh?).\nThe main reason is that, in fact, there are many possible (and most times mutually exclusive) definitions of what a random (vs fixed) effect is.\nIn the following summary—which is heavily based on Gelman’s post Why I don’t use the term “fixed and random effects” (and related journal article)—I’d like to offer an overview of five main definitions of “random effect” and some final thoughts."
  },
  {
    "objectID": "posts/2021-03-15-on-random-effects/index.html#five-definitions-of-random-effect",
    "href": "posts/2021-03-15-on-random-effects/index.html#five-definitions-of-random-effect",
    "title": "On random effects",
    "section": "Five definitions of “random effect”",
    "text": "Five definitions of “random effect”\nIn his post, Gelman says that there are at least five possible ways of defining random effects (with others being subsumable under those five). To illustrate these definitions and make them more relatable to phoneticians and phonologists alike, I will make use of a fictitious study of f0 (fundamental frequency) as a correlate of emotional arousal (\\(\\eta\\)).\nLet’s assume that we are interested in testing the (made-up) hypothesis that emotional arousal affects the speaker’s f0. We can test this hypothesis using the following model:\n\\[ f0_{ij} = \\alpha + \\alpha_j + \\beta \\times \\eta_i \\]\nwhere\n\n\\(f0_{ij}\\) is the outcome variable,\n\\(\\alpha\\) is the intercept,\n\\(\\alpha_j\\) is the individual speakers’ intercept coefficient,\n\\(\\beta\\) is the slope,\nand \\(\\eta_i\\) is emotional arousal status (0 = non-aroused, 1 = aroused).\n\nThe corresponding model in R:\nThis is just a model with a fixed effect and a by-speaker random intercept. The inclusion of speaker as a random effect is nothing exceptional, but what is a random effect?\nAs hinted at above, there is no one answer.\nThe following sections show how “speaker” can be interpreted as a random effect depending on which of the five definitions one picks.\n\n(1) Constant vs varying coefficients\nKreft, Kreft & de Leeuw (1998) distinguish between fixed and random regression coefficients. Fixed coefficients are constant across individuals, while random coefficients vary.\nIn the f0 study, the slope \\(\\beta\\) is fixed and \\(\\alpha_j\\) is random because it depends on which speaker the data is from.\n\n\n(2) Researcher’s interest\nSearle, Casella & McCulloch (2009: sec. 1.4) discuss effects in terms of the researcher’s interest. Effects are considered fixed if the research question/hypothesis being tested covers those effects, or random if the interest lies in the underlying population rather than on the individual effects.\nIn this sense, the effect of emotional arousal on f0 is the main focus of interest since we are testing the hypothesis that the former affects the latter, while the average f0 of each speaker (\\(\\alpha_j\\)) is not relevant.\n\n\n(3) Sampling\n\nWhen a sample exhausts the population, the corresponding variable is fixed; when the sample is a small (i.e., negligible) part of the population the corresponding variable is random.\n\n—Green & Tukey (1960)\nIn our example study, the observed levels of emotional arousal (non-aroused vs aroused) exhausts the “population” of emotional arousal states, while the set of speakers is just a sample from the whole population of speakers.\n\n\n(4) Random events\n\nIf an effect is assumed to be a realized value of a random variable, it is called a random effect.\n\n—LaMotte (1983)\nA random variable is a variable generated by a random event.\nIn the f0 study, the speakers that participated in the study are the outcome of random events, while we assume that the relation between f0 and arousal is governed by a specific mathematical relationship.\n\n\n(5) Shrinkage\nThe last definition of fixed vs random effects is based on the method employed to estimate them. Fixed effects are estimated using maximum likelihood, while random effects are estimated with partial pooling. Partial pooling means that the estimation of the random effects influence the estimation of the fixed effects and vice versa. This definition is standard in the multilevel modelling literature (Snijders & Bosker 2011: sec. 4.2) and in econometrics.\nA consequence of partial pooling is the so-called “shrinkage”. Shrinkage refers to the “regression to the mean”, by which the estimated effects are attracted towards the overall mean (i.e. the intercept).\nSo in the f0 study, the by-speaker random intercepts “shrink” towards the estimated fixed intercept. In sum, fixed effects are effects without shrinkage while random effects are effects with shrinkage.\nThus, under this definition, whether one chooses to model an effect with or without shrinkage has to do with the underlying process model one expects to have generated the observed data. If the expected process of a variable entails shrinkage, then it would make sense to enter such variable as a random effect."
  },
  {
    "objectID": "posts/2021-03-15-on-random-effects/index.html#some-final-thoughts",
    "href": "posts/2021-03-15-on-random-effects/index.html#some-final-thoughts",
    "title": "On random effects",
    "section": "Some final thoughts",
    "text": "Some final thoughts\nI agree with Gelman’s statement that the terms “fixed” and “random” could (and perhaps should) be avoided altogether.\nWithin the Bayesian framework, for example, it is becoming common to use the terms “population-level” and “group-level” effects to indicate, respectively, effects that are generated by a population-wide process vs effects that are generated by the modulation of such generative process within groups that make up the population.\nAs in definition (5) above, group-level effects are estimated with partial pooling (for a nice detailed explanation of partial pooling that includes robots cuing for coffee and tadpoles, see McElreath 2015, Ch 12).\nTo conclude, whether you include a variable as a fixed or random effect will depend on (a) which definition of random effect you (explicitly or implicitly) choose, and (b) what underlying generative process you envision to be at play."
  },
  {
    "objectID": "posts/2021-07-04-plotting-the-area-under-the-curve/index.html",
    "href": "posts/2021-07-04-plotting-the-area-under-the-curve/index.html",
    "title": "R gist — Plotting the area under the curve with ggplot",
    "section": "",
    "text": "knitr::opts_chunk$set(echo = TRUE)\nlibrary(tidyverse)\nlibrary(ggthemr)\nggthemr(\"earth\")\n\n\nx &lt;- 1:11\ny &lt;- (1.5:11.5)^2\nlow &lt;- (0:10)^2\nupp &lt;- (3:13)^2\n\n\nggplot() +\n  aes(x, y) +\n  geom_line() +\n  geom_ribbon(aes(ymin = low, ymax = upp), alpha = 0.5)\n\n\n\n\n\n\n\n\n\nx2 &lt;- c(1:8, NA, NA, NA)\nggplot() +\n  aes(x, y) +\n  geom_line() +\n  geom_ribbon(aes(x = x2, ymin = low, ymax = upp), alpha = 0.5)\n\n\n\n\n\n\n\n\n\nx &lt;- seq(-4, 4, by = 0.05)\ny &lt;- dnorm(x)\n\n\np &lt;- ggplot() +\n  aes(x, y) +\n  geom_line()\np\n\n\n\n\n\n\n\n\n\np +\n  geom_ribbon(\n    aes(x = ifelse(x &lt;= -1 , x, NA), ymin = 0, ymax = y),\n    fill = \"#E84646\",\n    alpha = 0.4\n  )"
  },
  {
    "objectID": "output/index.html",
    "href": "output/index.html",
    "title": "Scholarly output",
    "section": "",
    "text": "= Manuscript (author manuscript, not submitted, in preparation). —  = Submitted manuscript (aka Preprint; submitted author manuscript prior to peer-review). —  = Accepted manuscript (aka Postprint; accepted author manuscript after peer-review, same content as published version). —  = Published manuscript (aka Offprint; accepted manuscript with publisher’s formatting, same content as postprint). —  = Preregistration. —  = Research compendium (data and materials)."
  },
  {
    "objectID": "output/index.html#papers",
    "href": "output/index.html#papers",
    "title": "Scholarly output",
    "section": "Papers",
    "text": "Papers\n\n\n\n\n\n\nsubmitted\n\n\nA vitality assessment of Gallo-Romance of Northern Italy  Stefano Coretta, Simone De Cia, Jessica Hampton  \n\n\n\n\nsubmitted\n\n\nMultivariate analyses of tongue contours from ultrasound tongue imaging  Stefano Coretta, Georges Sakr  \n\n\n\n\nsubmitted\n\n\nBayesian beta regressions with brms in R: A tutorial for phoneticians  Stefano Coretta, Paul-Christian Bürkner  \n\n\n\n\nsubmitted\n\n\nBilingualism Effect for Delaying Dementia Onset: A Bayesian Meta-Analysis  Ziyuan Li, Stefano Coretta\n\n\n\n\nsubmitted\n\n\nIs 'intrinsic vowel duration' bio-mechanical or more? Preliminary results from Northwestern Italian  Stefano Coretta  \n\n\n\n\naccepted\n\n\nV2-Relatives in Old English  Bettelou Los, Stefano Coretta  Discourse structure and narration. A diachronic view from Germanic Ch 9, pp. 305-341. Eds Ulrike Demske and Barthe Bloom \n\n\n\n\n2024\n\n\n A tutorial on Generalised Additive Mixed Effects Models for bilingualism research  Stefano Coretta, Joseph V. Casillas  Linguistic Approaches to Bilingualism    \n\n\n\n\n2024\n\n\n Language practices of Emilian and Esperanto communities: spaces of use, explicit language attitudes and self-reported competence  Jessica Hampton, Stefano Coretta  Journal of Multilingual and Multicultural Development    \n\n\n\n\n2024\n\n\nGlossolects  Stefano Coretta, Jessica Hampton, Stephen Nichols  Octopus   \n\n\n\n\n2023\n\n\n  Multidimensional signals and analytic flexibility: Estimating degrees of freedom in human speech analyses  Stefano Coretta, Joseph V. Casillas, …, Timo Roettger  Advances in Methods and Practices in Psychological Science 6(3)   \n\n\n\n\n2023\n\n\n The decline of local anchoring: A quantitative investigation  Bettelou Los, Dreschler Gea, Ans van Kemenade, Erwin Komen, Stefano Coretta  English Language & Linguistics 27(2). 345–372   \n\n\n\n\n2023\n\n\n Northern Tosk Albanian (IPA Illustration)  Stefano Coretta, Josiane Riverin-Cutlée, Enkeleida Kapia, Stephen Nichols  Journal of the International Phonetic Association 53(3). 1122–1144    \n\n\n\n\n2021\n\n\nDistance vs. time: Acoustic and articulatory consequences of reduced vowel duration in Polish  Patrycja Strycharczuk, Małgorzata Ćavar, Stefano Coretta  Journal of the Acoustical Society of America 150(1), 592–607  \n\n\n\n\n2021\n\n\nPlanting the seed for sound change: Evidence from real-time MRI of velum kinematics in German  Chris Carignan, Stefano Coretta, Jans Frahm, Jonathan Harrington, Phil Hoole, Arun Joseph, Esther Kunay, Dirk Voit  Language 97(2), 333–364  \n\n\n\n\n2020\n\n\n A cross cultural analysis of early prelinguistic gesture development and its relationship to language development  Thea Cameron-Faulkner, Nivedita Malik, Circle Steele, Stefano Coretta, Ludovica Serratrice, Elena Lieven  Child Development 92, 273–290   \n\n\n\n\n2020\n\n\nLonger vowel duration correlates with greater tongue root advancement at vowel offset: Acoustic and articulatory data from Italian and Polish  Stefano Coretta  Journal of the Acoustical Society of America 147, 245–259    \n\n\n\n\n2020\n\n\n An exploratory study of voicing-related differences in vowel duration as compensatory temporal adjustment in Italian and Polish  Stefano Coretta  Glossa: a journal of general linguistics 4(1) 125, 1–25   \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "output/index.html#book",
    "href": "output/index.html#book",
    "title": "Scholarly output",
    "section": "Book",
    "text": "Book\n\n\n\n\n\n\n2023\n\n\nMikrovariacioni sintaksor në dialektet e shqipes: një atlas me të dhëna dixhitale [Syntactic Microvariation in Albanian Dialects: An atlas with digital data]  Enkeleida Kapia, Stefano Coretta, L. Buxheli, A. Omari Academy of Albanological Sciences. Institute of Linguistics and Literature. Tiranë.\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "output/index.html#research-compendia",
    "href": "output/index.html#research-compendia",
    "title": "Scholarly output",
    "section": "Research compendia",
    "text": "Research compendia\n\n\n\n\n\n\n2025\n\n\nAssessing the vitality of Gallo-Romance of Northern Italy  Stefano Coretta, Simone De Cia, Jessica Hampton  \n\n\n\n\n2023\n\n\nLanguage practices of Emilian and Esperanto communities: spaces of use, explicit language attitudes and self-reported competence [Research Compendium]  Jessica Hampton, Stefano Coretta  \n\n\n\n\n2023\n\n\nMany Speech Analyses  Stefano Coretta, Joseph V. Casillas, Timo B. Roettger \n\n\n\n\n2021\n\n\nIPA Illustration of Northern Tosk Albanian  Stefano Coretta, Josiane Riverin-Cutlée, Enkeleida Kapia, Stephen Nichols \n\n\n\n\n2021\n\n\nDistance vs. time. Articulatory and acoustic consequences of reduced vowel duration in Polish [Research Compendium]  Patrycja Strycharczuk, Małgorzata Ćavar, Stefano Coretta \n\n\n\n\n2020\n\n\nVowel duration and consonant voicing: A production study  Stefano Coretta \n\n\n\n\n2020\n\n\nA Cross-Cultural Analysis of Early Prelinguistic Gesture Development and Its Relationship to Language Development [Research Compendium]  Thea Cameron-Faulkner, Nivedita Malik, Circle Steele, Stefano Coretta, Ludovica Serratrice, Elena Lieven \n\n\n\n\n2019\n\n\nVowel duration and aspiration effects in Icelandic  Stefano Coretta \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "output/index.html#software",
    "href": "output/index.html#software",
    "title": "Scholarly output",
    "section": "Software",
    "text": "Software\n\n\n\n\n\n\n2025\n\n\nphonetisr: A Naive IPA Tokeniser  Stefano Coretta R package v0.1.0   \n\n\n\n\n2025\n\n\nrticulate: Ultrasound Tongue Imaging in R  Stefano Coretta R package v2.0.1   \n\n\n\n\n2024\n\n\nlmt: Literate Markdown Tangler Extension For Quarto  Stefano Coretta v0.2.0  \n\n\n\n\n2024\n\n\ntidygam: Tidy Prediction and Plotting of Generalised Additive Models  Stefano Coretta R package v1.0.0   \n\n\n\n\n2024\n\n\nspeakr: A Wrapper for the Phonetic Software Praat  Stefano Coretta R package v3.2.4   \n\n\n\n\n2017\n\n\nSFM exporter (Toolbox/FLEx SIL)  Stefano Coretta Shiny App v2.2.0  \n\n\n\n\n2017\n\n\nphonrule: TeX package for typesetting phonological rules in SPE style  Stefano Coretta LaTeX package v1.4.0  \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "output/index.html#invited-talks",
    "href": "output/index.html#invited-talks",
    "title": "Scholarly output",
    "section": "Invited talks",
    "text": "Invited talks\n\n\n\n\n\n\n2023\n\n\nRethinking the IPA vowel quadrilateral Department of Linguistics and Scandinavian Studies seminar, 26 May, University of Oslo, Norway. \n\n\n\n\n2022\n\n\nToday's coarticulation is tomorrow's sound change: Insights from dynamic articulatory data Understanding Sound Change, 27 January, Donostia-San Sebastián, Spain. \n\n\n\n\n2021\n\n\nThe more we learn the less we know: (Un)resolved questions on the voicing effect University of Potsdam, 28 July, Germany. \n\n\n\n\n2021\n\n\nExploring pathways to contrastive vowel nasalisation. Or what today's articulatory patterns can tell us about yesterday's sound change University of Lancaster, 25 May, UK. \n\n\n\n\n2018\n\n\nVowel duration differences before voiceless and voiced stops as compensatory temporal adjustment Indiana University Bloomington, 16 October, USA.\n\n\n\n\n2018\n\n\nVowel duration as a function of consonant gestural timing in Italian and Polish: Evidence from acoustics, ultrasound tongue imaging, and electroglottography Aarhus University, 18 September, Denmark.\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "output/index.html#talks-and-posters",
    "href": "output/index.html#talks-and-posters",
    "title": "Scholarly output",
    "section": "Talks and posters",
    "text": "Talks and posters\n\n\n\n\n\n\n2024\n\n\nComparing language attitudes in the speech communities of Emilian and Veneto  Jessica Hampton, Stefano Coretta and Simone de Cia Talk presented at the Tenth Cambridge Conference on Language Endangerment, 12 July.\n\n\n\n\n2024\n\n\nComparing language attitudes in the speech communities of Emilian and Veneto  Jessica Hampton, Stefano Coretta and Simone de Cia Talk presented at the Contested Languages in the Old World 4, 23–25 May.\n\n\n\n\n2024\n\n\nAnalysing tongue contours with multivariate Generalised Additive Models  Stefano Coretta and Georges Sakr Poster presented at Ultrafest 2024  \n\n\n\n\n2024\n\n\nIs vowel duration the product of gestural timing alone? Data from Northwestern Italian Talk given at the British Association of Academic Phoneticians (BAAP) 2024   \n\n\n\n\n2024\n\n\nMeasuring spaces and observing attitudes: a comparative analysis on the vitality of Emilian and Esperanto  Jessica Iubini-Hampton, Stefano Coretta Talk presented at the XIX International Conference on Minority Languages, University of Wales\n\n\n\n\n2023\n\n\nSpeech physiology or more? Vowel duration and tongue height in Northwestern Italian Poster presented at the 6th Edinburgh Symposium in Historical Phonology, 5 Dec, University of Edinburgh   \n\n\n\n\n2022\n\n\nData Version Control for Researchers Talk given at the Edinburgh Open Research Conference, 27 May, University of Edinburgh  \n\n\n\n\n2022\n\n\nResearch management in \"many analysts\" projects: Lessons from the Many Speech Analyses project Poster presented at the Edinburgh Open Research Conference, 27 May, University of Edinburgh \n\n\n\n\n2022\n\n\nHow significance testing might be limiting phonetic research and what to replace it with Talk presented at the 2022 BAAP Colloquium, 8 April, York (UK, online) \n\n\n\n\n2021\n\n\nOn the acoustics and articulation of the affricates of Northern Tosk Albanian  Stephen Nichols, Enkeleida Kapia, Josiane Riverin-Coutlée, Stefano Coretta Talk presented at the 2021 Annual Meeting of the LAGB, Belfast (online, UK)\n\n\n\n\n2021\n\n\nTowards a description of the rhotic sounds of Northern Tosk Albanian  Stephen Nichols, Enkeleida Kapia, Josiane Riverin-Coutlée, Stefano Coretta Talk presented at the 7th edition of R-atics, Lausanne (online, Switzerland)\n\n\n\n\n2020\n\n\nTwo mechanisms for vowel reduction in Polish  Patrycja Strycharczuk, Małgorzata Ćavar, and Stefano Coretta Talk presented at LabPhon17, 8 July, Vancouver (Canada, online)\n\n\n\n\n2020\n\n\nMeta-analytical estimates of the effect of voicing on vowel duration in English are biased Poster presented at LabPhon17, 8 July, Vancouver (Canada, online)  \n\n\n\n\n2020\n\n\nControl of larynx height in vowel production revisited: A real-time MRI study Talk presented at the 12th International Seminar on Speech Production, 17 December (online)  \n\n\n\n\n2019\n\n\nA cross-cultural analysis of early prelinguistic gesture development and its relationship to language development  Thea Cameron-Faulkner, Circle Steele, Nividita Malik, Stefano Coretta, Ludovica Serretrice, and Elena Lieven Talk presented at the 5th International Language and Communicative Development Conference, 12 June, Manchester (UK).\n\n\n\n\n2019\n\n\nTemporal stability and compensatory adjustments: Data on the eﬀect of voicing on vowel duration in Italian and Polish Talk presented at LAGB 2019 \n\n\n\n\n2018\n\n\nThe effect of lexical frequency on vowel phonation as a correlate of /t/-glottaling  Coretta, Stefano and Massimiliano Canzi Talk presented at LAGB 2018, 11-14 September, University of Sheffield, UK   \n\n\n\n\n2018\n\n\nQuantifying vocal fold activity: two new methods for analysing electroglottographic data Talk presented at New Developments in Speech Sensing and Imaging, 23 June, University of Lisbon, Portugal  \n\n\n\n\n2018\n\n\nLonger vowel duration correlates with tongue root advancement in Italian and Polish: An ultrasound study Talk presented at LabPhon16, 22 June, University of Lisbon, Portugal  \n\n\n\n\n2018\n\n\nProcessing EGG data: New methods for a multidimensional time-series assessment of vocal fold activity Talk presented at mFiL 2018, 26 Apr, The University of Manchester, UK\n\n\n\n\n2018\n\n\nTongue root advancement and vowel duration: A gradient effect? Talk presented at the 2018 BAAP Colloquium, 13 Apr, University of Kent, UK  \n\n\n\n\n2017\n\n\nVowel duration and tongue root advancement in Italian and Polish Talk presented at Ultrafest VIII, 4 Oct, University of Potsdam, Germany  \n\n\n\n\n2017\n\n\nA streamlined workflow for \"doing phonetics by computer\" (using Praat and R) Talk presented at the Postgraduate Academic Research in Linguistics at York (PARLAY), 15 Sep, University of York, UK  \n\n\n\n\n2017\n\n\nTowards an articulatory based typology of laryngeal effects on vowel duration Poster presented at the 25th Manchester Phonology Meeting (25mfm), 25–27 May, University of Manchester  \n\n\n\n\n2017\n\n\nImplementing reproducibility in phonetic research: a computational workflow Paper presented at the Manchester Forum in Linguistics 2017 (mFiL 2017), 28–29 April, University of Manchester  \n\n\n\n\n2015\n\n\nA new case of “rhinoglottophilia:” from nasalisation to aspiration Paper presented at the Second Edinburgh Symposium on Historical Phonology (ESHP2), 3–4 December, University of Edinburgh \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  }
]