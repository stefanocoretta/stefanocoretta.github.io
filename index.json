[{"authors":["admin"],"categories":null,"content":"Welcome to the homepage of Stefano Coretta (IPA: [ˈsteˑfano koˈrɛtta]).\nI am currently a postdoc researcher at the Institute of Phonetics und Speech Processing at the Ludwig-Maximilians Universität München (Germany). I obtained my PhD degree in linguistics at the University of Manchester (UK) in 2020. My area of research is linguistics with a focus in phonetics and phonology\u0026mdash;the study of speech sounds and their relation to linguisticality (Human Language).\nSome of the questions my research tries to answer are:\n How do we produce the sounds we use in our daily communication? How do these sounds create a system? What are the attested sound systems of the languages of the world, and why are they the way they are? What can we learn about human cognition from the knowledge of how sound systems work?  ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://stefanocoretta.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Welcome to the homepage of Stefano Coretta (IPA: [ˈsteˑfano koˈrɛtta]).\nI am currently a postdoc researcher at the Institute of Phonetics und Speech Processing at the Ludwig-Maximilians Universität München (Germany). I obtained my PhD degree in linguistics at the University of Manchester (UK) in 2020. My area of research is linguistics with a focus in phonetics and phonology\u0026mdash;the study of speech sounds and their relation to linguisticality (Human Language).\nSome of the questions my research tries to answer are:","tags":null,"title":"Stefano Coretta","type":"authors"},{"authors":null,"categories":["Methods"],"content":"  The choice of priors is a fundamental step of the Bayesian inference process. Vasishth et al. (2018) recommend plotting the chosen priors to see if they are reasonable.\nIn this post I will show how to easily plot prior distributions in ggplot2 (which is part of the tidyverse).\nLet’s load the tidyverse first.\nlibrary(tidyverse) ## ── Attaching packages ───────── tidyverse 1.3.0 ── ## ✓ ggplot2 3.3.2 ✓ purrr 0.3.4 ## ✓ tibble 3.0.3 ✓ dplyr 1.0.2 ## ✓ tidyr 1.1.2 ✓ stringr 1.4.0 ## ✓ readr 1.3.1 ✓ forcats 0.5.0 ## ── Conflicts ──────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() theme_set(theme_minimal()) # I just like this theme :) Plotting your priors Let’s start with a simple normal prior with \\(\\mu\\) = 0 and sd = 1.\nThe plot is initialised with an empty call to ggplot(). As aesthetics, you only need to specify the range of x values in aes(). Here, we use c(-4, 4), meaning that the x-axis of this plot will have these limits. For a normal distribution, it is useful to set the limits as the mean ± 4 times the standard deviation (this ensures all the distribution is shown).\nThe function ggplot2::stat_function() allows us to specify a distribution family with the fun argument. This arguments takes the density function (the R functions of the form dxxx) of the chosen distribution family, so for the normal (Gaussian) distribution we use dnorm(). The argument n specifies the number of points along which to calculate the distribution (here 101), while args takes a list with the parameters of the distribution (here the mean 0 and standard deviation 1).\nggplot(data = tibble(x = -4:4), aes(x)) + stat_function(fun = dnorm, n = 101, args = list(1)) + labs(title = \u0026quot;Normal (Gaussian) distribution\u0026quot;) A beta prior will be bounded between 0 and 1, so we can specify that in aes(). The beta distribution has two arguments, shape1 and shape2 (here 2 and 5).\nggplot(data = tibble(x = 0:1), aes(x)) + stat_function(fun = dbeta, n = 101, args = list(2, 5)) + labs(title = \u0026quot;Beta distribution\u0026quot;) Another common distribution is the Cauchy.\nggplot(data = tibble(x = -10:10), aes(x)) + stat_function(fun = dcauchy, n = 201, args = list(-2, 1)) + labs(title = \u0026quot;Cauchy distribution\u0026quot;) The Poisson distribution can be plotted by changing the type of geom and using an n that creates only integers.\n# the range 0:20 includes 21 integers, so n = 21 ggplot(data = tibble(x = 0:20), aes(x)) + stat_function(fun = dpois, n = 21, args = list(4), geom = \u0026quot;point\u0026quot;) + labs(title = \u0026quot;Poisson distribution\u0026quot;) Of course any family with a corresponding dxxx function can be plotted (see ?Distributions and package-provided families).\n References Vasishth, Shravan, M. Beckman, B. Nicenboim, Fangfang Li, and Eun Jong Kong. 2018. “Bayesian Data Analysis in the Phonetic Sciences: A Tutorial Introduction.” Journal of Phonetics 71: 147–61.\n   ","date":1560729600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560729600,"objectID":"d46d03280c251bb3270c5f2fb20b22e2","permalink":"https://stefanocoretta.github.io/post/plot-prior-distributions-with-ggplot2/","publishdate":"2019-06-17T00:00:00Z","relpermalink":"/post/plot-prior-distributions-with-ggplot2/","section":"post","summary":"The choice of priors is a fundamental step of the Bayesian inference process. Vasishth et al. (2018) recommend plotting the chosen priors to see if they are reasonable.\nIn this post I will show how to easily plot prior distributions in ggplot2 (which is part of the tidyverse).\nLet’s load the tidyverse first.\nlibrary(tidyverse) ## ── Attaching packages ───────── tidyverse 1.3.0 ── ## ✓ ggplot2 3.3.2 ✓ purrr 0.","tags":["data viz","rstats","tidy data","statistics"],"title":"Plotting prior distributions with ggplot2","type":"post"},{"authors":null,"categories":["Linguistics","Methods"],"content":"  A few weeks ago, I’ve asked on Twitter what people thought was the average number of participants used in phonetic studies. Here’s the tweet.\nDoes anyone have an estimate of the average number of participants/tokens per context of recently published phonetic studies (let's say from the last 10 years)? #OpenScience #phonetics #replication — Stefano Coretta (@StefanoCoretta) April 12, 2019   Thankfully, Timo Roettger has pointed me to a dataset he and Matthew Gordon created for a study on the acoustic correlates of word stress, and he suggested to look at how the median number of speakers changed (or not) through the years. The dataset reports, among other things, the number of participants in the surveyed studies. Christian DiCanio has also thoughtfully noted that language endangerment should be taken into consideration in any enquiry about number of speakers.\nGeneral trends The dataset contains data from 113 studies, published between 1955 and 2017 (the bulk of studies is within the range 1990-2017 though). The median number of speakers per study is 5. The histogram below illustrates that most studies have around 10 speakers or less, and that there are a few outliers with 30-40 speakers.\n Number of speakers through the years We now turn to the number of speakers through the years. I can’t really say that there is a clear trend, if not for the fact that the studies with more than 30 speakers are (unsurprisingly) more recent.\n Number of speakers by linguistic affiliation The following bar chart shows the median number of speakers in studies by genetic affiliation. The colour of the bars indicates the number of studies. Indo-European languages stand out in terms of number of studies (\u0026gt; 30), although the number of speakers does not fare better than other less-reachable language families.\n## `summarise()` ungrouping output (override with `.groups` argument) This plot is the same as the one above, but families have been categorised by number of studies in two categories: up to 5 studies vs. 5 or more. It is not surprising that Uralic, Indo-European, Turkic, Afro-Asiatic and Austronesian stand out.\n## `summarise()` ungrouping output (override with `.groups` argument)  Number of speakers by endangerment status Information on the endangerment status of the languages in the dataset was obtained from GlottoLog. The following strip chart show the number of speakers for each of the studies (each point) categorised by the endangerment of the language. Of course there are way more studies on safe languages, and if we focus on the first three categories of endangerment (safe, vulnerable, definitely endangered) there is a tendency to have a decreasing number of speakers. Considering though that we are talking of very low numbers of speakers (5-10) I am not sure it is actually relevant that definitely endangered languages have a lower median than safe languages. Difficult to say anything about higher endangerment levels given the low number of studies.\n## Warning: `fun.y` is deprecated. Use `fun` instead. While of course making generalisations based on this cursory analysis would not be wise, there seems to be a tendency for studies to have a very low number of speakers (median 5 speakers over study). The majority of studies have obtained data from 10 speakers or less, independent of publication year and endangerment status of the language enquired.\n ","date":1556841600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556841600,"objectID":"71ed1cb090f71d6bf2a04695537f0470","permalink":"https://stefanocoretta.github.io/post/an-estimate-of-number-of-speakers-per-study-in-phonetics/","publishdate":"2019-05-03T00:00:00Z","relpermalink":"/post/an-estimate-of-number-of-speakers-per-study-in-phonetics/","section":"post","summary":"A few weeks ago, I’ve asked on Twitter what people thought was the average number of participants used in phonetic studies. Here’s the tweet.\nDoes anyone have an estimate of the average number of participants/tokens per context of recently published phonetic studies (let's say from the last 10 years)? #OpenScience #phonetics #replication — Stefano Coretta (@StefanoCoretta) April 12, 2019   Thankfully, Timo Roettger has pointed me to a dataset he and Matthew Gordon created for a study on the acoustic correlates of word stress, and he suggested to look at how the median number of speakers changed (or not) through the years.","tags":["phonetics","statistics","reproducibility","open science"],"title":"An estimate of number of speakers per study in phonetics","type":"post"},{"authors":null,"categories":["Linguistics","Methods"],"content":"This post quickly illustrates how to apply a literate programming workflow to Praat scripting. To be able to reproduce the steps described here you need the latest version of pandoc and the Literate Markdown Tangler (lmt, you will need to install Go first to install lmt).\nWhat is literate programming? In literate programming, one writes both code and plain text which explains what the code does in a single document. Natural language and programming language are interleaved in the document in a way that is reader-oriented, rather than software oriented. So, for example, the code can be included in an order that is different from the order it should have had the document been a script.\nThis programming paradigm allows developers to focus on documenting their code in a more natural way. This has the double advantage of aiding a new user in understanding what the code does and helping the author of the code to develop the code following a logic that can be different from the logic of the code\u0026rsquo;s programming language.\nIn general, from a literate source file (a file containing both natural language and programming code) it is possible to obtain a documentation file (by the process called weaving) and a script file (by the process called tangling) which is interpretable by the target programming language.\nMarkdown, a simple but effective mark-up language, allows mixing natural language (with rich formatting) and code in a single document. Pandoc is a software utility which can convert documents from and to a variety of formats. The conversion relevant to us is from Markdown to PDF. Converting Markdown to PDF corresponds to the weaving process mentioned above, i.e. creating a richly formatted documentation of the code. Pandoc has syntax highlighting capabilities, and Praat syntax is supported, so that your documentation will also be easier to interpret. The Literate Markdown Tangler, by Dave MacFarlane, is a software written in Go that instead can be used to tangle (extract) the code from the source file into a scripting file.\nPandoc and lmt can be used together to develop a literate programming workflow with Praat scripting. This means that you can develop a Praat script by laying out the pieces of the script in the source file and explain what the various parts of the script do in using natural language. lmt further allows the user to create \u0026ldquo;blocks\u0026rdquo; of code that can be referenced in other blocks and reused. If you wanna generate a PDF version of the documentation, you can convert the source file to a PDF with Pandoc.\nThe figure at the top of this post shows an example of a literate Praat source file.\nThe following sections will point you to the software and files that need to be installed/copied and will show how to use literate programming with Praat scripting.\nNecessary software  You need to install the latest version of Pandoc, which can be found here. After installing, be sure you can run this command from your command line GUI: pandoc --version. If a version is returned, Pandoc is working on your system. Install Go from here and set it up, then download and install lmt from here. Download and unzip the content of this zip to a convenient directory (usually, in .pandoc/ in your user folder). This folder contains the files which allow Pandoc to highlight Praat syntax.  Literate Praat To generate the Praat script and its documentation, you have to:\n Write your script in a Markdown source file with Praat code enclosed in code chunks that follow the format required by lmt. Use lmt to tangle the code from the source file into a standalone Praat script. Use pandoc with a custom syntax highlighter to generate the documentation of the script.  The source file The source file will contain text, Markdown markup, and code enclosed between back-ticks. The following is an example of how such file would look like.\nTangle the code To tangle the code into a standalone Praat script, run the following line from your command line GUI, where my-script.praat.md is your Praat source file:\nlmt my-script.praat.md  The scripts defined in the source file will be output in the same directory as the source file (to learn more on how this works, check the lmt README on GitHub).\nWeave the documentation To weave the documentation, run the following by replacing the syntax definition path with the path to the pandoc-praat/ folder on your computer:\npandoc -f gfm -o doc.pdf script.praat.md -N --syntax-definition=\u0026lt;your-path-here\u0026gt;/pandoc-praat/praat.xml  This line of code tells Pandoc to convert from Markdown to PDF and where to find the files for highlighting Praat code.\nA .pdf file named doc.pdf containing the documentation of the script will be created when the line is run.\nSyntax highlighting in your editor If you are after an editor that has syntax highlighting for Praat, I suggest you to try out (Atom)[https://atom.io] and the package language-praat (disclaimer, I am the author of the package 😉).\n","date":1553126400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553126400,"objectID":"8a3ba4398a61957bfdacfe3500254e35","permalink":"https://stefanocoretta.github.io/post/literate-programming-with-praat/","publishdate":"2019-03-21T00:00:00Z","relpermalink":"/post/literate-programming-with-praat/","section":"post","summary":"This post quickly illustrates how to apply a literate programming workflow to Praat scripting. To be able to reproduce the steps described here you need the latest version of pandoc and the Literate Markdown Tangler (lmt, you will need to install Go first to install lmt).\nWhat is literate programming? In literate programming, one writes both code and plain text which explains what the code does in a single document. Natural language and programming language are interleaved in the document in a way that is reader-oriented, rather than software oriented.","tags":["data processing","phonetics","documentation","praat","literate programming","tutorial"],"title":"Literate programming with Praat","type":"post"},{"authors":null,"categories":["Linguistics"],"content":"  Proto-Indoeuropean lexicon is based on monosyllabic roots which have an alternating (ablaut) root vowel preceded and followed by consonants. In this post, I will share some thoughts on the phonotactic restrictions which seem to dictate which consonants can cooccur in a root. I will focus here on stops and laryngeal features. Although I have some formal training in Indoeuropean linguistics, what follows is more of an academic game, so I invite the reader not to expect a fully developed argument.\nThe traditional reconstruction of Proto-Indoeuropean (PIE) stops includes the following laryngeal oppositions:\n Voiceless unaspirated stops (T), Voiced unaspirated stops (D), and Voiced aspirated (murmured) stops (Dʰ).  The possible logical combinations of these laryngeal contrasts in a CVC- root, reviewed in Cooper (2009), are the following (the base ablaut vowel /e/ is used for illustrative purposes):\n   T D Dʰ    T TeT TeD **TeDʰ  D DeT **DeD DeDʰ  Dʰ **DʰeT DʰeD DʰeDʰ    The double asterisks signal those combinations which are not attested in the reconstructed PIE lexicon, namely **TeDʰ, **DED, and **DʰeT. Typologically, these restrictions, in combination with the reconstructed laryngeal oppositions, are somewhat baffling. There are no known languages which unequivocably contrasts voiceless stops with voiced stops and voiced aspirated stops.\nGamkrelidze and Ivanov (1994) and others have used this typological incongruence (with other aspects of the reconstructed PIE phonology) to argue that the reconstructed voiced (D) stops were in fact a type of ejective or glottalised consonants (which gave the name ‘Glottalic theory’). I’ll argue here that a reinterpretation of the restrictions seen above within Glottalic theory offers a sensible and more typologically grounded account of such restrictions.\nAccording to Glottalic theory, voiced stops (D) are glottalised consonants (T’), voiced aspirated stops (Dʰ) are voiced stops with aspirated allophones (D), and the voiceless stops are voiceless stops with aspirated allophones (T). The re-thought laryngeal contrasts thus are:\n Voiceless stops (T), Voiced stops (D), Glottalised (ejective) stops (T’).  Let’s now rewrite the restriction table above:\n   T T’ D    T TeT TeT’ **TeD  T’ T’eT **T’eT’ T’eD  D **DeT DeT’ DeD    The restriction **T’eT’ seems now more plausible, since it involves a typologically less common type of stop. (I remember from my time at the University of Pavia Prof. Gianguido Manzelli telling us there are American languages which have exactly this phonotactic restriction. Unfortunately I fail to remember which these are.) But what about **TeD and **DeT?\nIf we observe the attested combinations, a pattern emerges:\n  T D    TeT DeD  T’eT T’eD  TeT’ DeT’    There seems to be an opposition between ‘T-roots’ and ‘D-roots’, where T’ stops are kind of neutral stops (they can appear in both type of roots). My thought on this is that, speculatively, the T~D contrast derives from an earlier suprasegmental contrast that was assigned to the root, rather than to the individual stops. This could have been something like stress, tone, pitch, or else (also, think about word-level nasality in South American languages, in which a word is either all nasal or oral).\nIf indeed roots could be specified as having the T feature (whatever that was) or the D feature, then it is possible that the glottalised (ejective) stops T’ were immune to changes acted by the root-level T~D distinction. Ejective stops in particular are strongly articulated consonants, and this might explain their resilience to being affected by suprasegmental properties of the root.\nThus, the reconstructed original laryngeal system might have contrasted voiceless stops and ejective stops. There is indeed a dozen languages with this system in South America alone (data from the SAPhon database v1.1.4), for example Alacalufe (Alacalufan), Chulupí (Mataco), and Selk’nam (Chon).\nAll this is of course internal reconstruction, so highly speculative, and as mentioned above, it is not meant to be more than brainstorming. I hope that the potential readers had fun reading this anyway and I am happy to hear about their thoughts.\nReferences Cooper, Adam I. 2009. “Similarity Avoidance in the Proto-Indo-European Root.” University of Pennsylvania Working Papers in Linguistics 15 (1): 8.\n Gamkrelidze, Thomas Valerianis, and Vyacheslav Vsevolodovich Ivanov. 1994. Indo-European and the Indo-Europeans: A Reconstruction and Historical Analysis of a Proto-Language and a Proto-Culture. Translated by J. Nichols. Berlin–New York: Mouton de Gruyter.\n   ","date":1546732800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546732800,"objectID":"4400cd78a2d41ca7b016279876a89d71","permalink":"https://stefanocoretta.github.io/post/on-the-phonotactic-restrictions-of-proto-indoeuropean-roots/","publishdate":"2019-01-06T00:00:00Z","relpermalink":"/post/on-the-phonotactic-restrictions-of-proto-indoeuropean-roots/","section":"post","summary":"Proto-Indoeuropean lexicon is based on monosyllabic roots which have an alternating (ablaut) root vowel preceded and followed by consonants. In this post, I will share some thoughts on the phonotactic restrictions which seem to dictate which consonants can cooccur in a root. I will focus here on stops and laryngeal features. Although I have some formal training in Indoeuropean linguistics, what follows is more of an academic game, so I invite the reader not to expect a fully developed argument.","tags":["proto-indoeuropean","diachrony","typology","phonetics","phonology"],"title":"On the phonotactic restrictions of Proto-Indoeuropean roots","type":"post"},{"authors":null,"categories":["Linguistics"],"content":"  When plotting tongue contours data obtained from ultrasound tongue imaging in R using ggplot2, a common option to smooth over the individual contours and show the general pattern is to use geom_smooth(methood = \"loess\"). However, as I will show in this post, in certain cases this method leads to very disorted contours. Such distortion is more or less always present, although at a lower degree in less extreme cases.\nTo show the shortcomings of using geom_smooth() and present a viable alternative, we’ll be using ultrasound tongue imaging data from one speaker (me). This dataset includes tongue contours from within the closure of the conosonants /t, d/ preceeded by /a, o, u/. The dataset looks like this (some columns dropped):\nselect(tongue_data, rec_date, fan_line, X, Y, word, vowel, c2) ## # A tibble: 1,239 x 7 ## rec_date fan_line X Y word vowel c2 ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 29/11/2016 15:10:52 6 37.4 9.25 pada a d ## 2 29/11/2016 15:21:30 6 38.6 13.1 pada a d ## 3 29/11/2016 15:10:52 7 34.4 10.3 pada a d ## 4 29/11/2016 15:11:03 7 34.3 9.81 pata a t ## 5 29/11/2016 15:11:14 7 34.6 11.0 podo o d ## 6 29/11/2016 15:13:39 7 34.3 9.65 pada a d ## 7 29/11/2016 15:16:05 7 34.8 11.5 pada a d ## 8 29/11/2016 15:17:07 7 34.5 10.5 putu u t ## 9 29/11/2016 15:19:45 7 34.3 9.64 putu u t ## 10 29/11/2016 15:21:30 7 35.4 13.8 pada a d ## # … with 1,229 more rows rec_date is the date and time of recording. Each observed tongue contour has a unique rec_date (this will come in handy later). fan_line is the number of the line in the fan coordinate system used by Articulate Assistant Advanced (which I used to record the data). X and Y are the horizontal and vertical position of each point on the contour. The unit is millimeters. word, vowel and c2 are self-explanatory.\nLet’s start by plotting the smoothed contours by vowel and consonant.\ntongue_data %\u0026gt;% ggplot(aes(X, Y)) + geom_smooth(aes(colour = vowel), method = \u0026quot;loess\u0026quot;) + coord_fixed() + facet_grid(c2 ~ vowel) + theme(legend.position = \u0026quot;none\u0026quot;) We can immediately notice that with /u/ there is something odd going on. That does not look like a tongue surface (maybe that of a chameleon! Definitely not one of a ‘hooman’.) The smooths for /a/ and /o/ seem quite standard.\nTo see what is going on, let’s plot now also the individual points as recorded in the data, whith a superimoposed smooth, for comparison.\ntongue_data %\u0026gt;% ggplot(aes(X, Y)) + geom_point(alpha = 0.1) + geom_smooth(aes(colour = vowel), method = \u0026quot;loess\u0026quot;) + coord_fixed() + facet_grid(c2 ~ vowel) + theme(legend.position = \u0026quot;none\u0026quot;) While the smooths with /a/ and /o/ more or less have a good fit when compared to the points, with /u/ the smooths are really off.\nThis happpens because the tongue root (in this particular case) developpes vertically rather than slanted. The smooth isagnostic about the fact that points lying on the same X value but with different Y values belong to different portion of the tongue contour. The result is that smoothing happens across tongue parts.\nAn alternative (if you don’t like points) is to use geom_path() to plot the individual tongue contours as lines. geom_path() connects points with a line, following the order in which they appear in the dataset. So, before using this geometry, we need to arrange the dataframe such that the points are in the right order (now they are in the wrong order).\nTo do so, we can use rec_date (which identifies the individual contours) and fan_line which indicates the orders of points (for each contour, there a maximum 42 points/fan lines; NAs have been excluded).\ntongue_data \u0026lt;- tongue_data %\u0026gt;% arrange(rec_date, fan_line) tongue_data ## # A tibble: 1,239 x 30 ## speaker seconds rec_date prompt label TT_displacement… TT_velocity ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 it01 1.11 29/11/2… Dico … max_… 77.4 -7.18 ## 2 it01 1.11 29/11/2… Dico … max_… 77.4 -7.18 ## 3 it01 1.11 29/11/2… Dico … max_… 77.4 -7.18 ## 4 it01 1.11 29/11/2… Dico … max_… 77.4 -7.18 ## 5 it01 1.11 29/11/2… Dico … max_… 77.4 -7.18 ## 6 it01 1.11 29/11/2… Dico … max_… 77.4 -7.18 ## 7 it01 1.11 29/11/2… Dico … max_… 77.4 -7.18 ## 8 it01 1.11 29/11/2… Dico … max_… 77.4 -7.18 ## 9 it01 1.11 29/11/2… Dico … max_… 77.4 -7.18 ## 10 it01 1.11 29/11/2… Dico … max_… 77.4 -7.18 ## # … with 1,229 more rows, and 23 more variables: TT_velocity_abs \u0026lt;dbl\u0026gt;, ## # TD_displacement_sm \u0026lt;dbl\u0026gt;, TD_velocity \u0026lt;dbl\u0026gt;, TD_velocity_abs \u0026lt;dbl\u0026gt;, ## # TR_displacement_sm \u0026lt;dbl\u0026gt;, TR_velocity \u0026lt;dbl\u0026gt;, TR_velocity_abs \u0026lt;dbl\u0026gt;, ## # fan_line \u0026lt;int\u0026gt;, X \u0026lt;dbl\u0026gt;, Y \u0026lt;dbl\u0026gt;, word \u0026lt;chr\u0026gt;, language \u0026lt;chr\u0026gt;, sex \u0026lt;chr\u0026gt;, ## # item \u0026lt;int\u0026gt;, ipa \u0026lt;chr\u0026gt;, c1 \u0026lt;chr\u0026gt;, c1_phonation \u0026lt;chr\u0026gt;, vowel \u0026lt;chr\u0026gt;, ## # anteropost \u0026lt;chr\u0026gt;, height \u0026lt;chr\u0026gt;, c2 \u0026lt;chr\u0026gt;, c2_phonation \u0026lt;chr\u0026gt;, ## # c2_place \u0026lt;chr\u0026gt; We can now use geom_path(). The argument group = rec_date ensures that individual lines are plotted (without it, the last point of one contour is connected with the first of the contour following in the dataset).\ntongue_data %\u0026gt;% ggplot(aes(X, Y)) + geom_path(aes(group = rec_date, colour = vowel), alpha = 0.5) + coord_fixed() + facet_grid(c2 ~ vowel) + theme(legend.position = \u0026quot;none\u0026quot;) The tongue root in /u/ is now properly rendered.\nBut what fif you want to plot a single contour (possibly with confidence intervals) for each of the 6 panels in the previous figure, rather than all the contours?\nAn option is to plot an average contour (litterally, the aveages of X and Y). We can easily do that by grouping the data by fan_line and then summarise() it. Plotting can then be done with geom_path() and geom_polygon(). All together, the code looks like this.\nxy_mean \u0026lt;- tongue_data %\u0026gt;% group_by(fan_line, vowel, c2) %\u0026gt;% summarise( X_mean = mean(X, na.rm = TRUE), Y_mean = mean(Y, na.rm = TRUE) ) xy_ci \u0026lt;- tongue_data %\u0026gt;% group_by(fan_line, vowel, c2) %\u0026gt;% summarise( X_CI_low = t.test(X)$conf.int[1], X_CI_up = t.test(X)$conf.int[2], Y_CI_low = t.test(Y)$conf.int[1], Y_CI_up = t.test(Y)$conf.int[2] ) ci_upper \u0026lt;- xy_ci %\u0026gt;% dplyr::select(-X_CI_low, -Y_CI_low) %\u0026gt;% dplyr::rename( CI_X = X_CI_up, CI_Y = Y_CI_up ) ci_lower \u0026lt;- xy_ci %\u0026gt;% dplyr::select(-X_CI_up, -Y_CI_up) %\u0026gt;% dplyr::arrange(dplyr::desc(fan_line)) %\u0026gt;% dplyr::rename( CI_X = X_CI_low, CI_Y = Y_CI_low ) ci \u0026lt;- rbind(ci_upper, ci_lower) ggplot(xy_mean, aes(X_mean, Y_mean)) + geom_polygon(data = ci, aes(x = CI_X, y = CI_Y), alpha = 0.2) + geom_path(aes(X_mean, Y_mean, colour = vowel)) + facet_grid(c2 ~ vowel) + coord_fixed() + theme(legend.position = \u0026quot;none\u0026quot;) ","date":1534982400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534982400,"objectID":"626e10ca7bee3b5510e00e73e12ce785","permalink":"https://stefanocoretta.github.io/post/plotting-tongue-contours-with-ggplot2/","publishdate":"2018-08-23T00:00:00Z","relpermalink":"/post/plotting-tongue-contours-with-ggplot2/","section":"post","summary":"When plotting tongue contours data obtained from ultrasound tongue imaging in R using ggplot2, a common option to smooth over the individual contours and show the general pattern is to use geom_smooth(methood = \"loess\"). However, as I will show in this post, in certain cases this method leads to very disorted contours. Such distortion is more or less always present, although at a lower degree in less extreme cases.","tags":["rstats","phonetics","phonology","data viz","uti","ultrasound","tongue contours"],"title":"Plotting tongue contours with ggplot2","type":"post"},{"authors":null,"categories":["Linguistics"],"content":"  With the advent of more powerful statistical methods for accessing time series data, it is now more common to compare whole vowel formant trajectories rather then just using average formant values.\nSometimes, the output of the Praat script used for extracting formats data gives us a ‘wide format’ dataset. In this format, separate columns contain formant values for each interval within the vowel. Normally, values are extracted every 10% or 5% intervals within the vowel.\nTo work with formant trajectories data in R, we need instead a ‘long format’ dataset. In a long format dataset, the percent intervals are layed out in rows, rather then columns.\nWe start by reading in the formant data, which were kindly provided by Stephen Nichols.\ntrajectories \u0026lt;- read_csv(\u0026quot;./static/data/nichols-2018/tulemupepelako.csv\u0026quot;) ## Parsed with column specification: ## cols( ## .default = col_double(), ## Vowel = col_character(), ## Word = col_character() ## ) ## See spec(...) for full column specifications. trajectories ## # A tibble: 7 x 61 ## Time Vowel Word Duration F1_05 F1_10 F1_15 F1_20 F1_25 F1_30 F1_35 F1_40 ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 194. u tule… 43.3 406. 439. 453. 456. 430. 357. 314. 288. ## 2 194. e tule… 103. 503. 517. 537. 564. 556. 362. 315. 295. ## 3 194. u tule… 14.1 290. 288. 286. 283. 281. 281. 282. 295. ## 4 194. e tule… 75.7 440. 441. 439. 429. 386. 269. 250. 318. ## 5 194. e tule… 68.2 437. 445. 479. 562. 622. 605. 523. 618. ## 6 195. a tule… 89.8 800. 736. 662. 543. 447. 564. 768. 358. ## 7 195. o tule… 98.5 482. 463. 471. 326. 316. 573. 1511. 1389. ## # … with 49 more variables: F1_45 \u0026lt;dbl\u0026gt;, F1_50 \u0026lt;dbl\u0026gt;, F1_55 \u0026lt;dbl\u0026gt;, F1_60 \u0026lt;dbl\u0026gt;, ## # F1_65 \u0026lt;dbl\u0026gt;, F1_70 \u0026lt;dbl\u0026gt;, F1_75 \u0026lt;dbl\u0026gt;, F1_80 \u0026lt;dbl\u0026gt;, F1_85 \u0026lt;dbl\u0026gt;, ## # F1_90 \u0026lt;dbl\u0026gt;, F1_95 \u0026lt;dbl\u0026gt;, F2_05 \u0026lt;dbl\u0026gt;, F2_10 \u0026lt;dbl\u0026gt;, F2_15 \u0026lt;dbl\u0026gt;, ## # F2_20 \u0026lt;dbl\u0026gt;, F2_25 \u0026lt;dbl\u0026gt;, F2_30 \u0026lt;dbl\u0026gt;, F2_35 \u0026lt;dbl\u0026gt;, F2_40 \u0026lt;dbl\u0026gt;, ## # F2_45 \u0026lt;dbl\u0026gt;, F2_50 \u0026lt;dbl\u0026gt;, F2_55 \u0026lt;dbl\u0026gt;, F2_60 \u0026lt;dbl\u0026gt;, F2_65 \u0026lt;dbl\u0026gt;, ## # F2_70 \u0026lt;dbl\u0026gt;, F2_75 \u0026lt;dbl\u0026gt;, F2_80 \u0026lt;dbl\u0026gt;, F2_85 \u0026lt;dbl\u0026gt;, F2_90 \u0026lt;dbl\u0026gt;, ## # F2_95 \u0026lt;dbl\u0026gt;, F3_05 \u0026lt;dbl\u0026gt;, F3_10 \u0026lt;dbl\u0026gt;, F3_15 \u0026lt;dbl\u0026gt;, F3_20 \u0026lt;dbl\u0026gt;, ## # F3_25 \u0026lt;dbl\u0026gt;, F3_30 \u0026lt;dbl\u0026gt;, F3_35 \u0026lt;dbl\u0026gt;, F3_40 \u0026lt;dbl\u0026gt;, F3_45 \u0026lt;dbl\u0026gt;, ## # F3_50 \u0026lt;dbl\u0026gt;, F3_55 \u0026lt;dbl\u0026gt;, F3_60 \u0026lt;dbl\u0026gt;, F3_65 \u0026lt;dbl\u0026gt;, F3_70 \u0026lt;dbl\u0026gt;, ## # F3_75 \u0026lt;dbl\u0026gt;, F3_80 \u0026lt;dbl\u0026gt;, F3_85 \u0026lt;dbl\u0026gt;, F3_90 \u0026lt;dbl\u0026gt;, F3_95 \u0026lt;dbl\u0026gt; The dataset contains formant values of F1-F3 at 5% intervals for the vowels of the word tulemupepelako ‘we are praying for her’ (Bemba, [bemb1257]). It’s a toy dataset of course, just for purpose of illustration, so not very exciting!\nThe values for each 5% interval for each formant are in separate columns. For plotting and modelling, though, we need the data to be in a ‘tidy’ format (Wickham 2014):\n each observation unit is in a separate row each variable is a separate column  In our case, each observation unit is a 5% interval. As for the variables, they are: time in the recording, word, vowel, vowel duration, F1, F2, and F3.\nThe first step towards a long format data set is to gather all the columns that have formant values to a column indicating the formant plus interval (like ‘F1_05’) and the value of that formant in that interval. We can use gather() for this.\nIn the following chunks, I will illustrate the results of each step separately by saving the output of the functions to variables. Later in this post, you’ll find a pipe chain with all functions without intermediate outputs.\ntrajectories_gath \u0026lt;- gather(trajectories, \u0026quot;formant\u0026quot;, \u0026quot;value\u0026quot;, F1_05:F3_95) trajectories_gath ## # A tibble: 399 x 6 ## Time Vowel Word Duration formant value ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 194. u tulemupepelako 43.3 F1_05 406. ## 2 194. e tulemupepelako 103. F1_05 503. ## 3 194. u tulemupepelako 14.1 F1_05 290. ## 4 194. e tulemupepelako 75.7 F1_05 440. ## 5 194. e tulemupepelako 68.2 F1_05 437. ## 6 195. a tulemupepelako 89.8 F1_05 800. ## 7 195. o tulemupepelako 98.5 F1_05 482. ## 8 194. u tulemupepelako 43.3 F1_10 439. ## 9 194. e tulemupepelako 103. F1_10 517. ## 10 194. u tulemupepelako 14.1 F1_10 288. ## # … with 389 more rows Now we have a column formant with the formant plus interval label, and a column value with its value (in Hertz in our case).\nThe next step is to separate the label of the formant plus interval into two separate columns: one for formant, and one for interval.\ntrajectories_sep \u0026lt;- separate(trajectories_gath, formant, c(\u0026quot;formant\u0026quot;, \u0026quot;interval\u0026quot;), convert = TRUE) trajectories_sep ## # A tibble: 399 x 7 ## Time Vowel Word Duration formant interval value ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 194. u tulemupepelako 43.3 F1 5 406. ## 2 194. e tulemupepelako 103. F1 5 503. ## 3 194. u tulemupepelako 14.1 F1 5 290. ## 4 194. e tulemupepelako 75.7 F1 5 440. ## 5 194. e tulemupepelako 68.2 F1 5 437. ## 6 195. a tulemupepelako 89.8 F1 5 800. ## 7 195. o tulemupepelako 98.5 F1 5 482. ## 8 194. u tulemupepelako 43.3 F1 10 439. ## 9 194. e tulemupepelako 103. F1 10 517. ## 10 194. u tulemupepelako 14.1 F1 10 288. ## # … with 389 more rows Now we can create individual columns for each formant from F1 to F3. We can achieve this with spread().\ntrajectories_spr \u0026lt;- spread(trajectories_sep, formant, value) trajectories_spr ## # A tibble: 133 x 8 ## Time Vowel Word Duration interval F1 F2 F3 ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 194. u tulemupepelako 43.3 5 406. 1205. 2626. ## 2 194. u tulemupepelako 43.3 10 439. 1226. 2556. ## 3 194. u tulemupepelako 43.3 15 453. 1246. 2507. ## 4 194. u tulemupepelako 43.3 20 456. 1291. 2451. ## 5 194. u tulemupepelako 43.3 25 430. 1418. 2331. ## 6 194. u tulemupepelako 43.3 30 357. 1555. 2268. ## 7 194. u tulemupepelako 43.3 35 314. 1603. 2335. ## 8 194. u tulemupepelako 43.3 40 288. 1709. 2437. ## 9 194. u tulemupepelako 43.3 45 286. 1712. 2461. ## 10 194. u tulemupepelako 43.3 50 327. 1747. 2470. ## # … with 123 more rows What we have now is a long format dataset, with separate columns for each formant, and individual rows for each vowel interval.\nThe pipe chain All the steps above can be chained by using the pipe %\u0026gt;%.\ntrajectories \u0026lt;- trajectories %\u0026gt;% gather(\u0026quot;formant\u0026quot;, \u0026quot;value\u0026quot;, F1_05:F3_95) %\u0026gt;% separate(formant, c(\u0026quot;formant\u0026quot;, \u0026quot;interval\u0026quot;), convert = TRUE) %\u0026gt;% spread(formant, value) We can finally easily plot the formant trajectories.\ntrajectories %\u0026gt;% ggplot(aes(x = interval)) + geom_smooth(aes(y = F1), se = FALSE, colour = \u0026quot;red\u0026quot;) + geom_smooth(aes(y = F2), se = FALSE, colour = \u0026quot;green\u0026quot;) + geom_smooth(aes(y = F3), se = FALSE, colour = \u0026quot;blue\u0026quot;) + facet_wrap(~ Vowel) + ylab(\u0026quot;Hertz\u0026quot;) ## `geom_smooth()` using method = \u0026#39;loess\u0026#39; and formula \u0026#39;y ~ x\u0026#39; ## `geom_smooth()` using method = \u0026#39;loess\u0026#39; and formula \u0026#39;y ~ x\u0026#39; ## `geom_smooth()` using method = \u0026#39;loess\u0026#39; and formula \u0026#39;y ~ x\u0026#39;  References Wickham, Hadley. 2014. “Tidy Data.” Journal of Statistical Software 59 (10): 1–23.\n   ","date":1519948800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1519948800,"objectID":"8fab2b1cc3a63d9481187dba23e920ed","permalink":"https://stefanocoretta.github.io/post/vowel-formants-trajectories-and-tidy-data/","publishdate":"2018-03-02T00:00:00Z","relpermalink":"/post/vowel-formants-trajectories-and-tidy-data/","section":"post","summary":"With the advent of more powerful statistical methods for accessing time series data, it is now more common to compare whole vowel formant trajectories rather then just using average formant values.\nSometimes, the output of the Praat script used for extracting formats data gives us a ‘wide format’ dataset. In this format, separate columns contain formant values for each interval within the vowel. Normally, values are extracted every 10% or 5% intervals within the vowel.","tags":["rstats","tidy data","phonetics","phonology","linguistics","data processing","time series","formants","formant trajectories","ggplot2"],"title":"Vowel formants trajectories and tidy data","type":"post"},{"authors":null,"categories":[],"content":"Papers  = Preprint (author manuscript prior to peer-review).  = Postprint (accepted author manuscript after to peer-review, same content as published version).  = Published version (accepted manuscript with publisher's formatting, same content as postprint).  = Preregistration.  = Research compendium (data and code).  = Open access.    2020  Thea Cameron-Faulkner, Nivedita Malik, Circle Steele, Stefano Coretta, Ludovica Serratrice, Elena Lieven. A cross cultural analysis of early prelinguistic gesture development and its relationship to language development. Child Development. DOI: 10.1111/cdev.13406.      2020  Longer vowel duration correlates with greater tongue root advancement at vowel offset: Acoustic and articulatory data from Italian and Polish. Journal of the Acoustical Society of America 147. 245-259. DOI: 10.1121/10.0000556.        2019  An exploratory study of voicing-related differences in vowel duration as compensatory temporal adjustment in Italian and Polish. Glossa: a journal of general linguistics 4(1) 125. 1-25. DOI: 10.5334/gjgl.869.       PhD thesis   2020 Vowel duration and consonant voicing: A production study. University of Manchester, UK. DOI: 10.17605/OSF.IO/W92ME     Talks and posters   2020 Patrycja Strycharczuk, Małgorzata Ćavar, and Stefano Coretta. Two mechanisms for vowel reduction in Polish. Talk presented at LabPhon17, 8 July, Vancouver (Canada, virtual).     2020 Meta-analytical estimates of the effect of voicing on vowel duration in English are biased. Poster presented at LabPhon17, 8 July, Vancouver (Canada, virtual).     2019 Thea Cameron-Faulkner, Circle Steele, Nividita Malik, Stefano Coretta, Ludovica Serretrice, and Elena Lieven. A cross-cultural analysis of early prelinguistic gesture development and its relationship to language development. Talk presented at the 5th International Language and Communicative Development Conference, 12 June, Manchester (UK).     2018 Vowel duration as a function of consonant gestural timing in Italian and Polish: Evidence from acoustics, ultrasound tongue imaging, and electroglottography. Invited talk at Aarhus University, 18 September, Denmark.     2018 Coretta, Stefano and Massimiliano Canzi. The effect of lexical frequency on vowel phonation as a correlate of /t/-glottaling. Talk presented at LAGB 2018, 11-14 September, University of Sheffield, UK. DOI: 10.5281/zenodo.1415402     2018 Quantifying vocal fold activity: two new methods for analysing electroglottographic data. Talk presented at New Developments in Speech Sensing and Imaging, 23 June, University of Lisbon, Portugal. DOI: 10.13140/RG.2.2.17341.56801     2018 Longer vowel duration correlates with tongue root advancement in Italian and Polish: An ultrasound study. Talk presented at LabPhon16, 22 June, University of Lisbon, Portugal.     2018 Processing EGG data: New methods for a multidimensional time-series assessment of vocal fold activity. Talk presented at mFiL 2018, 26 Apr, The University of Manchester, UK.     2018 Tongue root advancement and vowel duration: A gradient effect?. Talk presented at the 2018 BAAP Colloquium, 13 Apr, University of Kent, UK.     2017 Vowel duration and tongue root advancement in Italian and Polish. Talk presented at Ultrafest VIII, 4 Oct, University of Potsdam, Germany.     2017 A streamlined workflow for \"doing phonetics by computer\" (using Praat and R). Talk presented at the Postgraduate Academic Research in Linguistics at York (PARLAY), 15 Sep, University of York, UK.     2017 Towards an articulatory based typology of laryngeal effects on vowel duration. Poster presented at the 25th Manchester Phonology Meeting (25mfm), 25–27 May, University of Manchester.     2017 Reproducibility and phonetic research: a computational workflow. Paper presented at the Manchester Forum in Linguistics 2017 (mFiL 2017), 28–29 April, University of Manchester.     2015 A new case of “rhinoglottophilia:” from nasalisation to aspiration. Paper presented at the Second Edinburgh Symposium on Historical Phonology (ESHP2), 3–4 December, University of Edinburgh.     Software and packages   2017 tidymv, Tidy Model Visualisation    2017 rticulate, Ultrasound Tongue Imaging in R    2017 speakr, an R wrapper for the phonetic software Praat    2016 SFM exporter    2016 language-praat, PRAAT scripting language support in the Atom Editor    2013 phonrule, LaTeX macros for typesetting phonological rules    ","date":1515628800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515628800,"objectID":"bec005c9d9ebc5f87cdf1693a8a9fc39","permalink":"https://stefanocoretta.github.io/output/","publishdate":"2018-01-11T00:00:00Z","relpermalink":"/output/","section":"","summary":"Papers  = Preprint (author manuscript prior to peer-review).  = Postprint (accepted author manuscript after to peer-review, same content as published version).  = Published version (accepted manuscript with publisher's formatting, same content as postprint).  = Preregistration.  = Research compendium (data and code).  = Open access.    2020  Thea Cameron-Faulkner, Nivedita Malik, Circle Steele, Stefano Coretta, Ludovica Serratrice, Elena Lieven. A cross cultural analysis of early prelinguistic gesture development and its relationship to language development.","tags":[],"title":"Research output","type":"page"},{"authors":null,"categories":null,"content":"  My research focusses on speech production. In particular, I am interested in the study of speech sounds from a variety of intersecting perspectives, including acoustics, articulation, descriptive linguistics, historical linguistics (sound change), comparative linguistic (typology), and computational modelling.\nProjects As part of my PhD research at the University of Manchester, supervised by Dr Ricardo Bermúdez-Otero and Dr Patrycja Strycharczuk), I investigated the effect of consonant voicing on vowel duration, using a combination of acoustic analyses, ultrasound tongue imaging and electroglottography. My thesis is available here.\nI am currently conducting research within the DFG project Nasal coarticulation and sound-change: a real-time MRI study, and the ERC project Human interaction and the evolution of spoken accent at the Institut für Phonetik und Sprachverarbeitung. These projects employ real-time MRI data to investigate, among other things, how articulatory aspects of speech can pave the way for sound change.\n Languages Among the languages I work(ed) with:\n Mawayana (Arawak) [mapi1252]. Santa Isabel languages (Oceanic) [sant1458]. Lombard (Indo-European) [lomb1257]. Icelandic (Indo-European) [icel1247]. Old Irish (Indo-European) [oldi1246]. English (Mancunian English, Indo-European). Italian (Indo-European) [ital182]. Polish (Indo-European) [poli1260]. German (Indo-European) [stan1295].   Frameworks My position regarding phonology (including phonetics) can be summarised as follows:\n Phonology is a dynamic system (Thelen and Smith 2006; Vihman 2014). Phonology is part of a complex socio-cultural system (Boer 2015; Foulkes and Docherty 2006; Thompson, Kirby, and Smith 2016). Phonology is a complex physical system (Ohala 1990, 2005). Phonology is a complex neuro-cognitive system:  It is rich in details (Johnson 1997; Pierrehumbert 2001; Bybee 2002). It is self-organising and emergent (Wedel 2007, 2011).   I also consider these statements to be extendible more generally to Human Language as a holistic system.\nAs far as research methods are concerned, I am an advocate of Open Science, a term which encompasses “concepts of openness, transparency, rigor, reproducibility, replicability, and accumulation of knowledge” (Crüwell et al. 2019) put to the service of “making the content and process of producing evidence and claims transparent and accessible to others” (Munafò et al. 2017).\nReferences Boer, Bart de. 2015. “Biology, Culture, Evolution and the Cognitive Nature of Sound Systems.” Journal of Phonetics 53: 79–87.\n Bybee, Joan. 2002. “Phonological Evidence for Exemplar Storage of Multiword Sequences.” Studies in Second Language Acquisition 24 (02): 215–21.\n Crüwell, Sophia, Johnny van Doorn, Alexander Etz, Matthew C Makel, Hannah Moshontz, Jesse Niebaum, Amy Orben, Sam Parsons, and Michael Schulte-Mecklenbeck. 2019. “7 Easy Steps to Open Science: An Annotated Reading List.” Zeitschrift Für Psychologie 227 (4): 237–48.\n Foulkes, Paul, and Gerard Docherty. 2006. “The Social Life of Phonetics and Phonology.” Journal of Phonetics 34 (4): 409–38.\n Johnson, Keith. 1997. “Speech Perception Without Speaker Normalization: An Exemplar Model.” In Talker Variability in Speech Processing, edited by Keith Johnson and John W. Mullenix, 145–65. San Diego, CA: Academic Press.\n Munafò, Marcus R., Brian A. Nosek, Dorothy V. M. Bishop, Katherine S. Button, Christopher D. Chambers, Nathalie Percie Du Sert, Uri Simonsohn, Eric-Jan Wagenmakers, Jennifer J. Ware, and John P. A. Ioannidis. 2017. “A Manifesto for Reproducible Science.” Nature Human Behaviour 1 (1): 0021.\n Ohala, John J. 1990. “There Is No Interface Between Phonology and Phonetics: A Personal View.” Journal of Phonetics 18 (2): 153–72.\n ———. 2005. “The Marriage of Phonetics and Phonology.” Acoustical Science and Technology 26 (5): 418–22.\n Pierrehumbert, Janet B. 2001. “Exemplar Dynamics: Word Frequency, Lenition and Contrast.” In Frequency and the Emergence of Linguistic Structure, edited by Joan L. Bybee and Paul J. Hopper, 137–57. Amsterdam Philadelphia: John Benjamins Publishing Company.\n Thelen, Esther, and Linda B. Smith. 2006. “Dynamic Systems Theories.” In Handbook of Child Psychology, edited by Richard M. Lerner, 258–312. Wiley \u0026amp; Soons.\n Thompson, Bill, Simon Kirby, and Kenny Smith. 2016. “Culture Shapes the Evolution of Cognition.” Proceedings of the National Academy of Sciences 113 (16): 4530–5.\n Vihman, Marilyn May. 2014. Phonological Development: The First Two Years. Oxford: Wiley-Blackwell.\n Wedel, Andrew B. 2007. “Feedback and Regularity in the Lexicon.” Phonology 24 (01): 147–85.\n ———. 2011. “Self-Organization in Phonology.” In The Blackwell Companion to Phonology, edited by Ewen C. J. Hume E. van Oostendorp Marc and Keren Rice, 1:130–47. Blackwell, Oxford.\n    ","date":1515110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515110400,"objectID":"7c426325d670833f9b666a69cfa56d5c","permalink":"https://stefanocoretta.github.io/research/","publishdate":"2018-01-05T00:00:00Z","relpermalink":"/research/","section":"","summary":"My research focusses on speech production. In particular, I am interested in the study of speech sounds from a variety of intersecting perspectives, including acoustics, articulation, descriptive linguistics, historical linguistics (sound change), comparative linguistic (typology), and computational modelling.\nProjects As part of my PhD research at the University of Manchester, supervised by Dr Ricardo Bermúdez-Otero and Dr Patrycja Strycharczuk), I investigated the effect of consonant voicing on vowel duration, using a combination of acoustic analyses, ultrasound tongue imaging and electroglottography.","tags":null,"title":"Research","type":"page"},{"authors":null,"categories":["Linguistics"],"content":"  The Italian Wikipedia has reached a number of 1,215,574 articles, with 1,247,172 registered users (source: Italian Wikipedia Statistics). That’s more or less one user per article. The Italian encyclopaedia counts an average of 358,814 views per hour (source: Wikipedia Statistics).\nNevertheless, the linguistics presence suffers from a variety of cyber-diseases. According to the figures described on the page of the Italian Linguistics WikiProject, out of 890 articles, 250 don’t cite proper sources for their information and about 270 are stubs that need to be expanded.\nBut one topic in particular has been recently called to our attention (I’m a Wikipedia editor myself): the “dialects of Italy.”\nThe problem is twofold: on the one hand, “dialects of Italy” refers to heterogeneous entities and, on the other, there is no agreement on how to define a “dialect” (nor a “language,” for that matter; see Cysouw and Good’s article about this, Cysouw and Good 2013). This is further complicated by the rooted misunderstanding of linguistics facts and concepts that the general public usually has.\nAll of this, together with the “poor sourcing” problem, led to chaos: see the lengthy discussion about what to call a dialect and what a language (the title Un argomento cruciale, ‘A critical topic,’ should be enough for grasping the seriousness of the matter).\nSome time ago, a decision has been made to use the term “language” for any linguistic entity that had a code from the ISO 639-3 (to be sure, that’s from Ethnologue, by SIL), and “dialect” for entities without a code. This created an inconvenient precedent: since no Italian scientific source uses labels like “Piedmontese language” (lingua piemontese) or “Calabrian language” (lingua calabrese), Wikipedia came to be a primary source of this use, thus contradicting one of the main tenets of the open encyclopaedia. That is: no original research (NOR).\nThe reaction of the laypeople is: “Wikipedia calls it a language, so it is indeed.” This is backed up by the (misled but widespread) notion of dialect as a “lower and/or corrupted variety of Italian,” further strengthened by the idea that Wikipedia is authoritative with no exceptions. But let me stress it again, no academic source labels the mentioned linguistic entities of Italy as “languages.” Sorry folks.\nBut why is that? Well, tradition. The dialects of Italy have been called that since long and it would be extremely difficult to ask Italian linguists to stop calling them that way. However, no (sensible) linguist would consider them as corruptions of the Italian language.\nAs an emblematic example, (Loporcaro 2009, 4–5) succinctly gives us an interesting perspective: “Derivando indipendentemente dal latino, i dialetti come il padovano, il napoletano ecc. sono lingue sorelle dell’italiano.” (trad: “Independently deriving from Latin, the dialects such as Paduan, Neapolitan, etc. are sister languages of Italian.”). Although Loporcaro stresses the fact that what are normally labelled as “dialects” are languages, he is probably forced to still call them “dialects.” The point is, no one has ever called the dialects of Italy using the apposition “language” (2018 EDIT: probably until recently): so no “Paduan language,” nor “Neapolitan language.” Hence, this use in Wikipedia is totally unjustified.\nLuckily, the trend in the encyclopaedia of abusing of the ISO 639 is in the process of being counteracted and some Wikipedians are making an effort to take the situation back under control. In the meantime, read the Cysouw and Good’s article mentioned early if you didn’t already.\nReferences Cysouw, Michael, and Jeff Good. 2013. “Languoid, Doculect, and Glossonym: Formalizing the Notion ‘Language’.” Language Documentation \u0026amp; Conservation 7: 331–59.\n Loporcaro, Michele. 2009. Profilo Linguistico Dei Dialetti Italiani. Bari: Laterza.\n   ","date":1438693915,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1438693915,"objectID":"bf73e51e53f4cf541161f1ec0a413364","permalink":"https://stefanocoretta.github.io/post/2015-08-04-wikipedia-and-the-dialects-of-italy/","publishdate":"2015-08-04T13:11:55Z","relpermalink":"/post/2015-08-04-wikipedia-and-the-dialects-of-italy/","section":"post","summary":"The Italian Wikipedia has reached a number of 1,215,574 articles, with 1,247,172 registered users (source: Italian Wikipedia Statistics). That’s more or less one user per article. The Italian encyclopaedia counts an average of 358,814 views per hour (source: Wikipedia Statistics).\nNevertheless, the linguistics presence suffers from a variety of cyber-diseases. According to the figures described on the page of the Italian Linguistics WikiProject, out of 890 articles, 250 don’t cite proper sources for their information and about 270 are stubs that need to be expanded.","tags":["dialect","Ethnologue","iso639","Italian","Italy","language","romance","wikipedia"],"title":"Wikipedia and the “Dialects of Italy”","type":"post"},{"authors":null,"categories":["Linguistics"],"content":"  List of available phonological databases (updated 2019-03-22):\n UCLA Phonological Segment Inventory Database (UPSID) Lyon-Albuquerque Phonological Systems Database (LAPSyD) Phonetics Information Base and Lexicon (PHOIBLE) World Atlas of Language Structures (WALS) South American Phonological Inventory Database (SAPhon) BDPROTO Proto-language segment inventories (DBPROTO) Database of Eurasian phonological inventories (link) Indo-European Phonological Inventory Database (IEPhon, dead link)  UCLA Phonological Segment Inventory Database  number of records: 451 languages type of sample: genetically balanced interface: desktop and web data: inventory, language family, comments, source searchable: for language, number of sounds, frequency index, family and phonetic features search display: list   Lyon-Albuquerque Phonological Systems Database  number of records: (in progress) type of sample: not balanced interface: web data: consonant and vowel inventories, syllable structure, stress and tone systems, language location and classification searchable: for language (name, iso, classification), sounds (table format), phonetic features, syllable search display: segment table, boolean (sound, feature, area, family, syllable)   Phonetics Information Base and Lexicon  number of records: 1,010 languages type of sample: not balanced interface: web data: inventory, segment class, language location searchable: for language (name, iso), sounds (list format), source search display: list   World Atlas of Language Structures  number of records: 2,679 languages type of sample: balanced interface: desktop and web data: size of consonant inventory, size of vowel inventory, consonant-vowel ratio, voicing and gaps in plosive system, uvular consonant, glottalized consonants, velar nasal, reduplication searchable: for language (name, iso, genus, family, macroarea; list format), characteristics (list format) search display: list and map   South American Phonological Inventory Database  number of records: 359 languages type of sample: not balanced, South America interface: web data: segment inventory, suprasegmentals, language (name, iso, family, country) searchable: for language (name, iso, family, country; list format and map), sounds (table) search display: table, list and map   BDPROTO Proto-language segment inventories  number of records: 137 languages type of sample: genialogical diversity, convenience sample interface: offline (csv, sql) data: segment inventory, suprasegmentals, language (name, iso, family, homeland, time depth) searchable: yes search display: none   Database of Eurasian phonological inventories  number of records: 416 languages type of sample: interface: web and offline (json) data: segment inventory, suprasegmentals, language (name, family, group) searchable: segment inventory, language, location search display: map, list, segments table   Indo-European Phonological Inventory Database [dead link]  number of records: 18 languages type of sample: not balanced, Indo-European family interface: web data: segment inventory, language (name, family, area) searchable: for language (name, family, country; list format and map), sounds (table) search display: table, list and map   ","date":1404086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1404086400,"objectID":"831c6cec14e3a6a73f7e3074cb614e84","permalink":"https://stefanocoretta.github.io/post/2014-06-30-short-review-phonological-databases/","publishdate":"2014-06-30T00:00:00Z","relpermalink":"/post/2014-06-30-short-review-phonological-databases/","section":"post","summary":"A review of available phonological databases (2014).","tags":["databases","distinctive features","linguistics","phonetics","phonology","statistics","computational linguistics"],"title":"Short review of phonological databases","type":"post"}]